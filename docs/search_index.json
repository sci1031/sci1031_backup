[["index.html", "SCI 1031 Visualisation et analyse de données spatiales sous R ", " SCI 1031 Visualisation et analyse de données spatiales sous R 2022-06-10 Bienvenue sur le site du cours SCI 1031! L’entièreté du contenu du cours est disponible en accès libre sur ce site. Les évaluations sont disponibles sur le site web de la TÉLUQ aux étudiantes et aux étudiants inscrits dans ce cours. Avant de débuter le cours, familiarisez-vous avec la structure de ce site en utilisant le menu vertical à gauche. Lisez attentivement la section Présentation avant de vous plongez dans les apprentissages. "],["à-propos-du-cours.html", "À propos du cours", " À propos du cours Présentation Comme son nom l’indique, le cours SCI1031 porte sur la visualisation et l’analyse de données spatiales avec le langage de programmation et logiciel libre R. Pourquoi suivre ce cours ? L’intérêt du cours SCI 1031 est lié plusieurs aspects. Tout d’abord, nos sociétés sont confrontées à une incroyable augmentation des données spatiales. C’est-à-dire des données qui possèdent une composante spatiale, comme des coordonnées géographiques. Pensons, par exemple, aux données de télédétection récoltées par des satellites et des véhicules aériens télépilotés (drones). Ou encore, aux données échantillonnées par des technologies de notre vie quotidienne qui sont munis d’un système de géo-positionnement par satellite (GPS!) intégré comme les téléphones intelligents, les caméras, et les tablettes. Cet accroissement des données spatiales est interrelié avec une explosion d’applications qui dépendent des données spatiales et qui en génèrent dans des domaines aussi variés que le marketing, l’évaluation des risques par les compagnies d’assurances, la logistique des réseaux de transports, et les études d’impact environnementaux. Ainsi, cette effervescence des données spatiales et de leurs applications entrainement nécessairement une hausse de la demande pour des compétences spécialisées dans la manipulation, la visualisation et l’analyse de données spatiales. L’objectif général du cours SCI 1031 est donc de permettre aux étudiantes et aux étudiants de développer ces compétences essentielles pour traiter les données spatiales, tant dans leurs études que sur le marché de l’emploi. Pourquoi R ? R1 est un logiciel libre et un langage de programmation qui offre un environnement riche permettant de réaliser une multitude de tâches incluant des calculs statistiques, des graphiques scientifiques, de la manipulation de bases de données, et de la modélisation. R est devenu un outil incontournable en sciences des données. La communauté R est constituée non seulement d’utilisatrices et d’utilisateurs, mais aussi de créatrices et de créateurs. Ceux-ci améliorent constamment les capacités de R par le développement de nouvelles fonctionnalités et de bibliothèques spécialisées qui deviennent accessibles à toute la communauté. Dans les dernières années, plusieurs expertes et experts de l’analyse et de la visualisation de données spatiales se sont affairés à bâtir des bibliothèques simples et efficaces destinées aux traitements des données spatiales. Ces bibliothèques sont mise-à-jour continuellement alors que d’autres bibliothèques voient le jour pour répondre à des nouveaux besoins. Un avantage indéniable à utiliser R, en comparaison aux autres outils de visualisation de données spatiales, est sa grande flexibilité. L’abondance des bibliothèques permet d’utiliser R pour accomplir des opérations diverses. Il est ainsi possible de produire des cartes géographiques de grande qualité avec R et de faire des analyses statistiques spatiales très poussées. Tout cela sans changer de logiciel et en conservant la même syntaxe générale. Objectifs Voici ce que vous serez en mesure de faire à la fin du cours SCI 1031: Identifier les concepts fondamentaux propres à la représentation spatiale. Décrire les types de données spatiales et leurs caractéristiques. Appliquer l’usage d’opérateurs spatiaux de base à la réalisation d’analyses spatiales simples. Créer une carte thématique respectant les règles cartographiques. Appliquer les fonctions de base des principales librairies R destinées à la manipulation, la visualisation et l’analyse de données spatiales. Représenter des données spatiotemporelles. Contenu sommaire Le cours est divisé en 9 modules: Module 1 : Introduction Ce module donne un aperçu de l’évolution historique dans la représentation des données spatiales, des premières cartes jusqu’à l’avènement des systèmes d’information géographiques. Il fait une revue des outils existants pour visualiser et analyser les données spatiales. Il présente aussi les concepts essentiels à l’étude des données spatiales. Module 2 : Modèles de données spatiales Ce module s’intéresse à la façon dont nous représentons les phénomènes spatiaux se déroulant à la surface de la Terre par des données spatiales. Il présente les propriétés des deux types de modèle de données spatiales: les données vectorielles et les données matricielles. Module 3 : Systèmes de coordonnées de référence Ce module porte sur les systèmes de coordonnées de référence. Il explique les concepts mathématiques et cartographiques pour représenter la position des données sur la surface de la Terre. Module 4 : Données vectorielles Ce module se veut une introduction à la bibliothèque R sf. Il présente les fonctions de base pour lire, interpréter et visualiser des données vectorielles. Module 5 : Données matricielles Ce module se veut une introduction à la bibliothèque R raster. Il présente les fonctions de base pour lire, interpréter et visualiser des données matricielles. Module 6 : Cartographie Ce module explique les principes essentiels de la cartographie, des informations indispensables comme la légende, jusqu’au choix des couleurs. Il présente les fonctions de la bibliothèque R tmap pour créer des projets cartographiques. Module 7 : Manipulation de données vectorielles Ce module présente les fonctions R pour manipuler les attributs de données vectorielles et faire des opérations spatiales sur ces données comme faire des jointures spatiales ou trouver l’intersection entre des données. Module 8 : Manipulation de données matricielles Ce module présente les fonctions R pour filtrer les valeurs des données matricielles et faire des opérations spatiales sur ces données tel que découper un raster. Module 9 : Données spatiotemporelles Ce module explique comment manipuler des données spatiales qui possèdent une dimension temporelle. Il présente certaines fonctions des bibliothèques R lubridate et animation. Fonctionnement du cours Organisation des modules Le cours s’échelonne sur 15 semaines. La feuille de route constitue un guide pour vous aider à répartir vos apprentissages tout au long de votre cheminement. Les modules sont tous divisés en deux parties: une partie Leçon et une partie Exercices. Pour les modules 1, 2, et 3 La partie Leçon comprend des apprentissages théoriques. Vous apprendrez les concepts de base propres aux données géospatiales. Ces apprentissages sont essentiels avant de se lancer dans l’apprentissage des fonctions R spécifiques à la manipulation, l’analyse et la visualisation de données spatiales. La partie Exercices comprend une révision des bases de R (module 1) et une introduction à RMarkdown (module 2 et 3). Vous serez également amenés à mettre en pratique ces apprentissages en répondant à quelques questions. Pour les modules 4, 5, 6, 7, 8, et 9 La partie Leçon comprend des apprentissages théoriques et aussi pratiques: vous serez guidé dans l’utilisation de fonctions R et dans la résolution de problèmes. La partie Exercices comprend des questions pour mettre en pratique vos apprentissages. Bien que les réponses aux questions soient disponibles, il est important de tenter d’y répondre par vous-mêmes. Les questions des travaux notés et de l’examen sont très semblables à celles des parties Exercices. Apprentissage de R Il est important d’organiser sur votre ordinateur un environnement de travail optimal pour faciliter vos apprentissages. Il est fortement recommandé de créer un répertoire, par exemple SCI1031, dédié exclusivement à ce cours. Dans ce répertoire, créé également un répertoire pour chacun des neuf modules du cours (p. ex. Module1, Module2, …, Module9). À chaque module du cours, vous serez amené à utiliser des données sur lesquelles vous pratiquerez des opérations R. Ces données seront fournies dans un dossier zippé à télécharger (Module1_donnees.zip, Module2_donnees.zip, …, Module9_donnees.zip). Sauvegarder le dossier de données dans le répertoire correspondant à son module sur votre ordinateur. Il est également recommandé de vous créer un fichier R (ou Rmd) pour chaque module (p.ex. Mod1.R, Mod2.R, …, Mod9.R) dans lequel vous pourrez copier-coller les opérations R enseignées. Vous pourrez ainsi vous exercer à utiliser ces opérations et vous assurer de comprendre leur fonctionnement. Il facile de copier les blocs de codes R à partir de la page web en utilisant le bouton dédié à cette fin dans le coin supérieur droit de chaque bloc. Figure 0.1: Le bouton supérieur droit vous permet de copier facilement un bloc de codes R. Travaux notés Le cours comprend trois (3) travaux notés (chacun 20%) et un examen final (40%). La date de remise des travaux notés, telle que suggérée dans la feuille de route est flexible: vous ne serez pas pénalisé si vous remettez votre travail après cette date. Toutefois, il est préférable d’espacer la remise des travaux pour pouvoir bénéficier d’une rétroaction de la part de la personne qui corrige. Noter que vous devez faire l’examen au plus tard au cours de la dernière semaine. Il s’agit d’un examen à faire chez soi. L’examen dure 3 heures mais vous avez 3 jours (72 heures) pour remettre vos réponses à partir du moment où vous l’entamez. Les consignes, les données à utiliser, et les gabarits de réponses pour les travaux notés et l’examen sont disponibles sur la page web du cours sur le site de la TÉLUQ. Seuls les étudiants inscrits à la TÉLUQ ont accès aux évaluations. Rétroaction Le mode de communication le plus efficace pour rejoindre la personne qui vous encadre est le courriel. Si cela s’avère nécessaire une rencontre zoom ou un appel téléphonique pourront être planifiés. Le sujet de votre courriel doit contenir le sigle du cours. De plus, vous devez clairement vous identifier dans votre courriel: nom, prénom, numéro d’étudiant. La personne qui vous encadre, encadre beaucoup d’étudiantes et d’étudiants, et cela dans plusieurs cours! Si votre courriel comporte une question sur une ou des opérations R qui vous causent problème, vous devez absolument inclure toutes les commandes R depuis l’importation des données jusqu’au problème rencontré. Il est recommandé d’envoyer un fichier R avec vos commandes pour faciliter l’intervention de la personne qui vous encadre. Sauf exception (en cas de maladie, de vacances ou de déplacements dans le cadre de travaux de recherche) vous recevrez une réponse à votre courriel dans les 48h. Les travaux corrigés seront remis au plus tard deux semaines suivant leur dépôt mais généralement dans un délai d’une semaine. Feuille de route Modules Semaines 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Module 1 Introduction Module 2 La représentation spatiale Module 3 Systèmes de coordonnées de référence Module 4 Données vectorielles Module 5 Données matricielles Travail noté 1: 20 % X Module 6 Cartographie Travail noté 2: 20 % X Module 7 Opérations sur les données vectorielles Module 8 Opérations sur les données matricielles Travail noté 3: 20 % X Module 9 Opérations sur les données spatio-temporelles Examen: 40 % X Crédits Équipe Direction pédagogique, conception et rédaction: Élise Filotas Soutien à la conception: Kevin Cazelles et Steve Vissault Direction multi-média: Mathieu Corriveau et Élodie Bussières Conception graphique: Marie-Sol Lapointe Intégration: Elise Filotas, Kevin Cazelles et Simon Gaudreau Reproduction du contenu Vous êtes autorisé à copier, distribuer et communiquer le matériel contenu sur ce site selon la licence Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0). Contact Élise Filotas Je suis professeure au Département Science et technologie de la TELUQ en écologie quantitative et je suis responsable du cours SCI 1031. Vous pouvez me rejoindre à l’adresse suivante: elise.filotas@teluq.ca Consultez mon site web pour en savoir plus sur ma recherche. R est soutenu par le R Core Team et la R Foundation for Statistical Computing: www.r-project.org↩︎ "],["ressources.html", "Ressources", " Ressources Travaux notés Le cours comprend trois (3) travaux notés (chacun 20%) et un examen final (40%). La date de remise des travaux notés, telle que suggérée dans la feuille de route est flexible: vous ne serez pas pénalisé si vous remettez votre travail après cette date. Toutefois, il est préférable d’espacer la remise des travaux pour pouvoir bénéficier d’une rétroaction de la part de la personne qui corrige. Noter que vous devez faire l’examen au plus tard au cours de la dernière semaine. Il s’agit d’un examen à faire chez soi. L’examen dure 3 heures mais vous avez 3 jours (72 heures) pour remettre vos réponses à partir du moment où vous l’entamez. Les consignes, les données à utiliser, et les gabarits de réponses pour les travaux notés et l’examen sont disponibles sur la page web du cours sur le site de la TÉLUQ. Seuls les étudiants inscrits à la TÉLUQ ont accès aux évaluations. Données Données du cours Les liens suivants vous dirigerons directement vers les données utilisées pour chaque module Module 1 Module 4 Module 5 Module 6 Module 7 Module 8 Module 9 Autres sources Cette rubrique répertorie différentes bases de données qui contiennent des données spatiales. Données Québec Données ouvertes du Gouvernement du Canada Répertoire de données spatiales de l’Université Laval Répertoire de données spatiales de l’Université Sherbrooke Répertoire de données spatiales de l’Université du Texas à Austin Données de la Banque Mondiale Données de la Commission Européenne sur l’urbanisation de la planète Données de déplacement UBER Vous êtes tombé sur une base de données intéressante qui ne figure pas plus bas? Partagez avec moi votre découverte et je l’ajouterai à cette liste. Ressources R Vous trouverez ici des liens vers différentes ressources R. Documentation générale R Site officiel de R: CRAN An introduction to R Forum de la communauté RStudio Introduction to R R for Data Science Documentation R-géospatial Geocomputation with R Introduction to R for Geospatial Data Intro to GIS and Spatial Analysis Spatial Data Science with applications in R Spatial Data Science with R Les bibliothèques R Outil de recherche des bibliothèques de CRAN sf raster mapview tmap animation lubridate Documentation R-Markdown Aide-mémoire Syntaxe de base Guide de référence Livre d’astuces Syntaxe Pandoc Markdown (en français) Utilisation de R Markdown pour la création de documents : PDF HTML Word Tufte handout (Pdf) R Package Vignette (Html) Utilisation de R Markdown des présentations : Beamer ioslide Slidy Dérivés de R Markdown bookdown blogdown Les couleurs dans R Document pdf des couleurs dans R. Liste des couleurs par leur nom. Les couleurs dans ggplot2 Palettes de couleurs ColorBrewer Références "],["intro.html", "Module 1 Introduction", " Module 1 Introduction Ce module est une introduction au cours que vous vous apprêter à suivre. Dans la section leçon, nous discuterons de l’évolution historique de la visualisation des données spatiales, des premières cartes jusqu’à l’avènement des systèmes d’information géographique. Nous ferons une revue des outils existants pour visualiser et analyser les données spatiales. Finalement, nous présenterons quelques concepts de base essentiels à l’étude des données spatiales. À la fin de ce module vous saurez: Décrire les changements dans la représentation géographique au cours de l’histoire. Définir ce qu’est la géomatique. Décrire les propriétés générales des systèmes d’information géographique (SIG). Donner des exemples d’application des SIG. Nommer des outils et logiciels de visualisation et d’analyse géospatiale. Décrire les avantages offerts par le logiciel R. Définir les concepts de bases dans l’étude des données spatiales : la résolution, l’étendue, le voisinage, les gradients, l’effet de bordure, etc. La section exercice est une brève introduction au logiciel R. Vous apprendrez à installer R et RStudio et vous vous familiariserez avec les notions importantes de l’environnement de travail R. Vous réviserez également les concepts et les fonctions de base pour utiliser R. Cette section se conclue par un petit exercice pour mettre en pratique les concepts R enseignés. "],["lecon_intro.html", "1.1 Leçon", " 1.1 Leçon 1.1.1 Les données spatiales d’hier à aujourd’hui Les cartes anciennes La représentation géographique est une description de l’emplacement des éléments naturels (cours d’eaux, montagnes, forêts, etc.) et artificiels (routes, ponts, bâtiments, etc.) au sein d’un territoire. Cette représentation peut être détaillée ou abstraite, et décrire un espace restreint tout comme un vaste territoire. La cartographie est utilisée depuis l’Antiquité pour répondre à de multiples besoins comme celui d’illustrer la distribution spatiale des ressources, de définir les frontières et l’appartenance des territoires ou encore de guider les déplacements. La carte de la cité babylonienne de Nippur, datant d’environ 1500 av. J.-C., constitue probablement la plus vieille carte connue tracée à l’échelle (Figure 1.1). Dessinée sur une tablette d’argile, cette carte représente, notamment, un réseau d’irrigation destiné à l’agriculture. Figure 1.1: La carte de Nippur tracée sur une tablette d’argile. Source : Mary Harrsch. Les cartes reflètent la compréhension et la perception qu’ont le ou leurs auteurs du territoire. Le géographe et historien grec Hécatée de Milet, qui a vécu au 5ième siècle av. J.-C., aurait conçu une des premières cartes du monde. Cette dernière est circulaire et place la Méditerranée en son centre (Figure 1.2). Figure 1.2: Une reconstitution de la carte du monde d’Hétacée. Source : Arnaud, P. (2009). Les cartes antiques. L’archéotherma. Un regard sur les cartes anciennes du monde est révélateur de l’évolution des connaissances en géographie (Figure 1.3 et Figure 1.4). Par le choix des éléments représentés et l’importance visuelle accordée à certains éléments plutôt que d’autres, les cartes témoignent aussi des valeurs et des croyances qui animaient les sociétés qui les ont produites. Figure 1.3: La carte du monde de Claude Ptolémée. Cet astronome, mathématicien et géographe grec du 1er siècle est l’auteur du Manuel de géographie. La carte illustrée ci-dessus a été reconstituée par le cartographe Nicolaus Germanus en 1467, qui s’est intéressé à moderniser et vulgariser les travaux de Ptolémée. Source: https://archives.fbi.gov/archives/news/stories/2007/november/stolenmaps_110807. Figure 1.4: Carte du nouveau monde de Sebastien Münster. Ce cartographe, astronome et mathématicien allemand, connu, entre autres pour son œuvre Cosmographia Universalis a produit cette carte en 1552. Source : https://digital.library.yorku.ca/islandora/object/yul:1153586. Pour ceux et celles intéressés aux cartes historiques, la figure 1.5 présente des cartes de Montréal produites à différents moments depuis la colonisation. Ces cartes démontrent l’évolution dans l’organisation du territoire de l’île de Montréal et aussi dans le rendu visuel des cartes. Figure 1.5: Représentations de Montréal en 1556, 1645, 1758, 1843, 1897, 1920, 1960, et 1982 (dans l’ordre allant de gauche à droite et de haut en bas). Sources: Archives Montréal. À partir du 19e siècle, on commence à utiliser la représentation géographique afin d’explorer les relations entre l’occurrence de certains phénomènes et leur localisation. C’est le début de l’analyse spatiale. Un exemple bien connu est celui de l’analyse réalisée en 1854 par le docteur anglais John Snow pour comprendre la propagation d’une épidémie soudaine de choléra dans le quartier Soho de Londres. John Snow doutait de la théorie en vigueur à l’époque voulant que les maladies telles le cholera ou la peste soient transmises par l’inhalation d’émanations malsaines (appelées des miasmes – des mauvais airs). Il supportait plutôt l’hypothèse que le choléra se développe par l’ingestion d’eau impropre. Il cartographia les lieux de résidence des personnes infectées et observa qu’ils se trouvaient à proximité de la pompe à eau de Broad Street (Figure 1.6. Cette dernière puisait son eau d’une section polluée de la Tamise. Il sut convaincre les autorités de fermer la pompe, ce qui stoppa l’épidémie. John Snow est perçu aujourd’hui comme un des pionniers de l’épidémiologie moderne. Figure 1.6: Reconstitution de la carte de l’épidémie de cholera créée par John Snow. Chaque barre rouge représente une personne infectée. Les pompes à eau sont illustrées en vert. Source: Wikipedia. La géomatique L’arrivée de l’informatique et des données numériques viennent transformer la cartographie traditionnelle et la façon de traiter l’information géographique. Dans les années 1960, le terme « géomatique », qui est une contraction entre les mots géographie et informatique, est proposé pour désigner cette nouvelle discipline. On définit la géomatique comme « l’ensemble des connaissances et technologies nécessaires à la production et au traitement des données numériques décrivant le territoire, ses ressources ou tout autre objet ou phénomène ayant une position géographique. »2 En effet, les géographes ou autres utilisateurs de données spatiales doivent maintenant composer avec des données numériques diverses acquises par la photographie aérienne et satellitaire, les outils topographiques électroniques ou munis de GPS, la numérisation de documents papiers, etc. De nos jours, la cartographie a laissé place aux systèmes d’informations géographiques (SIG). Un SIG est un système informatique servant à acquérir, gérer, analyser, et visualiser des données géographiques numériques dans le but d’étudier un phénomène se produisant sur la Terre. Nous pouvons donc utiliser un SIG pour produire des cartes, mais également pour intégrer des données multi-sources (cartes, photos, images, …), pour réaliser des requêtes et visualiser des résultats, ou encore faire des analyses spatiales (Figure 1.7). Figure 1.7: Les différents éléments qui composent un SIG. Source: image récupérée le 6 décembre 2021 à https://bookdown.org/tep/gisbooklet/introduction-to-gis.html. Un SIG est composé d’un ordinateur, de données numériques, et d’un ou plusieurs logiciels spécialisés. De plus, un SIG doit être développé par du personnel qualifié et pouvoir servir à des utilisatrices ou des utilisateurs. Les SIG font maintenant partie de notre vie quotidienne. Pensez par exemple à Google Map, un des SIG les plus utilisés. Ce dernier permet de calculer des itinéraires, de localiser des services près d’une adresse, et de visualiser une localisation par l’outil « Street View ». Plusieurs services offerts aux individus sont aussi dotés d’une interface SIG, comme la plateforme de vélos en libre-service BIXI, ou encore les sites immobiliers pour la vente ou la location de logement (Figure 1.8). Figure 1.8: Exemples de SIG dans notre vie quotidienne. Google Map affiche les services autour d’une adresse. L’application BIXI permet de trouver les bornes et les vélos accessibles. Source: image récupérée le 6 décembre 2021 à https://journaldesvoisins.com/nouvelles-stations-bixi-dans-ahuntsic-cartierville/. L’outil d’affichage de DuProprio permet d’identifier les résidences à vendre dans un secteur donné. Les SIG sont surtout de puissants outils pour visualiser et diffuser de l’information et sont de plus en plus utilisés pour faciliter la prise de décisions dans divers contextes. Nommons quelques exemples parmi les multiples domaines d’application des SIG : Logistique des transports : connaître l’état du réseau routier, les chantiers de construction, les accidents et le trafic, pour planifier des trajets ou des travaux futurs. Figure 1.9: Suivi de l’état du réseau routier par Transport Québec. Source: https://www.quebec511.info/fr/Carte/. Études sociodémographiques : cartographier des indices de défavorisation qui servent au gouvernement à répartir de façon équitable les ressources financières dédiées à l’éducation. Figure 1.10: Atlas de défavorisation du Ministère de l’Éducation et de l’Enseignement supérieur du Québec. Source: https://infogeo.education.gouv.qc.ca/public/Atlas_Defavorisation/. Évaluation des risques : identifier les risques d’inondation d’un secteur pour déterminer la couverture d’assurance requise pour une habitation. Figure 1.11: Cartographie interactive des zones inondables développée par le Ministère de l’Environnement et de la Lutte contre les changements climatiques du Québec. Source: https://geoinondations.gouv.qc.ca/. Gestion des risques : surveiller les risques journaliers d’incendies de forêt pour déterminer les mesures préventives à adopter et les ressources nécessaires pour assumer la suppression de feux. Figure 1.12: Cartographie des risques d’incendies de forêt mise à jour quotidiennement par la Société de protection des forêts contre le feu (https://sopfeu.qc.ca/cartes/). Source : image récupérée de https://www.rcinet.ca/. Gestion des ressources naturelles : cartographier la distribution des peuplements forestiers et leurs caractéristiques (composition essences, âge, sol, etc.) pour déterminer les futures récoltes de bois. Figure 1.13: Cartographie des peuplements forestiers et de leurs caractéristiques par le Ministère des Forêts, de la Faune et des Parcs du Québec. Source: https://www.foretouverte.gouv.qc.ca/. Évaluation foncière : représenter les limites géographiques des cadastres et identifier la valeur des terrains et des bâtiments pour projeter les revenus municipaux provenant des taxes municipales ou pour préparer une vente immobilière. Figure 1.14: Zonage et évaluation foncière de la municipalité de Mont-Laurier dans la MRC d’Antoine-Labelle (http://geo.mrc-antoine-labelle.qc.ca/sigimweb/). Géomarketing : mener une étude de marcher qui évaluera comment la clientèle visée par une entreprise ainsi que les entreprises concurrentes sont distribuées dans le secteur géographique convoité. Figure 1.15: Géomarketing pour les études de marché. Source : https://www.geopoint.pt/en/retalho/. La science des données La science des données est un domaine pluridisciplinaire qui regroupe les méthodes scientifiques et l’infrastructure permettant d’extraire les connaissances d’ensembles de données. La science des données utilisent notamment les approches d’intelligence artificielle (tels l’apprentissage automatique et l’apprentissage profond) ainsi que l’infonuagique (p. ex. les serveurs, le stockage de données, et les logiciels disponibles via internet) pour dégager des tendances au sein de données volumineuses ou complexes et ainsi solutionner des problèmes diverses. Les applications de la science des données se sont multipliées devant la disponibilité de données massives et le besoin de les analyser. Ces applications incluent maintenant des secteurs aussi variés que la santé, le commerce et l’astrophysique. Depuis les années 2010, nous observons une convergence entre la géomatique et la science des données. En effets, les concepts et les outils développer dans ces domaines traditionnellement distincts sont mis à profit afin de pouvoir gérer, analyser et visualiser un nombre de grandissant de données spatiales. L’augmentation fulgurante des données spatiales est associée à plusieurs avancées en technologie des capteurs et des communications (Lee and Kang 2015). Ces développements ont permis de diversifier les appareils capables d’acquérir des données géoréférencées et de produire des appareils accessibles à tous et mobiles (penser à vos téléphones cellulaires!). Ces développements ont également permis de connecter en réseau les capteurs de données, et d’accroître la précision des mesures ainsi que leur suivi en temps réel. Ces avancées technologiques ont donc suscité (et continuent de susciter) l’émergence de nouvelles applications reposant sur l’utilisation de données spatiales. Par exemple, les données de géolocalisation, et même les messages sur les médias sociaux peuvent faciliter le travail des gouvernements lorsqu’ils doivent fournir efficacement une aide appropriée suivant des évènements tels des accidents. Dans le contexte de la pandémie de COVID-19, les données sur la distribution des cas ont servis, entre autres, à prendre des décisions sur les règles de confinement à adopter selon le nombre de cas par régions. Figure 1.16: Carte illustrant la distribution des cas au Canada. Ce portail SIG est fourni par la compagnie ESRI Canada et est disponible sur le site suivant : https://ressouces-fr-covid19canada.hub.arcgis.com/. Dans ordre d’idées similaires, l’application Alerte COVID du gouvernement canadien, qui a pour objectif de limiter la propagation de la maladie, permet aux abonnés d’être informés si une tierce personne ayant reçu un résultat positif s’est trouvée dans leur proximité dans les 14 derniers jours. En environnement les applications des données spatiales sont nombreuses. Par exemple, les colliers-GPS portés par des mammifères permettent de mieux comprendre le déplacement des individus appartenant à une espèce menacée et ainsi de mieux protéger leur habitat3. Figure 1.17: Carte illustrant les migrations printanières et automnales de caribous de la sous-population de la Rivière-aux-Feuilles dans le Nord du Québec. Chaque ligne représente le déplacement d’un individu suivi par satellite. Ces données ont été acquises aux cours des années 2009-2011 dans le cadre du projet Caribou Ungava. Source : Caribou Ungava, Photo : Steeve Côté. Images récupérées le 10 décembre 2021 à https://www.canada.ca/fr/environnement-changement-climatique/services/registre-public-especes-peril/evaluations-rapports-situations-cosepac/caribou-certaines-populations-2017.html. Les observations par des professionnels ou même par des citoyens peuvent aussi servir à cartographier la présence d’animaux et aider à déterminer leurs aires de répartition. Par exemple, le programme ebird développé par le Cornell Lab of Ornithology et la National Aubudon Society consiste en une immense base de données d’observation d’oiseaux à travers le monde auxquelles tous peuvent contribuer en identifiant l’espèce, la localisation et le nombre d’individus repéré. En date de mai 2021, ebird contenait plus d’un milliard d’obervations d’oiseaux soumises par environ 700 mille participants4. Figure 1.18: Carte illustrant la distribution du Roitelet à triple-bandeau produite à partir des données d’observation de ebird. Le mauve indique les lieux où l’espèce est présente à l’année, le rouge, durant la période de reproduction, le bleu, durant les périodes de non-reproduction, le jaune durant les saisons de pré- et post-reproduction, et le gris les lieux d’absence ou d’observations rares. Source : https://ebird.org/science/status-and-trends/range-maps - Illustration © Hilary Burn/Lynx Edicions. Les services basés sur la géolocalisation aussi sont de plus en plus important dans notre économie. L’industrie du commerce de détails, de la restauration, du tourisme, et du transport profitent tous d’applications géo-dépendantes. Pensez par exemple à Uber, Dashdoor, Trip Advisor et même les applications de rencontre comme Tinder. De tels services permettent, entre autres, de signaler des offres aux consommateurs en fonction de leur position. De plus, les données spatiales peuvent servir à identifier des intérêts locaux pour certains produits et ainsi permettre aux entreprises d’améliorer l’efficacité de leur chaîne d’approvisionnement. Figure 1.19: Carte illustrant la position des consommateurs et le nombre de ventes d’une entreprise commerciale en Espagne. Carte tirée du site web de la compagnie Log-hub offrant des services basés sur l’analyse de données spatiales pour améliorer les chaînes d’approvisionnement. Source : https://log-hub.com/my-maps-platform/. Les utilisateurs des données spatiales se limitaient historiquement aux organismes gouvernementaux. Or, la multiplication des applications dans différents secteurs a augmenté le besoin pour des logiciels de visualisation et d’analyse de données spatiales et aussi pour une main d’œuvre qualifiée capable d’opérer ces outils. 1.1.2 Les outils et logiciels de visualisation et d’analyse géo-spatiale Dans le cadre de ce cours, nous utiliserons le logiciel et langage de programmation R pour réaliser des tâches de visualisation et d’analyse de données spatiales. Or, il existe plusieurs autres logiciels et il est important de savoir où R se situe par rapport aux autres options disponibles dans ce paysage géo-spatial5. Les logiciels commerciaux Il existe plusieurs logiciels commerciaux de géomatique. Ces logiciels sont relativement dispendieux et généralement seulement les entreprises qui offrent des services spécialisés en géomatique ou les ministères, certaines villes et les universités peuvent se procurer ces licences. ArcGIS : est la plateforme principale de la compagnie ESRI (Environmental Systems Research Institute). Créée en 1999 sous le nom ArcMap, cette application est maintenant vendue sous le nom ArcGIS Pro. ESRI offre également d’autres plateformes dont ArcGIS Online, un logiciel de cartographie web, et ArcGIS Developer pour les développeurs. MapInfo: est la plateforme de la compagnie Precisely (autrefois Pitney Bowes Software et MapInfo Corporation). Créée en 1995, c’est une des premières plateformes à avoir vu le jour. Hexagon Geospatial Power Portfolio: est une plateforme qui comprend divers outils géo-spatiaux dont ERDAS reconnu pour la manipulation d’images de télédétection. Manifold: est une plateforme qui se démarque par sa rapidité de par son utilisation de traitements en parallèle et GPU. Les logiciels libres d’accès Il existe une offre de plus en plus intéressante de logiciels libres d’accès. La Fondation Open Source Geospatial (OSGeo), une organisation non-gouvernementale fondée en 2006, a pour objectif de soutenir et promouvoir le développement de codes et de logiciels libres en géomatique. Elle chapeaute plusieurs projets comme des bibliothèques spécialisées, des applications SIG mobiles ou bureautiques, et des applications pour la gestion de données spatiales. Voici quelques exemples : QGIS: est une application SIG gratuite et de source libre. Elle est écrite en Python mais possède plusieurs interfaces écrite en R, dont RQGIS. GRASS GIS: est un des projets fondateurs de l’OSGeo qu’on appelle communément GRASS (Geographic Resources Analysis Support System). Cette application libre permet la gestion, le traitement, l’analyse et la visualisation de données spatiales, ainsi que le traitement d’images et la modélisation. Elle est utilisée par des entreprises commerciales et dans les milieux universitaires et gouvernementaux. GDAL: pour Geospatial Data Abstraction Library est une bibliothèque qui permet de lire des données spatiales en formats vectoriel et matriciel6. Plusieurs logiciels, libres et commerciaux, utilisent cette bibliothèque dont QGIS, GRASS GIS, ArcGIS, Google Earth et aussi R. PostGIS: est une extension pour les données spatiales de PostgreSQL, un système de source libre pour la gestion de base de données relationnelle et objet. Les services d’infonuagique Les services infonuagiques sont des services de stockage et de traitement de données externalisés sur des serveurs distants auxquels les utilisatrices et les utilisateurs peuvent accéder via internet. Google Earth Engine: est une plateforme de calcul infonuagique de Google qui permet le traitement de données géo-spatiales. Celle-ci donne accès à un large catalogue d’images satellitaires (p. ex. de Landsat et Sentinel-2) et à la puissance de calcul requise pour les analyser. Google Earth Engine permet ainsi d’explorer les changements sur la surface de la Terre à l’échelle planétaire. Il a été utilisé pour visualiser l’évolution de diverses problématiques environnementales comme la perte de couvert forestier. Google Earth Engine est gratuit pour des utilisations académiques et de recherche et une version payante existe pour les utilisations commerciales. Une interface de programmation existe également pour les développeurs, Earth Engine API. ArcGIS Online: est la plateforme web d’ArcGIS, le logiciel commercial présenté plus haut. Cette plateforme donne accès à des milliers de cartes. PanGEO: est une plateforme de source libre, et collaborative, pour le développement d’applications pour les analyses géo-spatiales à grande échelle. Sepal: est une plateforme gratuite pour l’analyse d’images satellitaires qui repose sur Google Earth Engine et des logiciels de source libre comme Python, R. Sepal est un multiples outils qu’offre OpenForis, un projet conçu par la FAO (Organisation des Nations Unis pour l’alimentation et l’agriculture) pour permettre aux pays de faire le suivi de leurs ressources naturelles. Kepler: est également une plateforme de source libre pour les analyse géo-spatiales à grande échelle. Elle est supportée par la compagnie Uber. Planet: est une plateforme commerciale pour les analyses géo-spatiales. Les langages de programmation pour l’analyse géospatiale La majorité des logiciels d’information géographique reposent sur des interfaces graphiques élaborées où les outils et les fonctions sont accessibles par des menus et des boutons. Or, le mode « pointer-cliquer» de ces interfaces n’est pas idéal lorsqu’on veut s’assurer que nos analyses soient facilement reproductibles – un aspect crucial de la recherche scientifique est en effet la reproductibilité. C’est pour cette raison que l’utilisation de langages de programmation pour réaliser des analyses et des visualisations de données spatiales est bénéfique et de plus en plus populaire. L’utilisation de lignes de commandes plutôt que d’interfaces graphiques permet également d’automatiser des tâches que l’on désire répéter plusieurs fois dans une analyse ou encore de réutiliser des blocs de code dans différents projets. De plus, un code se partage facilement et peut être ainsi amélioré par d’autres contributeurs ou contributrices. Il existe plusieurs bibliothèques géo-spatiales dans les langages de programmation à usage général comme C++ et Java. Cependant, la courbe d’apprentissage est grande pour ces langages et les efforts requis sont disproportionnés pour les usagers qui comptent utiliser leurs fonctionnalités de façon limitée seulement. En revanche, les langages interprétés7, comme R et Python, sont beaucoup plus simples à apprendre et à utiliser. Ces deux langages possèdent maintenant leur propre ensemble de bibliothèques d’analyse et de visualisation de données spatiales. Ce site documente les bibliothèques utiles en Python. Dans le cadre de ce cours, nous utiliserons R en combinaison avec RStudio qui est un environnement de développement (en anglais « integrated development environment », IDE). L’interface RStudio facilite et rend convivial l’utilisation de R. Elle permet, entre autre, de créer des fichiers de code d’extension .R ou .Rmd que vous pouvez réutiliser et modifier. 1.1.3 Les bibliothèques géo-spatiales de R Il existe un nombre important de bibliothèques R (« packages » en anglais) qui se concentrent sur différents aspects de la manipulation, de l’analyse et de la visualisation de données spatiales. D’autres bibliothèques plus générales, comme base R et ggplot2 peuvent aussi être utilisées sur des données spatiales pour accomplir certaines fonctions. La communauté R est très active, de nouvelles bibliothèques sont régulièrement offertes alors les bibliothèques existantes sont mises à jour et améliorer constamment. Ceci est également vrai pour la « communauté R spatiale ». R étant un projet ouvert, tout le monde peut créer des bibliothèques, ou signalez des problèmes afin d’améliorer des bibliothèques existantes. Vous aussi! Vous trouverez sur le site de CRAN (The Comprehensive R Archive Network) une page dédiée aux bibliothèques R pour l’analyse géo-spatiale. Voici quelques bibliothèques importantes que nous utiliserons dans ce cours : sf: bibliothèque incontournable offrant de nombreuses fonctions pour lire et manipuler des objets spatiaux vectoriels de différentes classes. sf est relativement récente et est venue remplacer les bibliothèques sp, rgeos et les parties vectorielles de rdgal. raster: bibliothèque offrant de nombreuses fonctions pour lire et manipuler des objets spatiaux matriciels. Notez que la bibliothèque terra remplacera peut-être raster dans les années à venir. spacetime: bibliothèque offrant des fonctions pour manipuler des objets spatiaux-temporels. mapview: bibliothèque offrant des fonctions pour visualiser rapidement et de façon interactives des données spatiales. tmap : bibliothèque offrant des fonctions plus flexibles pour visualiser des données spatiales. Elle utilise un style qui s’apparente à ggplot2. 1.1.4 La pensée géographique Définition donnée par le Département des sciences géomatiques de l’Université Laval - https://www.scg.ulaval.ca/la-geomatique-cest-quoi, consultée le 11 novembre 2021↩︎ Allez jeter un coup d’œil au projet Voyageur Wolf Project, qui suit le déplacement de loups dans le nord du Minnesota grâce à des colliers GPS. On peut y voir des animations démontrant le déplacement d’individus de différentes meutes.↩︎ Source: https://ebird.org/news/global-big-day-2021-reaches-new-heights.↩︎ Le contenu de cette sous-section est adapté du cours Introduction to Geospatial Concepts : The Geospatial Landscape (Wasser et al., n.d.) de l’organisme Data Carpentry. Data Carpentry développe et offre des formations variées et spécialisées sur le traitement et l’analyse de données. Ses formations s’adressent surtout aux chercheuses et chercheurs scientifiques, mais peuvent être consultées par quiconque car leur matériel est libre d’accès. N’hésitez donc pas à y jeter un coup d’œil.↩︎ Nous verrons les concepts de données vectorielles et matricielles au Module 2 portant sur les Modèles de données spatiales.↩︎ Un langage de programmation interprété est un langage qui fait l’interprétation du code directement au moment de l’exécution sans exiger que l’utilisateur ou l’utilisatrice le compile préalablement. Allez voir cet article de Wikipédia pour en connaître davantage.↩︎ "],["ex_intro.html", "1.2 Exercices", " 1.2 Exercices Le cours SCI 1031 est dédié à l’apprentissage des bibliothèques et des fonctions pour manipuler, visualiser et analyser des données spatiales. Il est donc important de vous assurer de posséder les acquis de base en R pour poursuivre votre apprentissage vers des notions plus complexes. Cette section est divisée en trois parties. Dans la partie Démarrage vous apprendrez à installer R et RStudio et vous vous familiariserez avec les notions importantes de l’environnement de travail R. Dans la partie Intro à R vous réviserez les concepts et les fonctions de base pour utiliser R. Finalement, dans la partie À vous de jouer!, vous réaliserez un exercice pour mettre en pratique les concepts enseignés. Une grande partie du contenu de cette section est tiré du livre numérique An Introduction to R (Douglas et al. 2022). 1.2.1 Démarrage Installer R Nous possédez déjà R sur votre ordinateur? Nous recommandons tout de même d’installer la plus récente version afin d’avoir la version la plus à jour pour être compatible avec les bibliothèques qui seront utilisées dans le cours. Windows Aller sur le site CRAN et cliquer sur le lien Download R for Windows Cliquer maintenant sur install R for the first time Cliquer sur Download R (numéro de la version) for Windows pour télécharger le fichier *.exe Exécuter le fichier *.exe MacOS Aller sur le site CRAN et cliquer sur le lien Download R for macOS Cliquer sur le lien compatible avec votre système d’opération pour télécharger le fichier *.pkg Double-cliquer sur le fichier *.pkg Installer RStudio Vous avez déjà RStudio? Assurez-vous d’avoir la dernière version: Dans la barre horizontale de votre interface RStudio, aller dans le menu déroulant Help Sélectionner l’option Check for Updates Si vous n’avez pas la version la plus à jour, celle-ci vous sera proposée. Vous n’avez pas RStudio? Aller sur la page de téléchargement de RStudio Télécharger et exécuter le fichier qui correspond à votre système d’opération, c’est-à-dire *.exe pour Windows et *.dmg pour macOS. Vous utilisez une autre plateforme que RStudio ? Si vous préférez vraiment un autre environnement de développement que RStudio, vous pouvez bien sûr l’utiliser. Aucun apprentissage dans ce cours est dépendant de RStudio. Toutefois, si, en cours de route, vous avez des questions liées à l’environnement que vous avez choisi d’utiliser, il n’est pas certain que la personne qui vous encadre sera en mesure de vous aider. Apprivoiser RStudio Lorsque vous ouvrez RStudio pour la première fois, vous devriez voir une interface semblable à celle-ci (peut varier selon votre système d’exploitation): Figure 1.20: Interface RStudio. Source : Douglas et al. (2022) An introduction to R: RStudio orientation. La grande fenête à gauche est la console R. Vous pouvez y écrire des commandes R à éxécuter. La fenêtre supérieure à droite contient les onglets Environment / History / Connections: Environment: contient les objets que vous avez créé ou chargez dans votre session R. History: contient la liste des commandes que vous avez entrées dans la console `R. Cette fenêtre peut être utile pour retrouver des commandes que vous avez précédemment utilisées. Connections: permet de se connecter à d’autres sources de données. La fenêtre inférieur droite contient les onglets Files / Plots / Packages / Help / Viewer: Files: contient la liste de tous les fichiers et les répertoires qui sont dans votre répertoire de travail (working directory) sur votre ordinateur. Plots: contient toutes les figures crées au cours de votre session R. Vous pouvez agrandir la figure (Zoom) et la sauvegarder dans le format de votre choix (Export). Packages: contient la liste de toutes les bibliothèques installées sur votre ordinateur. À partir de cet onglet vous pouvez installer des nouvelles bibliothèques ou mettre à jour vos bibliothèques actuelles en cliquant sur les boutons Install et Update respectivement. Help: présente la documentation R pour une fonction recherchée. Viewer: affiche des graphiques web générés par certaines bibliothèques. Vous pouvez personnaliser votre inferface RStudio de multiples façons. Par exemple aller dans le menu déroulant Tool au haut de l’écran et sélectionner Global Options/Appearance pour changer les couleurs de l’écran et du lettrage. Vous n’allez quand même pas garder cet écran blanc et cette écriture monochrome pendant les 15 semaines de cours ?! Créer un fichier R Bien qu’il soit possible d’utiliser R en rédigeant des commandes dans la console, une meilleure habitude de travail consiste à créer un fichier R (c-à-d un fichier d’extension *.R) qui contient une série de commandes successives à exécuter. Un fichier R permet de conserver les commandes. Ainsi, vous pourrez répéter les commandes d’une session à une autre sans devoir les retaper dans la console. Un tel fichier permet également d’ajouter des commentaires pour préciser les opérations réalisées. Finalement, un fichier R permet de partager facilement son code avec autrui. Au cours de votre cheminement, si vous avez des questions ou des problèmes avec du code R, joignez un fichier R dans un courriel à la personne qui vous encadre. Il sera ainsi beaucoup plus facile de vous aider. Pour créer un fichier R, aller dans le menu déroulant File au haut de l’écran et sélectionner New File/R Script: Figure 1.21: Créer un fichier R. Source : Douglas et al. (2022) An introduction to R: RStudio orientation. Remarquer qu’une nouvelle fenêtre s’ouvre en haut à gauche de l’écran (appelée le panneau Source) et que la console se trouve maintenant en bas à gauche. Pour exécuter une ligne de code dans un fichier R, vous n’avez qu’à placer votre curseur sur la ligne désirée et cliquer sur le bouton Run. Le résultat apparaitra dans la console. Vous pouvez également utiliser le raccourci ctrl + enter sous Windows ou cmd + enter sous Mac au lieu de cliquer sur Run. Pour exécuter l’ensemble des commandes contenues dans un fichier, cliquer sur Source. Figure 1.22: Utiliser un fichier R. Source : Douglas et al. (2022) An introduction to R: RStudio orientation. Sauvegarder un fichier R en lui donnant un nom qui a du sens. Ce nom doit être sans accent et sans espace Les bibliothèques Une bibliothèque R, appellée “package” en anglais, est un ensemble de fonctions spécialisées créées par des experts ou des expertes dans un champ d’analyse précis. Pour installer une bibliothèque dans R à même la console, il faut utiliser la fonction install.packages(). Par exemple, la ligne de commande suivante installe la bibliothèque mapview: install.packages(&quot;mapview&quot;) Pour charger une bibliothèque dans une session R, il faut utiliser la fonction library(). Par exemple, vous pouvez écrire la commande suivante dans la console ou encore dans un fichier R: library(mapview) Il faut charger une bibliothèque à toute nouvelle session R. Le répertoire de travail Le répertoire de travail (working directory en anglais) est le dossier par défaut dans lequel R cherche les fichiers que vous téléchargerez au cours de votre session et dans lequel R inscrit tout fichier que vous sauvegarderez. Pour choisir un répertoire, aller dans le menu déroulant Session au haut de l’écran et sélectionner Set Working Directory/Choose Directory …. Pour connaitre le répertoire de travail courrant, entrer la commande getwd() dans la console. Pour choisir un autre répertoire, il s’agit d’utiliser le commande setwd() en identifiant le chemin (path) vers le répertoire désiré: setwd(&quot;C:/Users/Elise/TELUQ/SCI1031/Module4/Module4_Donnees&quot;) Vous pouvez ainsi écrire cette ligne de commande au début d’un fichier R pour préciser à R le répertoire de travail auquel le code contenu dans le fichier se rapporte. Toutefois, ce chemin est absolu. C’est-à-dire qu’il est propre à votre ordinateur seulement et à la façon dont vous avez structuré vos dossiers. Dans la perspective où vous serez amené à partager des fichiers de code R, il est préférable d’utiliser un chemin relatif. C’est-à-dire un chemin qui pointe vers un répertoire commun aux personnes qui utiliseront le même code. Dans le cours, les lignes de code vous invitant à lire des fichiers de données utiliseront toujours un chemin relatif. Par exemple: donnees &lt;- read.table(&quot;/Module4_Donnees/nz_capitales.csv&quot;, header = TRUE, sep = &quot;,&quot;) Ce sera donc à vous de bien régler votre répertoire de travail afin que R trouve le dossier commun (Module4_Donnees pour le présent exemple). 1.2.2 Intro à R La base L’utilisation la plus simple qu’on peut faire de R est celle d’un calculateur. R exécute des opérations arithmétiques et une foule de fonctions mathématiques. Par exemple, # addition 2 + 2 [1] 4 # multiplication 2 * 8 [1] 16 # R suit les conventions pour la priorité des opérations 2 * 8 - 2 [1] 14 2 * (8 - 2) [1] 12 # Le logarithme en base 2 log(2) [1] 0.6931 # Le logarithme en base 10 log10(2) [1] 0.301 # Le carré ou autres puissances 2^2 [1] 4 3^8 [1] 6561 # La racine carrée sqrt(16) [1] 4 # pi pi [1] 3.142 Les objets Un objet en R est n’importe quelle entrée à laquelle on assigne un nom en utilisant l’opérateur d’assignation &lt;- . Par exemple, mon_objet &lt;- 10 Un objet peut être un chiffre, un vecteur, une chaine de caractères, ou même une structure plus complexe comme un graphique. Tout objet créé au cours d’une session R est affiché dans l’onglet Environment de la fenêtre supérieure droite de l’interface RStudio. Un objet est logé dans la mémoire vive et vous pouvez l’utiliser pour des opérations futures. obj1 &lt;- &quot;J&#39;aime le cours&quot; obj2 &lt;- &quot;SCI 1031&quot; paste(obj1, obj2) [1] &quot;J&#39;aime le cours SCI 1031&quot; Les catégories de données Dans le cadre de ce cours nous utiliserons quatre principales catégories ou classes de données supportées par R: Numérique (numeric en anglais) est un nombre décimal ou un nombre entier. obj_num &lt;- 10.3 Entier (integer): un nombre entier. Une donnée de catégorie entier ne peux jamais être décimale. Nous devons utiliser la fonction as.integer() pour créer un entier, sans quoi R lui attribuera la catégorie numérique. obj_ent &lt;- as.integer(10) Logique (logical): une donnée qui prend la valeur vrai (TRUE) ou faux (FALSE), ou encore la valeur NA lorsque la valeur d’une donnée est manquante. obj_log &lt;- FALSE Caractère (character): une chaine de un ou plusieurs caractères. obj_car &lt;- &quot;Yo!&quot; Nous utiliserons également une catégorie particulière de données de type caractère qu’on appelle des facteurs (factor). Les facteurs désignent des données catégoriques qui possèdent un ensemble connu de valeurs possibles (niveaux - levels). Nous créons des données de type facteur avec la fonction factor(): obj_fac &lt;- factor(c(&quot;Faible&quot;, &quot;Modéré&quot;, &quot;Élevé&quot;)) obj_fac [1] Faible Modéré Élevé Levels: Élevé Faible Modéré La fonction class() permet de connaitre la catégorie d’une données. class(obj_num) [1] &quot;numeric&quot; class(obj_ent) [1] &quot;integer&quot; class(obj_log) [1] &quot;logical&quot; class(obj_car) [1] &quot;character&quot; class(obj_fac) [1] &quot;factor&quot; Les fonctions is.[nom de la catégorie]() retournent la valeur TRUE si l’objet interrogé appartient à la catégorie précisée et FALSE autrement. is.integer(obj_num) [1] FALSE is.integer(obj_ent) [1] TRUE is.character(obj_log) [1] FALSE Il est parfois utile de changer la classe d’un objet en utilisant la fonction is.[nom de la catégorie](). # FALSE devient &quot;FALSE&quot; as.character(obj_log) [1] &quot;FALSE&quot; # FALSE devient 0 as.numeric(obj_log) [1] 0 # 10.3 devient 10 as.integer(obj_num) [1] 10 Les structures de données En plus de différentes catégories, il existe différentes structures de données. Les scalaires et les vecteurs Un vecteur est une séquence de données de même catégorie. Nous définissons un vecteur par l’expression c(,) où la virgule sépare les éléments de la séquence. # Un vecteur de catégorie numérique vec_num &lt;- c(9, 11, 4, 5) # Un vecteur de catégorie caractère vec_car &lt;- c(&quot;bleu&quot;, &quot;vert&quot;, &quot;rouge&quot;) Un vecteur ne peut contenir des données de différentes catégories à l’exception d’une donnée de valeur NA qui est de catégorie logique et qui désigne l’absence de données. # R converti les nombres en caractère pour que les éléments # soient de même catégorie vec_mix &lt;- c(9, 2, &quot;bleu&quot;) vec_mix [1] &quot;9&quot; &quot;2&quot; &quot;bleu&quot; # NA conserve la catégorie des autres éléments vec_numNA &lt;- c(9, 2, NA) vec_numNA [1] 9 2 NA vec_carNA &lt;- c(&quot;bleu&quot;, NA, &quot;rouge&quot;) vec_carNA [1] &quot;bleu&quot; NA &quot;rouge&quot; La fonction length() donne le nombre d’éléments contenu dans un vecteur. length(vec_num) [1] 4 length(vec_car) [1] 3 Une donnée scalaire est un vecteur de longueur 1. sca &lt;- 3833 length(sca) [1] 1 Pour accéder à des éléments particuliers d’un vecteur, nous utilisons l’expression []. a &lt;- c( 38, 33, 45, 26) # Le premier élément a[1] [1] 38 # Le troisième élément a[3] [1] 45 # Le premier et le troisième a[c(1,3)] [1] 38 45 Figure 1.23: Représentation d’un scalaire et d’un vecteur. Source : Douglas et al. (2022) An introduction to R: Data structures. Les matrices et les arrays Une matrice est simplement un vecteur de deux dimensions, tandis qu’un array est une matrice pouvant avoir plus de deux dimensions. Tout comme un vecteur, une matrice et un array sont formés de données d’une même classe. Figure 1.24: Représentation d’une matrice et d’un array. Source : Douglas et al. (2022) An introduction to R: Data structures. Nous pouvons créer une matrice avec la fonction matrix(). Dans l’exemple ci-dessous les données de 1 à 12 sont structurées dans une matrice de 4 rangées qui est remplie en suivant les rangées. mat_ex1 &lt;- matrix(1:12, nrow = 4, byrow = TRUE) mat_ex1 [,1] [,2] [,3] [1,] 1 2 3 [2,] 4 5 6 [3,] 7 8 9 [4,] 10 11 12 Une matrice de structure différente mais avec les mêmes éléments. mat_ex2 &lt;- matrix(1:12, nrow = 2) mat_ex2 [,1] [,2] [,3] [,4] [,5] [,6] [1,] 1 3 5 7 9 11 [2,] 2 4 6 8 10 12 Remarquer que dans cet exemple, la matrice est remplie suivant les colonnes. Nous pouvons aussi créer une matrice en combinant des vecteurs. vec1 &lt;- 1:6 vec2 &lt;- 7:12 # combinaison le long des colonnes mat_ex3 &lt;- cbind(vec1, vec2) mat_ex3 vec1 vec2 [1,] 1 7 [2,] 2 8 [3,] 3 9 [4,] 4 10 [5,] 5 11 [6,] 6 12 # combinaison le long des rangées mat_ex4 &lt;- rbind(vec1, vec2) mat_ex4 [,1] [,2] [,3] [,4] [,5] [,6] vec1 1 2 3 4 5 6 vec2 7 8 9 10 11 12 Pour créer un array, nous pouvons utiliser la fonction array() et définir ces dimensions avec l’argument dim. array_ex1 &lt;- array(1:16, dim = c(2,4,2)) array_ex1 , , 1 [,1] [,2] [,3] [,4] [1,] 1 3 5 7 [2,] 2 4 6 8 , , 2 [,1] [,2] [,3] [,4] [1,] 9 11 13 15 [2,] 10 12 14 16 Cet array est constitué de deux matrices, chacune possédant 2 rangées et 4 colonnes. La dimension d’une matrice ou d’un array se calcule avec la fonction dim(): dim(mat_ex1) [1] 4 3 dim(array_ex1) [1] 2 4 2 Il est parfois utile d’attribuer des noms aux colonnes et aux rangées d’une matrice ou d’un array. Ceci est possible avec les fonctions colnames() et rownames(): colnames(mat_ex1) &lt;- c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;) rownames(mat_ex1) &lt;- c(&quot;alpha&quot;, &quot;beta&quot;, &quot;gamma&quot;, &quot;delta&quot;) mat_ex1 A B C alpha 1 2 3 beta 4 5 6 gamma 7 8 9 delta 10 11 12 Pour accéder à un élément particulier d’une matrice ou d’un array nous utilisons toujours l’expression [] mais cette fois la position de l’élément dans chaque dimension doit être précisée: # élément à la ligne 1, colonne 2 mat_ex1[1,2] [1] 2 # élément à la ligne 2, colonne 1, 2e matrice array_ex1[2,1,2] [1] 10 Les listes Une liste est un objet pouvant héberger des données de différentes classes. En fait, une liste peut également héberger des données de différentes structures. Nous définissons une liste par la fonction list() où chaque objet de la liste est séparé par une virgule. Voici un exemple: list_ex1 &lt;- list( matrix(1:6, nrow = 3), c(&quot;bleu&quot;, &quot;vert&quot;, &quot;rouge&quot;), c(FALSE, TRUE, FALSE, TRUE, FALSE)) list_ex1 [[1]] [,1] [,2] [1,] 1 4 [2,] 2 5 [3,] 3 6 [[2]] [1] &quot;bleu&quot; &quot;vert&quot; &quot;rouge&quot; [[3]] [1] FALSE TRUE FALSE TRUE FALSE Nous pouvons assigner des noms à chaque objet de la liste en utilisant la fonction names(): names(list_ex1) &lt;- c(&quot;quantite&quot;, &quot;couleur&quot;, &quot;resultat&quot;) list_ex1 $quantite [,1] [,2] [1,] 1 4 [2,] 2 5 [3,] 3 6 $couleur [1] &quot;bleu&quot; &quot;vert&quot; &quot;rouge&quot; $resultat [1] FALSE TRUE FALSE TRUE FALSE Ou encore au moment de définir la liste: list_ex2 &lt;- list( frequence = matrix(1:6, nrow = 3), saveur = c(&quot;bleu&quot;, &quot;vert&quot;, &quot;rouge&quot;), verification = c(FALSE, TRUE, FALSE, TRUE, FALSE)) list_ex2 $frequence [,1] [,2] [1,] 1 4 [2,] 2 5 [3,] 3 6 $saveur [1] &quot;bleu&quot; &quot;vert&quot; &quot;rouge&quot; $verification [1] FALSE TRUE FALSE TRUE FALSE Pour accéder à un objet de la liste, nous devons utiliser l’expression [[]], ou encore son nom précédé du symbole $. # Premier objet list_ex1[[1]] [,1] [,2] [1,] 1 4 [2,] 2 5 [3,] 3 6 # objet couleur list_ex1$couleur [1] &quot;bleu&quot; &quot;vert&quot; &quot;rouge&quot; Pour accéder à un élément particulier de la liste, il faut d’abord préciser sa position dans la liste, puis sa position dans l’objet. # Element sur la 3e ligne, 2e colonne du premier objet list_ex1[[1]][3,2] [1] 6 # Element 2 de l&#39;objet couleur list_ex1$couleur[2] [1] &quot;vert&quot; Les data frames Un data frame est un tableau de données à deux dimensions, semblable à une matrice, mais pouvant contenir des données de différentes classes. Généralement chaque ligne du tableau correspond à une observation et chaque colonne à une variable mesurée. Les data frames sont similaires à un tableau Excel. Ils peuvent aussi être perçus comme une combinaison de vecteurs de même longueur. Nous pouvons créer un data frame en utisant la fonction data.frame(): tab_ex1 &lt;- data.frame(voiture = 1:5, marque = c(&quot;Hyundai&quot;, &quot;Ford&quot;, &quot;Toyota&quot;, &quot;Hyundai&quot;, &quot;Subaru&quot;), couleur = c(&quot;Gris&quot;, &quot;Rouge&quot;, &quot;Bleu&quot;, &quot;Noir&quot;, &quot;Gris&quot;)) tab_ex1 voiture marque couleur 1 1 Hyundai Gris 2 2 Ford Rouge 3 3 Toyota Bleu 4 4 Hyundai Noir 5 5 Subaru Gris Ou encore: nom &lt;- c(&quot;Price&quot;, &quot;Suzuki&quot;, &quot;Gallagher&quot;, &quot;Caufield&quot;, &quot;Hoffman&quot;, &quot;Dvorak&quot;, &quot;Romanov&quot;) prenom &lt;- c(&quot;Carey&quot;, &quot;Nick&quot;, &quot;Brendan&quot;, &quot;Cole&quot;, &quot;Mike&quot;, &quot;Christian&quot;,&quot;Alexander&quot;) numero &lt;- c(&quot;31&quot;,&quot;14&quot;,&quot;11&quot;,&quot;22&quot;,&quot;68&quot;,&quot;28&quot;,&quot;27&quot;) age &lt;- c(34,22,29,21, 32, 26, 22) position &lt;- factor(c(&quot;Gardien&quot;, &quot;Centre&quot;, &quot;Ailier droit&quot;, &quot;Ailier droit&quot;, &quot;Centre&quot;,&quot;Ailier gauche&quot;, &quot;Défenseur droit&quot; )) buts &lt;- c(NA, 19, 6,22, 11, 10, 3) tab_ex2 &lt;- data.frame(nom, prenom, numero, age, position, buts) tab_ex2 nom prenom numero age position buts 1 Price Carey 31 34 Gardien NA 2 Suzuki Nick 14 22 Centre 19 3 Gallagher Brendan 11 29 Ailier droit 6 4 Caufield Cole 22 21 Ailier droit 22 5 Hoffman Mike 68 32 Centre 11 6 Dvorak Christian 28 26 Ailier gauche 10 7 Romanov Alexander 27 22 Défenseur droit 3 Nous pouvons accéder à une colonne particulière d’un data frame en utilisant l’expression [, n] où n est la position de la colonne ou en utilisant le nom de la colonne précédé du symbole $: tab_ex2[,3] [1] &quot;31&quot; &quot;14&quot; &quot;11&quot; &quot;22&quot; &quot;68&quot; &quot;28&quot; &quot;27&quot; tab_ex2$numero [1] &quot;31&quot; &quot;14&quot; &quot;11&quot; &quot;22&quot; &quot;68&quot; &quot;28&quot; &quot;27&quot; Pour accéder à une ligne particulière d’un data frame, nous pouvons utiliser l’expression [m, ] où m est la position de la ligne tab_ex2[4,] nom prenom numero age position buts 4 Caufield Cole 22 21 Ailier droit 22 La fonction str() donne un résumé de la structure d’un data frame (le nom des variables, la classe des données, et leur valeur): str(tab_ex2) &#39;data.frame&#39;: 7 obs. of 6 variables: $ nom : chr &quot;Price&quot; &quot;Suzuki&quot; &quot;Gallagher&quot; &quot;Caufield&quot; ... $ prenom : chr &quot;Carey&quot; &quot;Nick&quot; &quot;Brendan&quot; &quot;Cole&quot; ... $ numero : chr &quot;31&quot; &quot;14&quot; &quot;11&quot; &quot;22&quot; ... $ age : num 34 22 29 21 32 26 22 $ position: Factor w/ 5 levels &quot;Ailier droit&quot;,..: 5 3 1 1 3 2 4 $ buts : num NA 19 6 22 11 10 3 Parfois les data frame peuvent contenir beaucoup de variables et d’observations. Dans ces situations, il peut être utile d’utiliser les fonctions head() ou tail() qui retournent les 5 premières et les 5 dernières lignes du tableau respectivement. head(tab_ex2) nom prenom numero age position buts 1 Price Carey 31 34 Gardien NA 2 Suzuki Nick 14 22 Centre 19 3 Gallagher Brendan 11 29 Ailier droit 6 4 Caufield Cole 22 21 Ailier droit 22 5 Hoffman Mike 68 32 Centre 11 6 Dvorak Christian 28 26 Ailier gauche 10 Importer et exporter des données Importer des données Dans le cadre de ce cours, vous serez amené à importer des fichiers de données en format *.txt ou *.csv. Ces deux formats peuvent être importés en utilisant la fonction read.table(). Tableau &lt;- read.table(file = &quot;NomDuFichier.txt&quot;, header = TRUE, sep = &quot;\\t&quot;, dec = &quot;,&quot;, na.string = &quot;S/O&quot;, stringsAsFactors = TRUE) La fonction read.table() peut comprendre plusieurs arguments. Entre autres: file =, indique le nom du fichier à importer. header = TRUE ou FALSE précise si on importe ou non le nom des colonnes. sep = \"\\t\" ou \",\" ou \"\" précise comment les données sont séparées dans le fichier d’origine (où \\t désigne la touche de tabulation (tab)). dec = \",\" ou \".\" précise comment la décimale est représentée dans le fichier d’orgine (p. ex. en français nous utilisons la virgule). na.string = précise le symbole utilisé pour désigner les valeurs NA (p.ex. en français nous utilisons souvent l’expression “S/O” qui signifie sans objet) stringsAsFactors = TRUE ou FALSE précise si les données de classe caractère sont importées en classe facteur. D’autres fonctions similaires facilitent l’importation de fichiers *.csv. Ces fonctions sont des variantes de la fonction read.table() qui incluent certaines combinaisons d’arguments par défaut. # Importer un fichier csv Tableau &lt;- read.csv(file = &quot;NomDuFichier.csv&quot;) # Importer un fichier csv avec dec = &quot;,&quot; et sep = &quot;;&quot; Tableau &lt;- read.csv2(file = &quot;NomDuFichier.csv&quot;) # Importer un fichier avec sep = &quot;\\t&quot; Tableau &lt;- read.delim(file = &quot;NomDuFichier.txt&quot;) Dans les modules futurs, nous verrons les fonctions R permettant d’importer des fichiers de données spatiales de différents formats. Exporter des données Similairement à la fonction read.table() pour lire les données, R dispose de la fonction write.table() pour exporter des données. Par exemple, nous pouvons exporter le data frame tab_ex2 dans un fichier *.txt: write.table(tab_ex2, file = &quot;JoueursCanadiens.txt&quot;, col.names = TRUE, row.names = FALSE, sep = &quot;\\t&quot;) Ou en format *.csv: write.table(tab_ex2, file = &quot;JoueursCanadiens.csv&quot;, col.names = TRUE, row.names = FALSE, sep = &quot;,&quot;) Nous pouvons également utiliser la fonction write.csv() pour exporter les données en format *csv write.csv(tab_ex1, file = &quot;voitures.csv&quot;, row.names = FALSE) Dans ce cas, il n’est pas nécessaire les arguments col.names = TRUE et sep = \",\" sont pris par défaut, et il n’est donc pas nécessaire de les préciser. Graphiques de base Diagramme de dispersion Nous utilisons la fonction plot() pour représenter une variable y en fonction d’une variable x: x &lt;- 1:10 y &lt;- x^2 plot(x,y) Il est possible d’ajouter des arguments pour préciser: le nom des axes: xlab et ylab les limites des axes: xlim et ylim le titre: main la façon de lier les points: type l’épaisseur du trait: lwd le style du trait: lty le style des points: pch la taille des points: cex la couleur des points: col et autres! Figure 1.25: Quelques arguments de la fonction plot() et les valeurs possibles. Source : The R Graph Gallery. Personnalisons le graphique précédent en ajoutant des arguments: plot(x,y, main = &quot;Croissance incroyable de ma plante&quot;, xlab = &quot;Jours&quot;, ylab = &quot;Taille (cm)&quot;, cex.lab = 1.5, xlim = c(0, 12), ylim = c(0, 120), type = &quot;b&quot;, lty = 3, lwd = 1, pch = 16, col = &quot;blue&quot;, cex = 0.9) 1.2.2.0.1 Histogramme Nous utilisons la fonction hist() pour produire un histogramme qui illustre le nombre ou la fréquence d’observation qui ont une certaines valeurs. # générer 20 nombres aléatoires à partir d&#39;une # distribution normale de moyenne 20 et de distribution standard 5 x &lt;- rnorm(100, mean = 20, sd = 5) # histogramme hist(x) Comme pour la fonction plot(), nous pouvons améliorer l’apparence de l’histogramme par l’ajout d’arguments. hist(x, breaks = 10, main = &quot;&quot;, xlab = &quot;Valeurs&quot;, ylab = &quot;Fréquences&quot;, cex.lab = 1.5, col = &quot;pink&quot;, xlim = c(5, 40), ylim = c(0, 35)) L’argument breaks permet de réduire ou d’augmenter le nombre de bandes dans le diagramme. Le nombre de bandes ne sera probablement pas la valeur exacte que vous précisez mais respectera l’ordre de grandeur. Diagramme à boîtes Nous utilisons la fonction boxplot() pour créer un diagramme à boîtes (aussi appelé diagramme à moustaches). Un diagramme à boîtes est une bonne façon de voir comment les données sont distribuées autour de leur valeur médiane. # générer 20 nombres aléatoires à partir d&#39;une # distribution normale de moyenne 20 et de distribution standard 5 x &lt;- rnorm(100, mean = 20, sd = 5) # histogramme boxplot(x) Le trait horizonal foncé au centre correspond à la valeur médiane. La ligne supérieure de la boîte correspond au 75ième percentile (3ième quartile) et la ligne inférieure de la boîte au 25ième percentile (1er quartile) Comme pour les autres types de graphique, nous pouvons personnaliser les diagrammes à boîtes en ajoutant des arguments à la fonction boxplot() boxplot(tab_ex2$age, ylab = &quot;Âge des joueurs&quot;, ylim = c(19, 36), col = &quot;violet&quot;, cex.lab = 1.5 ) 1.2.3 À vous de jouer! Dans cette section, vous allez mettre en pratique les concepts enseignés en utilisant des données sur les municipalités du Québec qui proviennent du répertoire des municipalités du Québec. Bien que la réponse à chaque question soit disponible, il est très important de tenter d’y répondre par vous même! Les données Télécharger le dossier Module1_donnees.zip dans votre répertoire de travail pour ce module, et dézippez-le. Le dossier contient le fichier villes_qc.csv. Question 1 a) Utiliser la fonction read.csv pour importer les données dans votre session de travail R. Nommer l’objet importer villes. Réponse villes &lt;- read.csv(&quot;Module1/Module1_donnees/villes_qc.csv&quot;) b) Quelles sont les dimensions du data frame villes et comment se nomment ses attributs (c’est-à-dire le nom de ses colonnes)? Réponse Les dimensions sont données par la fonction dim() dim(villes) [1] 1131 4 Le nom des attributs est donné par la fonction names() names(villes) [1] &quot;munnom&quot; &quot;regadm&quot; &quot;mpopul&quot; &quot;msuperf&quot; Ces attributs correspondent: Au nom de la municipalité (“munnom”). À la région administrative d’attache de la municipalité (“regadm”). À la taille de la population de la municipalité en 2021 (“mpopul”). À la superficie de la municipalité en km2 (“msuperf”). c) Utiliser la fonction str() pour produire un résumé du contenu du data frame villes. Déterminer à quelle classe appartient chaque attribut. Réponse str(villes) &#39;data.frame&#39;: 1131 obs. of 4 variables: $ munnom : chr &quot;Abercorn&quot; &quot;Acton Vale&quot; &quot;Adstock&quot; &quot;Aguanish&quot; ... $ regadm : chr &quot;Mont\\xe9r\\xe9gie (16)&quot; &quot;Mont\\xe9r\\xe9gie (16)&quot; &quot;Chaudi\\xe8re-Appalaches (12)&quot; &quot;C\\xf4te-Nord (09)&quot; ... $ mpopul : int 344 7733 2768 238 678 2232 227 172 30831 1459 ... $ msuperf: num 27 91.1 306.2 680.6 82.3 ... Nous constatons que “munnom” et “regadm” sont de classe caractère (char), “mpopul” de classe nombre entier (int), et “msuperf” de classe numérique (num). d) Transformer l’attribut “regadm” en facteur et déterminer son nombre de niveaux. Réponse La fonction as.factor() permet de transformer un attribut en classe facteur. villes$regadm &lt;- as.factor(villes$regadm) Le nombre de niveau d’un objet de classe facteur est donné par la fonction levels(). levels(villes$regadm) [1] &quot;Abitibi-T\\xe9miscamingue (08)&quot; [2] &quot;Bas-Saint-Laurent (01)&quot; [3] &quot;C\\xf4te-Nord (09)&quot; [4] &quot;Capitale-Nationale (03)&quot; [5] &quot;Centre-du-Qu\\xe9bec (17)&quot; [6] &quot;Chaudi\\xe8re-Appalaches (12)&quot; [7] &quot;Estrie (05)&quot; [8] &quot;Gasp\\xe9sie--\\xceles-de-la-Madeleine (11)&quot; [9] &quot;Lanaudi\\xe8re (14)&quot; [10] &quot;Laurentides (15)&quot; [11] &quot;Laval (13)&quot; [12] &quot;Mauricie (04)&quot; [13] &quot;Mont\\xe9r\\xe9gie (16)&quot; [14] &quot;Montr\\xe9al (06)&quot; [15] &quot;Nord-du-Qu\\xe9bec (10)&quot; [16] &quot;Outaouais (07)&quot; [17] &quot;Saguenay--Lac-Saint-Jean (02)&quot; Nous observons qu’il y a 17 niveaux correspondants à chacune des régions administratives du Québec. Question 2 a) Créer l’objet Mtl qui contient seulement les entrées du data frame villes pour la municipalité de Montréal. Réponse Nous souhaitons créer un data frame comprenant seulement la ligne de villes pour laquelle l’attribut “munnon” prend la valeur “Montréal”. Mtl &lt;- villes[villes$munnom==&quot;Montréal&quot;,] Mtl [1] munnom regadm mpopul msuperf &lt;0 rows&gt; (or 0-length row.names) Remarquer que l’expression villes$munnom==\"Montréal\" est un vecteur logique qui prend la valeur vrai (TRUE) lorsque le nom de municipalité est Montréal, et la valeur faux (FALSE) dans le cas contraire (c’est-à-dire pour les 1130 autres municipalités) length(villes$munnom==&quot;Montréal&quot;) [1] 1131 class(villes$munnom==&quot;Montréal&quot;) [1] &quot;logical&quot; b) Créer l’objet villes_Outaouais qui contient les entrées du data frame villes pour toutes les municipalités de la région administrative de l’Ouatouais. Réponse Nous procédons de façon similaire à la question 2a. Nous sélectionnons toutes les lignes de villes pour lesquelles l’attribut “regadm” prend la valeur “Outaouais (07)” villes_Outaouais &lt;- villes[villes$regadm==&quot;Outaouais (07)&quot;,] head(villes_Outaouais) munnom regadm mpopul msuperf 8 Alleyn-et-Cawood Outaouais (07) 172 325.9 21 Aumond Outaouais (07) 766 227.6 60 Blue Sea Outaouais (07) 656 87.5 61 Boileau Outaouais (07) 336 140.9 65 Bois-Franc Outaouais (07) 412 74.3 72 Bouchette Outaouais (07) 667 143.2 Question 3 a) Créer un histogramme de la distibution de la population des villes du Québec comprenant une dizaine de bandes. Utiliser la fonction log10() pour représenter la taille des populations. Préciser les axes de votre graphique adéquatement. Réponse Nous utilisons la fonction hist() avec l’argument breaks = 10 pour produire un histogramme d’environ 10 bandes. hist(villes$mpopul, breaks = 10 ) Nous observons que la distribution de la taille des villes suit une loi de puissance. En effet, nous comptons beaucoup de villes avec une petite taille de population (plus de 1000 villes avec une population inférieure à 250 000 habitants) et peu de villes avec une très grande taille de population. Dans cette situation, il est préférable d’illustrer le logarithme de la taille de la population. Cette distribution nous donne une meilleure appréciation de la variation dans la taille des villes. hist(log10(villes$mpopul), breaks = 10 ) Identifions correctement les axes. hist(log10(villes$mpopul), breaks = 10, main = &quot;&quot;, xlab = &quot;Nombre d&#39;habitants&quot;, ylab = &quot;Nombre de villes&quot;, col = &quot;darkorange&quot;, xlim = c(0, 7), ylim = c(0, 400), xaxt=&#39;n&#39; # ceci retire le nom des ticks sur l&#39;axe x. ) # Pour aller un peu plus loin ... axis(side =1 , at = 0:7, labels = c(&quot;1&quot;,&quot;10&quot;,&quot;100&quot;,&quot;1000&quot;, expression(10^4) , expression(10^5), expression(10^6), expression(10^7))) b) Créer un diagramme à boîte pour représenter la superficie des villes de la région de l’Outaouais. Réponse boxplot(villes_Outaouais$msuperf, main = &quot;Superficie des municipalités de l&#39;Ouatouais&quot;, ylab = expression(paste(&quot;Superficie (km&quot;^&quot;2&quot;,&quot;)&quot;)), col = &quot;deepskyblue&quot; ) "],["base.html", "Module 2 Modèles de données spatiales", " Module 2 Modèles de données spatiales Ce module s’intéresse à la façon dont nous représentons les phénomènes spatiaux se déroulant à la surface de la Terre par des données spatiales. Les objectifs principaux sont de connaître les propriétés des deux types de modèle de données spatiales, les données vectorielles et les données matricielles. À la fin de ce module vous saurez: Définir les propriétés principales des données vectorielles. Reconnaître des formats de fichier de données vectorielles. Définir les propriétés principales des données matricielles. Reconnaître des formats de fichier de données matricielles. Comprendre ce qu’est une structure en couches. À la section Exercices vous suivrez la première partie d’une introduction à la bibliothèque rmarkdown. La deuxième partie de cette introduction aura lieu dans la section Exercices du Module 3. R Markdown permet de créer des documents dynamiques de formats variés (dont HTML, PDF et Word) qui intègrent des morceaux de code R. Dans le cadre de ce cours, toutes vos évaluations devront être remises dans un fichier R Markdown. Cette section vous permet ainsi de vous familiarisez avec cette bibliothèque. "],["leçon.html", "2.1 Leçon", " 2.1 Leçon Les phénomènes spatiaux sont généralement perçus comme étant soit des entités discrètes avec des frontières bien définies ou encore comme des phénomènes continus qu’on observe de partout mais qui ne possèdent pas de frontières naturelles8. Une rivière, une route, un pays, ou une ville sont tous des exemples d’entités spatiales discrètes. D’autre part, l’élévation, la température ou la qualité de l’air sont des exemples de phénomènes continus, appelés aussi des champs spatiaux. Figure 2.1: Exemples de données vectorielles et matricielles. Gauche: La carte délimitant les régions administratives du Québec est formée à partir de données vectorielles. Droite: La carte topographique du Québec (source : https://mern.gouv.qc.ca/repertoire-geographique/carte-relief-quebec/)) Les entités spatiales (ou objets) sont habituellement représentés par ce qu’on appelle des données vectorielles (« vector data », en anglais), alors que les phénomènes continues sont habituellement représentés par des données matricielles (« raster data », en anglais). Ces deux modèles sont des façons bien différentes de percevoir et de représenter les phénomènes spatiaux. Nous les décrivons dans les deux sous-sections suivantes. 2.1.1 Les données vectorielles Définition Les données vectorielles sont utilisées pour représenter des entités spatiales dont les frontières sont explicites et qui possède une localisation précise et unique. Les données vectorielles sont définies par leur localisation géographique, leur géométrie, et un ou plusieurs attributs. La localisation géographique désigne l’emplacement de l’entité selon un système de coordonnées géographique ou un système de coordonnées projeté. Un système de coordonnées géographique utilise un système en trois dimensions pour donner la position (x,y,z) ou longitude et latitude d’une entité spatiale sur la surface sphérique de la Terre. Un système de coordonnées projeté, donne la position d’une entité spatiale sur une surface plane à deux dimensions. Nous reviendrons sur les systèmes de coordonnées de référence à la section 2.1.3. La géométrie d’une entité spatiale correspond à sa forme (« shape », en anglais). Il existe trois principaux types de géométrie, aussi appelées des classes : les points, les lignes, et les polygones (Tableau 2.2). Ces classes peuvent être combinées pour créer des géométries plus complexes; des multipoints, des multilignes, des multipolygones, etc. Figure 2.2: Exemple de données vectorielles de géométrie simple. Remarquez que dans le cas d’un polygone, la première et la dernière coordonnées sont les mêmes. Tableau inspiré de Wikipedia (https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry) Les données vectorielles comprennent également des variables additionnelles appelées des attributs. Les attributs sont toutes informations permettant de décrire une entité spatiale autres que sa localisation et sa géométrie. Géométrie et topologie Les points sont les données vectorielles les plus simples. Par exemple, un point pourrait représenter l’emplacement d’un restaurant dans une ville. Les attributs associés à ce point pourraient inclure les heures d’ouverture, sa spécialité culinaire, l’échelle de prix de son menu ou d’autres informations. Figure 2.3: L’emplacement des stations de vélo en libre partage, Bixi, dans un quartier de Montréal correspond à une géométrie multipoints. Source : https://secure.bixi.com/map/. Il est aussi possible de combiner plusieurs points ensemble dans une structure multipoints définie par un attribut unique (Figure 2.3). Par exemple, l’ensemble des restaurants de cuisine vietnamienne dans une ville pourrait être considéré comme une géométrie unique. La géométrie des lignes est plus complexe. Le terme ligne en analyse spatiale n’a pas la même définition que dans le langage usuel. Une ligne désigne un ensemble d’une seule ou de plusieurs polylignes (Figure 2.4). Une polyligne, quant à elle, désigne une séquence de segments de droite reliés entre eux. Ainsi, en analyse spatiale, une seule ligne pourrait représenter le fleuve Saint-Laurent et l’ensemble de ces affluents (rivière des Outaouais, rivière Saint-Maurice, le Fjord du Saguenay, etc.). D’autre part, il serait aussi possible de définir plusieurs lignes – une pour chaque affluent, par exemple. Figure 2.4: Le réseau hydrologique du bassin de l’Amazone représente un exemple d’un ensemble de polylignes. Source : Wang et al. 2020. Une ligne est représentée par un ensemble ordonné de coordonnées. Les segments de droite peuvent être calculés ou dessinés sur une carte en connectant ensemble les points. Ainsi, la représentation d’une ligne est semblable à celle d’une structure multipoints. La différence notable est que l’ordre des points est important dans la représentation d’une ligne car il est nécessaire de savoir quels points sont connectés entre eux. Un réseau – par exemple un réseau routier ou un réseau hydrographique – est une ligne de géométrie particulière comprenant des informations additionnelles comme le débit, la connectivité ou la distance. Un polygone désigne un ensemble de polylignes fermées. La géométrie d’un polygone est très semblable à celle des lignes à l’exception que la dernière paire de coordonnées doit coïncider avec la première paire afin de « fermer » le polygone. Une particularité des polygones est qu’ils peuvent comprendre des trous. C’est-à-dire qu’un polygone peut être entièrement compris à l’intérieur d’un polygone de plus grande superficie. Ceci est le cas d’une île au sein d’un lac, par exemple. Le polygone formant un îlot permet d’éliminer une partie du polygone qui l’englobe. De plus, alors que l’auto-intersection est permise pour une ligne (c’est-à-dire qu’elle peut se croiser sur elle-même), cette propriété n’est pas valide pour un polygone. Finalement, plusieurs polygones peuvent être considérés comme formant une géométrie unique ((Figure 2.5)). Par exemple, l’Indonésie est constituée de plusieurs îles. Chaque île peut être représentée par son propre polygone, ou encore l’ensemble des îles peut être représenté par un seul polygone (ou multi-polygones) désignant le pays en entier. Figure 2.5: Les Antilles peuvent être représentées par plusieurs polygones distincts pour chaque île, ou par un seul multipolygone. Source : https://fr.wikipedia.org/wiki/Antilles Le modèle vectoriel est très efficace pour représenter la topologie. La topologie est une description des relations spatiales qu’ont les entités spatiales entre elles. Par exemple, une analyse de données vectorielles permettra de déterminer précisément si une entité spatiale est adjacente à une autre, si elle y est incluse, ou si elle s’intersecte (Figure 2.6). Figure 2.6: Exemples de relations spatiales entre deux entités spatiales : a) adjacence, b) inclusion, et c) intersection. Format de données vectorielles Les données vectorielles peuvent être stockées dans une grande variété de formats différents. Ces formats ont évolué et continuent d’évoluer en fonction des besoins et des avancées technologiques. Plusieurs formats ont été développés pour être utilisés avec des logiciels commerciaux mais peuvent être lus et parfois édités par d’autres logiciels. Peu importe leur format, les données vectorielles sont toujours organisées selon une base de données relationnelle. Un identifiant désigne chaque objet spatial et l’associe à une géométrie et à un ou plusieurs attributs (Tableau 2.7). Figure 2.7: Exemple d’une base de données relationnelle pour la carte des régions administratives du Québec (Figure 2.1). Chaque objet vectoriel dans la carte correspond à une ligne dans la base de données où figurent les attributs qui lui sont associés Voici une liste non-exhaustive de formats de données vectorielles. SHAPEFILE (.SHP, .DBF, .PRJ, .SHX) Le shapefile est un format propriétaire d’ESRI créé pour les logiciels ArcView et ArcGIS. En français, on le nomme aussi un fichier de forme. À ce jour, il est le format le plus couramment utilisé pour les données vectorielles. Il est devenu un standard tant pour les plateformes commerciales qu’opensource. Un shapefile comprend entre quatre types de fichiers qui contiennent des informations différentes et toutes essentielles à sa représentation. .shp : contient les données spatiales .dbf : contient les données d’attributs .prj : contient l’information sur la projection des données .shx : fichier d’index Le fichier d’index sert à lier entre elles les informations contenues dans les autres fichiers. Il existe parfois d’autres types de fichier d’index (.sbx, .sbn). Pour visualiser un shapefile, il est nécessaire d’avoir tous les fichiers associés (et pas seulement le fichier .shp). Le fichier .prj peut être absent. En son absence, le shapefile peut être lu mais les données ne seront pas projetées adéquatement. Nous reviendrons sur le concept de projection plus tard dans ce module. GEODATABASE (.GDB) La géodatabase est le nouveau format propriétaire d’ESRI conçu pour ArcGIS. Il est de plus en plus adopté car il présente de nombreux avantages par rapport au shapefile. Une géodatabase est une façon de rassembler et d’organiser des données propres à un sujet ou à un projet dans une unique base de données. Elle peut contenir des données géographiques dans une large gamme de fichiers et de formats (Figure 2.8). Figure 2.8: Illustration d’une géodatabase telle que représentée sur le site web d’ArcGIS. Image récupérée à : https://desktop.arcgis.com/fr/arcmap/10.3/manage-data/geodatabases/a-quick-tour-of-the-geodatabase.htm Par exemple, un projet sur le réseau de transport d’électricité au Québec pourrait nécessiter l’utilisation de plusieurs shapefiles (position des centrales, position des pylônes, parcours des câbles, etc.) et aussi plusieurs données matricielles (topographie, végétation, etc.). Ainsi, il s’avère beaucoup plus efficace d’avoir l’ensemble de ces données au sein d’une même base. De plus, une géodatabase peut être utilisée par de multiples utilisateurs, ce qui est fort utile pour assurer le partage efficace, la mise à jour, et la cohérence des données géographiques au sein de grandes organisations, comme des entreprises ou des ministères. Malheureusement, bien que les géodatabases peuvent être lues avec R, elles peuvent seulement être modifiées dans ArcGIS. GEOGRAPHIC JAVASCRIPT OBJECT NOTATION (.GEOJSON, .JSON) Le format geoJSON est un format standard ouvert très utilisé en cartographie web. geoJSON est une extension du format JSON pour les données géographiques. Un fichier geoJSON contient les coordonnées des données géospatiales ainsi que d’autres informations sur les attributs. Un seul fichier est nécessaire pour stocker l’ensemble de l’information. GOOGLE KEYHOLE MARKUP LANGUAGE (.KML, .KMZ) Ce format est basé sur le langage XML et est optimisé pour les navigateurs de cartographie web comme Google Maps et Google Earth. KMZ est une version compressée d’un fichier KML (KML-Zipped). COVERAGE COVERAGE est le format propriétaire d’ESRI, développé pour le logiciel ArcInfo, qui a précédé le format shapefile. C’est une autre façon de stockée les données vectorielles qui nécessite plusieurs fichiers. Bien que ce format ne soit plus utilisé lorsque de nouvelles données vectorielles sont conçues, vous pourriez être amenés à rencontrer ce format si vous devez travailler avec des données qui précédent 1990. ARCINFO INTERCHANGE FILE (.EOO) C’est le format utilisé pour importer ou exporter des données d’ArcInfo. Il fonctionne comme un fichier zip et permet de partager facilement en un seul fichier les multiples fichiers et dossiers associés au format Coverage. Il permet aussi de transférer des données matricielles de format GRID. MAPINFO INTERCHANGE FILE (.MID, .MIF) C’est le format propriétaire de MapInfo, le compétiteur d’Esri. Le format shapefile a supplanté le format interchange qui est de moins en moins utilisé. Le fichier MIF contient la localisation géographique et la topologie, et le fichier MID contient les attributs. WEB MAP SERVICE (WMS) N’est pas un format de données mais plutôt un protocole de communication qui permet de visualiser des données spatiales qui sont logées sur un serveur. Les organisations gouvernementales ont souvent recours à cette méthode de partage de l’information spatiale car elle permet de s’assurer que les données diffusées sont toujours à jour. L’utilisateur peut jouer avec les paramètres de visualisation mais ne peut pas importer et modifier les données. Notez que ce protocole est utilisé à la fois pour les données vectorielles et les données matricielles. 2.1.2 Les données matricielles Définition Les données matricielles représentent la surface terrestre par une grille régulière, communément appelé un raster, formée de rectangles de même forme et de même dimension appelés cellules ou pixels (Figure 2.9). À chaque cellule de la matrice correspond une valeur numérique (ou une valeur manquante) associée à un attribut d’intérêt. On appelle couche (« layer » en anglais) l’information recueillie dans la matrice. La valeur d’une cellule peut être continue (p. ex. l’élévation - voir Figure 2.1b) ou catégorique (p. ex. le zonage attribué à différents secteurs d’une ville tel que résidentiel, commercial ou industriel). Normalement, la valeur d’une cellule représente la valeur moyenne (ou la valeur prédominante) pour la superficie qu’elle couvre. Cependant, les valeurs sont parfois estimées pour le centre de la cellule. Figure 2.9: Exemple de données matricielles associées à des classes de végétation obtenues à partir d’une image satellitaire. Figure inspirée de NEON neonscience.org/resources/series/introduction-working-raster-data-r On peut utiliser une base de données relationnelle pour lier la valeur d’un pixel à l’attribut qu’il décrit (Figure 2.10). Contrairement aux données vectorielles où les polygones peuvent être associés à plusieurs attributs, une couche de données matricielles peut représenter un seul attribut. Figure 2.10: Exemple de table relationnelle pour les données vectorielles de la Figure 2.9. Une valeur numérique est associée à chaque couleur de l’image ainsi qu’à un attribut, ici le type de végétation. Dans leur format le plus simple, les données matricielles prennent la forme d’une image digitale. Cependant, pour associer les données matricielles à une location particulière sur la surface de la Terre, des informations spatiales doivent être ajoutées. Ainsi, un fichier de données matricielles géospatiales débute toujours par une section, appelée le «header» en anglais, qui procure la localisation. La localisation pour des données matricielles est définie par l’étendue spatiale (« extent » en anglais) couverte par la matrice, la dimension des cellules, le nombre de rangées et de colonnes qui divisent la superficie (respectivement « rows » et « columns » en anglais), et le système de coordonnées géographique ou projeté. La dimension des cellules correspond à la résolution spatiale et peut être calculée à partir de l’étendue et du nombre de rangées et de colonnes. Résolution et géométrie La résolution définie la précision avec laquelle nous pouvons discerner les objets dans l’espace. Une grande résolution correspond à une matrice de données dont les cellules ont une petite taille (Figure 2.11). En conséquence, une telle matrice est plus lente à visualiser et à manipuler, et requière un fichier plus volumineux. En contrepartie, une couche de données matricielles de faible résolution possède des cellules de plus grande taille, se visualise et se manipule plus rapidement, et est contenue dans un fichier moins volumineux. Figure 2.11: Exemple du concept de résolution: plus la résolution est grande, plus la taille des cellules est petite. Dans cette figure, la résolution diminue de droite à gauche, et la taille des cellules augmente. Source de données: https://mern.gouv.qc.ca/nos-publications/spatiocarte-quebec/ Contrairement aux données vectorielles, la géométrie des données matricielles n’est pas définie explicitement par un ensemble de coordonnées. La géométrie peut être déduite en observant les démarcations se produisant aux limites des ensembles de cellules de même valeur. Cependant ces démarcations ne correspondent pas nécessairement aux frontières des entités sur le terrain (Figure 2.12). Figure 2.12: La géométrie des objets spatiaux matriciels. Les frontières d’une entité spatiale définie avec des données matricielles (droite) ne correspondent pas nécessairement aux frontières réelles (gauche) Ainsi, lorsque nous représentons des objets spatiaux aux frontières bien définies, l’utilisation de données vectorielles plutôt que matricielles s’avère plus précise et plus efficace. Par ailleurs, la représentation de phénomènes continus avec des données vectorielles, nécessiterait de définir un grand nombre de petit polygones et d’enregistrer les coordonnées de chacun d’eux. Dans la majorité des cas, une telle représentation augmenterait dramatiquement le temps de traitement des données. Données matricielles à bande unique et multi-bandes Un raster peut contenir une couche ou plusieurs couches de données. Par exemple, un fichier de données matricielles d’élévation comprendra une seule couche de données, soit l’élévation à chaque cellule. Par exemple la carte topographique du Québec (Figure 2.1b) est un exemple de raster à une seule couche. Un raster à une seule couche peut aussi représenter des images en noir et blanc en utilisant un codage binaire pour exprimer différentes teintes de gris. Un codage sur 1 bit exprimera 21 (2) teintes de gris [0,1], un codage sur 4 bit exprimera 24 (16) teintes de gris [0,1,2,…,15], et un codage sur 16 bits exprimera 216 (65536) teintes de gris [0,1,2,…, 65535] (Figure 2.13). Figure 2.13: Exemple de codage binaire pour les raster à une couche: Images en blanc et noir utilisant différentes teintes de gris : 2 teintes (gauche), 8 teintes (centre) et 256 teintes (droite). D’autres rasters peuvent contenir plusieurs couches, appelées aussi des bandes (ou canaux). Par exemple, les images de couleurs contiennent souvent trois bandes: une bande de rouge, une bande de vert et une bande de bleu. C’est ce qu’on nomme le format RGB (pour « red », « green », et « blue »). Ces bandes font références à des sections du spectre électromagnétique captées lors de la prise de l’image (Figure 2.14). Figure 2.14: Raster multibande. Les bandes blues, vertes et rouges correspondent à des sections du spectre électromagnétique. Source: Esri. Image récupérée à https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/raster-bands.htm. En combinant ces bandes, on peut recréer l’image (Figure 2.15). Attention : chaque bande doit posséder les mêmes informations spatiales pour être superposée aux autres. Figure 2.15: Image satellitaire de région de l’Estrie. Le raster multi-bande contient une bande de rouge, une bande de vert et une bande de bleu. L’image couleur s’obtient en combinant les trois bandes. Source de données: https://mern.gouv.qc.ca/nos-publications/spatiocarte-quebec/ Format des données matricielles Tout comme les données vectorielles, les données matricielles peuvent être stockées dans une grande variété de formats différents. Les images possèdent des structures matricielles, ainsi les formats bien connus pour la transmission d’images sur le Web, .jpg (Joint Photographic Experts Group), .gif (Graphics Interchange Format), et .png (Portable Network Graphics), sont des exemples de format de données matricielles. Voici une liste non-exhaustive de formats de données matricielles. GRID (.GRD) GRID est le format propriétaire d’ESRI pour stocker des données matricielles. TIFF AND GEOTIFF (.TIF) Le Tag Image File format (TIFF) est utilisé pour le stockage d’images numériques. Il a la particularité d’être comme un contenant dans lequel plusieurs informations additionnelles sur les données peuvent être stockées (par ex. les attributs, et autres métadonnées). Le format GeoTIFF est un fichier .tif standard dans lequel on intègre des informations additionnelles sur la localisation spatiale des données (p. ex. la résolution, l’étendue ou le système de coordonnées). COMMA SEPERATED VALUE FORTMAT (.CSV) Le format .csv contient du texte séparé par des virgules, et correspond à une façon simple et très répandue de représenter des données matricielles. Par exemple, un fichier .csv pourrait être constitué de trois colonnes : la première pour la coordonnée x de la cellule, la deuxième pour sa coordonnée y, et la troisième pour la valeur de l’attribut. Une autre façon d’utiliser le format .csv est d’y stocker la matrice de données sous forme d’un tableau de dimension égale à cette dernière. Chaque entrée du tableau donne la valeur d’attribut pour la cellule correspondante. Les informations sur la localisation spatiale doivent alors être fournies en en-tête du fichier. BITMAP (.BMP) BITMAP est le format d’images utilisé dans les applications de Microsoft Windows. De plus, comme expliqué plus haut, la géodatabase et Web Map Service sont aussi utilisés pour les données matricielles. Peu importe le type de données spatiales et le format utilisé pour les stocker, les données spatiales sont souvent accompagnées de métadonnées. Les métadonnées sont les données sur les données. C’est-à-dire qu’elles viennent donner des informations supplémentaires pour faciliter la compréhension et l’utilisation des données spatiales (p. ex. l’origine des données, l’auteur.e, les détails sur la structure, le lexique, les abréviations, la légende, etc.). Idéalement, tout ensemble de données devrait être accompagné de métadonnées. 2.1.3 Structure en couches Lorsque nous travaillons avec des données spatiales, il est fréquent de devoir combiner des données représentant des phénomènes spatiaux distincts. Nous devons alors utiliser une structure en couches. Une couche de donnée réfère à un thème spécifique (par ex. topographie, végétation, ou réseau routier) et contient un seul modèle de données (matricielles ou vectorielles) (Figure 2.16). Figure 2.16: Représentation de données spatiales par la superposition de couches thématiques. Source: Esri. Image récupérée à https://desktop.arcgis.com/fr/arcmap/10.3/guide-books/map-projections/what-are-map-projections.htm La superposition de couches permet de visualiser les relations spatiales entre les données de différentes thématiques (Auda 2018). Il est primordial que chaque couche de données utilise le même système de coordonnées de référence lorsqu’elles sont superposées. Le module 3 portera spécifiquement sur cette notion. Repris de l’introduction aux données spatiales du site Spatial Data Science.↩︎ "],["ex_markdown1.html", "2.2 Exercices", " 2.2 Exercices Cette section est une introduction à R Markdown qui passe en revue différents aspects techniques nécessaires à la bonne compréhension et utilisation de la biblothèque rmarkdown. Cette introduction est divisée en deux parties. Vous ferez la première partie maintenant, au module 2, et la deuxième partie dans le section Exercices du module 3. La bibliothèque rmarkdown permet de créer des documents de formats variés (dont HTML, PDF et Word) avec un contenu R dynamique. C’est-à-dire des documents qui intègrent des morceaux de code R et ce qu’ils génèrent (p. ex. des figures et tableaux). Le code source de ce site web est lui-même un exemple d’application de cette bibliothèque! R Markdown n’est pas un outil spécifique à la visualisation de données spatiales. Toutefois, puisqu’il constitue un outil d’édition, de visualisation et de diffusion fort pratique, nous l’utiliserons dans ce cours. En particulier, les évaluations devront être remises dans un fichier R Markdown .Rmd. À la fin de cette introduction vous saurez: Décrire en quoi consiste R Markdown; Décrire les liens entre R, Markdown et Pandoc; Utiliser la syntaxe Pandoc Markdown de base; Créer des documents dynamiques avec la bibliothèque rmarkdown. Cette introduction à RMarkdown a été rédigée par Kevin Cazelles, collobateur clé à réalisation de ce cours. Kevin est un chercheur en écologie computationnelle et fervent utilisateur des outils pour la science ouverte. Allez voir ses travaux sur son site https://kevcaz.insileco.io/ et son profil GitHub https://github.com/KevCaz. 2.2.1 Introduction à R Markdown Bénéfices de R Markdown Dans de nombreux milieux professionnels, à des fins de communication diverses, sont produits régulièrement des documents intégrant des analyses de données (tableaux, figures, tests statistiques, etc.). Pour créer de tels documents, il faut être en mesure de manipuler des données, de les analyser et de créer des figures pour les intégrer dans le document final. R est un langage de programmation qui répond à ces besoins avec un grand nombre de bibliothèques qui permettent de manipuler et traiter un spectre très large de données et de les visualiser efficacement. Le langage R offre également la possibilité d’intégrer code et les produits du code (résultats de tests, tableaux, figures, etc.) directement dans un document qui est alors qualifié de dynamique. La bibliothèque la plus utilisée pour créer des documents dynamiques est rmarkdown. En effet, elle permet l’intégration de R dans un document écrit avec Markdown et qui peut être converti en de nombreux formats de document (dont PDF, Word, HTML). Qu’est-ce que Markdown? Markdown est un langage de balisage léger. C’est-à-dire un langage dans lequel on peut utiliser des ensembles de caractères spécifiques (des balises) pour délimiter une zone de texte pour laquelle un formatage associé (e.g. text en gras) est appliqué. Markdown est aujourd’hui très répandu sur Internet. La syntaxe originale de Markdown est le fruit du travail de John Gruber9, programmeur, bloggeur et baladodiffuseur de Philadelphie en collaboration avec Aaron Swartz10 (lui même connu pour avoir participer à la création de Creative Commons et son tragique destin qui fut l’objet d’un film). Sur le site de John Gruber, “daringfireball”, Markdown est décrit depuis décembre 2004 et on peut même y télécharger la version 1.0.1 (voir http://daringfireball.net/projects/markdown). L’idée de départ est simple et élégante : produire un langage léger qui simplifie les balises HTML utilisé par tous les sites Internet. L’idée n’est pas tant de remplacer le HTML mais plutôt d’en augmenter l’efficacité d’écriture et de fait, il est beaucoup plus rapide d’écrire en Markdown qui couvre les opérations de formatage les plus courantes (listes, hyperliens, etc.). Notons qu’il existe d’autres langages qui répondent aux mêmes objectifs, par exemple ReStructuredText11. Après la publication de Markdown, John Gruber a cessé de travailler sur Markdown12 et d’autres développeurs, sans doute séduits par le langage, ont proposé différentes additions syntaxiques. Il s’agissait surtout de lever certaines limitations tout en préservant l’esprit d’origine. Ci-dessous, en voici une liste non exhaustive de différentes variantes Markdown: GitHub Flavored Markdown (GFM) Kramdown Markdown Extra Multi Markdow Pandoc Markdown Depuis 2014, CommonMark (https://commonmark.org/) propose une spécification (norme technique) pour Markdown de plus en plus utilisée13. Ceci signifie qu’en allant d’un outil à l’autre qui utilise cette spécification, il n’y a pas de questions à se poser quant à savoir ce qui marche ou non en terme de syntaxe (un problème parfois frustrant quand on utilise plusieurs outils qui utilisent différentes syntaxes Markdown), il suffit de se reporter à la spécification! Qu’est-ce que Pandoc? R Markdown (voir http://rmarkdown.rstudio.com)14 utilise la variante Markdown de Pandoc15. Pandoc, comme l’indique son site internet (voir http://www.pandoc.org) est un “convertisseur de document universel”. En une ligne de commande, Pandoc convertit un document d’un format donné en un document d’un autre format. Par exemple, Pandoc permet de passer d’un fichier .tex (LaTeX) à un fichier .docx (Word)! La variante Markdown de Pandoc a été pensé pour rester fidèle à l’esprit originel de Markdown tout en incluant davantage d’éléments communs à différents formats de documents16. Ainsi, un fichier R Markdown pourra être converti dans un grand nombre de formats grâce à l’utilisation de Pandoc. Dans cette introduction, nous nous concentrerons sur la création de documents en format Word, PDF et HTML, mais que les possibilités offertes par rmarkdown sont plus vastes (voir la section Ressources du cours dédiée à la documentation R Markdown). 2.2.2 Utiliser un fichier RMarkdown Organisation générale Un fichier R Markdown, dont l’extension est .rmd ou .Rmd, un fichier de texte brut qui contient trois types de langage. Un langage de programmation, R. Le fichier peut contentir des blocs de codes R utilisés pour présenter des opérations R, pour les exécuter, et pour afficher leur résultat. Ces blocs commencent et finissent par trois accents graves (backtick ou backquote en anglais): ` et les trois accents graves ouvrant le bloc sont suivis d’une accolade qui commence par r ou R, par exemple ```{R name, option1, option2} # code R à exécuter ``` ou encore ```{r option1} # code R à exécuter ``` Ces blocs de code sont intégrés au document grâce aux fonctionnalités de la bibliothèque knitr17. Un langage de balisage pour l’écriture du document, la variante syntaxique Pandoc de Markdown. Un langage de sérialisation, YAML, pour personnaliser la mise en page du ou des documents produits. Il s’agit d’une entête (Front Matter en anglais) placée au début du document dans un bloc de trois tirets ( --- ) qui donne des indications sur les sorties à générer. --- title: &quot;R Notebook&quot; output: html_notebook --- De plus, la variante syntaxique Pandoc de Markdown inclut les symboles mathématiques TeX18 pour facilité l’écriture, entre autres, des équations. En un sens c’est un quatrième langage que peut contenir un fichier R Markdown! Une fois le fichier R Markdown créé, il s’agit d’utiliser la fonction R render() pour appeler le fichier. R Markdown générera alors le ou les documents selon le format désiré. Installer R Markdown Commençons par installer la bibliothèque rmarkdown: install.packages(&#39;rmarkdown&#39;) Pour la production de document PDF, vous aurez besoin d’installer LaTeX. Si vous n’avez pas déjà LaTeX sur votre ordinateur, installer plutôt la bibliothèque tinytex19: install.packages(&#39;tinytex&#39;) tinytex::install_tinytex() # installer TinyTeX Créer un fichier R Markdown Créer un fichier R Markdown, c’est simplement créer un fichier dont l’extension est .Rmd ou .rmd, ce qui peut être fait avec n’importe quel éditeur de texte, ou de code, ou même en ligne de commande20. Dans R Studio, cela peut se faire en 2 clics, comme illustré dans la marche à suivre ci-dessous. L’intérêt d’utiliser R Studio pour cette opération est que le fichier ainsi créé contient des indications relatives à l’utilisation du fichier en question. Première étape : Utilisez l’icône de création de nouveaux fichiers (symbole + dans un cercle vert), et choissez R Markdown dans le menu vertical Deuxième étape : Choisissez le format de sortie désiré (HTML, PDF ou Word), précisez le titre du document ainsi que votre nom, puis appuyez sur la touche OK. Un fichier contenant différentes instructions et exemples est généré. Sauvegardez le fichier créé en lui attribuant un nom. Spécifier les options YAML L’entête YAML sert à spécifier différentes propriétés des documents à générer à partir du fichier .Rmd (par exemple, le titre, la date, les polices de caractères utilisées, ajout d’une table des matières, etc.) grâce à des gabarits (templates en anglais) utilisés par Pandoc. Lorsque vous créez un fichier .Rmd avec R Studio, une entête YAML est créée par défaut avec les champs: titre, autrice ou auteur, date et format de la sortie. --- title: &quot;mondoc&quot; author: &quot;Kevin Cazelles&quot; date: &quot;30/04/2022&quot; output: html_document --- Les champs disponibles dépendent des gabarits utilisés qui sont spécifiques à un format donné, les champs par défaut varient ainsi d’un format à l’autre. Notez qu’il est possible de créer ses propres gabarits et donc d’ajouter autant de champs que désiré. Un champ donné peut contenir une chaîne de caractères, une date, des chiffres ou encore une liste: nomduchamp: [élément1, élément2] ou encore nomduchamp: - élément1 - élément2 On utilise l’indentation pour signifier la hiérarchie entre les différents éléments. Les commentaires sont introduits par un “#”. Pour un aperçu assez complet des options YAML utilisables dans un fichier R Markdown, rendez-vous à la dernière page du guide de référence. Voici quelques exemples de champs valables pour les sorties HTML, PDF et docx: abstract: le texte d’un résumé apparaissant au début du document produit. description : la description du contenu du fichier. celle-ci n’apparaîtra pas sur le document produit. Utiliser les guillemets pour un texte long ou avec des signes de ponctuation. Pour un document HTML, plusieurs champs additionnels sont utiles: theme: le thème Bootstrap21 à utiliser pour l’apparence du document HTML. Les thèmes disponibles sont: default, bootstrap, cerulean, cosmo, darkly, flatly, journal, lumen, paper, readable, sandstone, simplex, spacelab, united, et yeti. Consultez la page de la bibliothèque Bootswatch pour voir à quoi ces thèmes ressemblent. highlight: le style de la coloration syntaxique. Les styles disponibles sont: default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark, et textmate. Vous trouverez ici quelques exemples de ces styles. number_sections: numéroter ou non les sections. toc: inclure ou non une table des matières (table of content en anglais). toc_depth: la profondeur de la table, c’est-à-dire, le niveau des titres apparaissant sur la table. toc_float: inclure ou non la table des matières en menu vertical visible à gauche sur le document HTML. Ce champ peut également être spécifié par une liste d’options: collapsed: permettre ou non un menu de type accordéon qui se referme et se déploie. smooth_scroll: colorer ou non le titre d’une section dans le menu lors de la navigation sur la page. fig_width: la largeur des figures. fig_height: la hauteur des figures. fig_caption: inclure ou non une légende aux figures. Pour les documents PDF, les champs suivants peuvent être précisés: fontfamily: la police de caractère. fontsize: la taille des caractères. Éditer le contenu du fichier R Markdown Le contenu principal d’un fichier R Markdown contient du texte et des blocs de code R. Le texte doit suivre la syntaxe Pandoc Markdown. Nous détaillerons cette syntaxe dans la deuxième partie de cette introduction à R Markdown, à la section Exercices du Module 3. Les blocs de code R sont ce qui distinguent un fichier R Markdown d’un fichier Markdown. La façon dont le code R est intégré au document final est déterminé par une suite de paramètres. Ces paramètres contrôlent, par exemple, si le code est affiché, si le résultat est affiché, la position d’un graphique produit, etc. Nous détaillerons également ces paramètres dans la deuxième partie de cette introduction à R Markdown. Lorsque vous créer un fichier R Markdown dans RStudio, un exemple est donné par défaut. Cet exemple contient du texte selon la syntaxe Pandoc de Markdown et du code R. Obtenir le document final Pour générer le document final à partir du fichier R Markdown, nous utilisons la fonction render() de la bibliothèque rmarkdown. Il s’agit d’appeler le fichier *.Rmd en spécifiant le chemin vers son répertoire. render(&quot;chemin/ex_Rmardown.rmd&quot;) Nous pouvons ajouter l’argument all pour obtenir tous les documents (PDF, HTML, Word) pour lesquels une spécification YAML existe. render(&quot;ex_Rmardown.rmd&quot;, &quot;all&quot;) Avec RStudio, que nous utilisons dans ce cours, générer le document final peut se faire de façon encore plus simple. Il s’agit d’appuyer sur le bouton Knit en haut à gauche dans le menu horizontal du fichier R Markdown. Vous pouvez aussi choisir le format de la sortie dans le menu déroulant associé au bouton Knit : Knit to PDF, Knit to HTML, ou Knit to Word. 2.2.3 À vous de jouer ! Question 1 Suivez la démarche présentée pour créer un fichier R Markdown en choisissant le format de sortie HTML (rappel). Préciser les champs de l’entête YAML selon les indications données. Ne modifier pas le contenu du fichier. Créer le document final. a) --- title: &quot;Bonjour Markdown!&quot; author: &quot;Votre nom&quot; date: &quot;La date&quot; abstract: &quot;Ce document HTML constitue ma première tentative de modifier l&#39;entête YAML d&#39;un document R Markdown&quot; description: &quot;Eh bien, je pensais que ça serait plus difficile!&quot; output: html_document: theme: yeti highlight: breezedark --- Réponse Vous devriez obtenir un document semblable à celui-ci. b) --- title: &quot;Document HTML produit avec le thème darkly&quot; author: &quot;Votre nom&quot; date: &quot;la date&quot; output: html_document: theme: darkly toc: true number_section: true --- Réponse Vous devriez obtenir un document semblable à celui-ci. Question 2 Suivez la démarche présentée pour créer un fichier R Markdown en choisissant le format de sortie PDF (rappel). Préciser les champs de l’entête YAML selon les indications données. Ne modifier pas le contenu du fichier. Créer le document final. --- title: &quot;Mon premier document PDF produit avec R Markdown&quot; author: &quot;Votre nom&quot; date: &quot;La date&quot; abstract: &quot;Résumez toute votre vie depuis votre naissance jusqu&#39;au moment où vous vous êtes incrit dans le cours SCI 1031!&quot; output: pdf_document: fig_width: 3 fig_height: 3 toc: true number_section: true --- Réponse Vous devriez obtenir un document semblable à celui-ci. https://en.wikipedia.org/wiki/John_Gruber, consulté le 28 avril 2022.↩︎ https://fr.wikipedia.org/wiki/Aaron_Swartz, consulté le 28 avril 2022.↩︎ https://fr.wikipedia.org/wiki/ReStructuredText, consulté le 28 avril 2022.↩︎ https://blog.codinghorror.com/responsible-open-source-code-parenting/, consulté le le 28 avril 2022.↩︎ Par example Goldmark, https://github.com/yuin/goldmard, un parser Markdown écrit en Go et utilisé par Hugo (un générateur de site très populaire), est compatible avec Common Mark.↩︎ La version 1 n’utilise pas Pandoc.↩︎ Pandoc est d’ailleurs capable de gérer différentes variantes de Markdown.↩︎ Voir https://pandoc.org/MANUAL.html#pandocs-markdown, consulté le 29 avril 2022.↩︎ Voir https://yihui.org/knitr/), consulté le 29 avril 2022.↩︎ Voir https://fr.wikibooks.org/wiki/LaTeX/%C3%89crire_des_math%C3%A9matiques, consulté le 29 avril 2022.↩︎ Voir https://yihui.org/tinytex/, consulté le 29 avril 2022.↩︎ Par example, si vous travaillez dans un environnement Linux, vous pouvez simplement entrer cette commande dans un terminal: $ echo \"---\\nauthor: VotreNom \\n---\" &gt; mondoc.Rmd↩︎ Boostrap est une collection d’outils pour le design de page web. Voir: https://fr.wikipedia.org/wiki/Bootstrap_(framework))↩︎ "],["SRC.html", "Module 3 Systèmes de coordonnées de référence", " Module 3 Systèmes de coordonnées de référence Ce module porte sur les systèmes de coordonnées de référence (SRC). Nous avons vu dans le module 2 que l’intégration de couches de données spatiales différentes nécessite qu’elles soient définies selon le même système de référence spatiale. C’est-à-dire que le modèle mathématique utilisé pour représenter la position des données sur la surface de la Terre doit être le même pour les deux jeux de données. Dans ce module, nous définissons plusieurs concepts cartographiques pour bien comprendre l’importance du SRC dans la visualisation, la manipulation et l’analyse de données spatiales. À la fin de ce module vous saurez: Expliquer la différence entre un ellipsoïde local et un ellipsoïde global. Définir ce qu’est un datum et nommer des datums courants. Expliquer la différence entre le système de coordonnées géographique et le système de coordonnées projeté. Définir les propriétés permettant de catégoriser les projections Nommer des projections courantes. La section exercices est divisée en deux parties. Dans un premier temps, vous réaliserez une auto-évaluation pour vérifier votre acquisition des connaissances enseignées dans ce module. Dans un second temps, vous continuerez votre apprentissage de R Markdown. "],["leçon-1.html", "3.1 Leçon", " 3.1 Leçon Un système de coordonnées de référence (SCR) est un ensemble d’informations qui accompagne un jeu de données spatiales et qui permet de situer ces données sur la surface de la Terre. Ces informations comprennent le modèle utilisé pour représenter la forme de la Terre, c’est-à-dire sa géodésie, et le système de mesure utilisé pour définir des coordonnées qui est soit géographique (système à trois dimensions où les coordonnées sont mesurées à partir du centre de la Terre) ou planimétrique (système à deux dimensions où les coordonnées terrestres sont projetées sur une carte plane) (Esri 2016). 3.1.1 Les systèmes géodésiques La géodésie est l’étude de la forme et des dimensions de la Terre. Au cours de l’histoire, les penseurs et les scientifiques ont adopté divers modèles pour représenter la forme de la Terre (Figure 3.1). Nous référons couramment à la Terre comme un objet rond et nous la représentons comme telle (le globe terrestre!). En vérité, la Terre n’est pas sphérique mais légèrement aplatie aux pôles. Figure 3.1: Évolution des modèles de la forme de la Terre : un corps plat, une sphère, une ellipsoïde et un géoïde. La Terre est un corps plastique qui est façonné par un ensemble de forces internes et externes lui donnant une forme irrégulière qui évolue continuellement dans le temps (Figure 3.2). En particulier, le champ gravitationnel agit différemment sur les parties solides, semi-rigides et liquides de la Terre car celles-ci ont des densités différentes22. Figure 3.2: Les différentes forces internes et externes agissant continuellement sur la Terre. Source : Ressources naturelles Canada. Le géoïde est un modèle de la Terre qui tient compte de l’effet du champ gravitationnel. C’est une surface équipotentielle23 du champ de gravité de la Terre qui coïncide avec le niveau moyen des océans (Figure 3.3). Figure 3.3: Le géoïde. a) La forme irrégulière du géoïde avec des bosses et de creux créer par le champ gravitationnel agissant de façon inégale sur la Terre (source : Bezdek et Sebera 2013). b) Le géoïde coïncide avec le niveau moyen des océans et se distingue de l’ellipsoïde (figure adaptée de USGS). La précision avec laquelle nous pouvons lier un endroit sur Terre à un ensemble de coordonnées dépend du modèle du globe choisi. Le géoïde procure une plus grande précision que l’ellipsoïde, mais l’ellipsoïde peut être décrit plus facilement par des équations mathématiques. Nous pouvons distinguer deux types d’ellipsoïdes utilisés en cartographie. Les ellipsoïdes globaux représentent la Terre à l’échelle du globe (Figure 3.4). Les ellipsoïdes locaux représentent une petite région du globe (Figure 3.4). La précision d’un ellipsoïde local est meilleure que celle d’un ellipsoïde global mais uniquement pour des coordonnées situées dans la région qu’il représente. Figure 3.4: Ellipsoïdes global et local. Un ellipsoïde global épouse mieux la forme globale du géoïde, tandis qu’un ellipsoïde local épouse mieux la forme du géoïde localement dans la région indiquée par la flèche noire. Figure adaptée de Knippers (2009). Un datum est un système de référence qui détermine la position d’un ellipsoïde sur la Terre : c’est-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont l’origine correspond au centre de masse de la Terre . Puisque aucun ellipsoïde n’épouse parfaitement la surface de la Terre, il y a toujours une certaine marge d’erreur à l’utilisation d’un datum géocentrique (Figure 3.4). La communauté internationale a adopté différent modèles d’ellipsoïdes globaux au fil du temps avec l’amélioration des techniques spatiales de télémétrie et de positionnement (Thériault 2010). Ces ellipsoïdes diffèrent par les paramètres mathématiques utilisés pour les définir. Les principaux systèmes de référence globaux utilisés présentement à travers de monde sont le Geodetic Reference System 1980 (GRS80), adopté par l’Union Géodésique et Géophysique Internationale et le World Geodetic System 1984 (WGS84), défini par le National Geospatial-Intelligence Agency des États-Unis (Figure 3.5). Le Global Positioning System (le GPS) utilise le WGS 84. Figure 3.5: Datums globaux. L’origine de l’ellipsoïde WGS84 se trouve au centre de masse de la Terre. L’origine de l’ellipsoïde GRS80 se trouve à environ 2 m de l’origine de l’ellipsoïde WGS84. L’ellipsoïde Clarke 1866 se trouve à environ 236 m de celle du WGS84. Le datum local NAD27 qui a précédé le NAD83 (voir plus bas) était basé sur l’ellipsoïde Clarke 1866. Figure adaptée du National Oceanic and Atmospheric Administration, source : https://vdatum.noaa.gov/docs/datums.html Le Cadre international de référence terrestre (ITRF) est un système de référence créé et maintenu par le Service international de la rotation de la Terre et des Systèmes de référence (IERS), un organisme international « qui étudie l’orientation de la Terre et établit un système de coordonnées sur la Terre et par rapport à l’espace. »24 L’ITRF n’est pas basé sur un modèle d’ellipsoïde. Il est constitué d’un ensemble de repères terrestres dont les coordonnées \\((x,y,z)\\) à la surface de la Terre sont établies à partir du centre de la Terre (Figure 3.6). On se sert de ces repères pour déterminer les paramètres des ellipsoïdes globaux et locaux. À cause du mouvement des plaques tectoniques, les coordonnées des repères de l’ITRF doivent être réévaluées périodiquement. Figure 3.6: Réseau de repères terrestres en vue d’établir le prochain ITRF. Source : NASA Earth Observatory Les datums locaux sont associés à des ellipsoïdes locaux. Ce sont des systèmes de référence dont l’origine de l’ellipsoïde est décalée par rapport au centre de la Terre. Un datum local fait correspondre un point de la surface de l’ellipsoïde local à un point de la surface de la Terre. Ce point de référence est fixe et il sert « d’ancrage » au datum. C’est le point d’origine du système de référence local, et il est souvent basé sur une plaque tectonique. Il existe des centaines de datum local servant de système de référence à différentes régions du globe. Il est possible d’utiliser le même ellipsoïde pour définir différents datums. Le système de référence utilisé en Amérique du Nord est le North American Datum of 1983 (NAD83). Il est basé sur l’ellipsoïde GRS80 et est fixé à la plaque tectonique nord-américaine. Le European Terrestrial Reference System of 1989 (ETRS89) est le système de référence utilisé en Europe. Il est aussi basé sur l’ellipsoïde GRS80 mais est fixé à la plaque tectonique eurasienne. On peut utiliser un datum local seulement pour la région pour laquelle il a été conçu. Ainsi, il serait erroné d’utiliser le ETRS89 pour définir la localisation d’un phénomène spatial au Québec. Figure 3.7: Réseau de repères terrestres. Gauche : un repère du Réseau de base canadien (RBC) situé en Saskatchewan. Droite : un repère du Réseau géodésique de grande précision (RGP) au Québec. Certains repères du RGP font partie du RBC. (source : www.waymarking.com) Le Système canadien de référence spatiale (SCRS) est un datum local créé par le gouvernement canadien spécifiquement pour ces besoins. La majorité des agences fédérales canadiennes qui ont recours à des données spatiales (Ressources naturelles Canada, Pêches et Océan Canada, Agence spatiale canadienne, etc.) utilise ce système de référence. Le SCRS est un quadrillage tridimensionnel (latitude, longitude et élévation) adapté du système NAD83 – il est d’ailleurs appelé le NAD83 (SCRS). Il a été développé dans les années 1990 pour corriger des distorsions d’environ 2 m observées entre le NAD 83 et un réseau de points de contrôle (le Réseau de base canadien, RBC, Figure 3.7 suivi par un système global de navigation par satellite (GNSS) (pour en savoir plus consulter cette description du SCRS donnée par Ressources naturelles Canada) (Figure 3.8). Figure 3.8: Comparaison entre le NAD83 et le SCRS. Les points rouges sont la localisation de repères selon le SCRS et les lignes bleues représentent les erreurs (décalages) produites par le NAD83 sur ces localisations. Figure tirée de Craymer (2006). 3.1.2 Les systèmes de coordonnées La localisation géographique se fait à partir d’un système de coordonnées. Multiples systèmes de coordonnées peuvent être définis, et les coordonnées d’un endroit sur Terre différeront selon le système utilisé. Il existe deux types de système de coordonnées : le système de coordonnées géographiques et le système de coordonnées projetées. Le système de coordonnées géographique représente la Terre comme une sphère et donne des coordonnées en trois dimensions pour se situer sur sa surface. Le système géographique est défini par le datum choisi (qui peut être local ou global), une unité angulaire de mesure et un méridien principal (Esri 2016) (Figure 3.9). Figure 3.9: Le système de coordonnées géographique. Les points à la surface de la Terre sont définis par les coordonnées sphériques (\\(\\phi\\),\\(\\lambda\\)) associées à la longitude (ligne mauve) et à la latitude (ligne bleue foncée) respectivement. Le point rouge possède les coordonnées (\\(\\phi\\),\\(\\lambda\\)) = (50\\(^{\\circ}\\) E, 40\\(^{\\circ}\\) N). La ligne jaune représente le méridien principal. Source : Esri, image récupérée à https://desktop.arcgis.com/fr/arcmap/10.3/guide-books/map-projections/geographic-coordinate-system.htm Les coordonnées sphériques (\\(\\phi\\), \\(\\lambda\\)) d’un point sur la surface de la Terre correspondent à sa longitude et à sa latitude respectivement (Figure 3.9). On exprime ces coordonnées en degrés (degrés, minutes, secondes (DMS) ou degré décimal (D,D)). Le système géographique forme ce que l’on appelle un graticule sur la surface de la Terre (Figure 3.10). C’est une grille composée de lignes horizontales, appelées les parallèles, et de lignes verticales, appelées les méridiens. Le parallèle de latitude zéro constitue l’équateur, alors que le méridien de longitude zéro constitue le méridien principal. Dans la plupart des systèmes de coordonnées géographiques, le méridien qui traverse l’Observatoire royal de Greenwich en Angleterre correspond au méridien principal. Figure 3.10: Graticule. Les parallèles et les méridiens forment un graticule. Source : Esri, image récupérée à https://desktop.arcgis.com/fr/arcmap/10.3/guide-books/map-projections/about-geographic-coordinate-systems.htm Le système de coordonnées projeté, quant à lui, réfère à une transformation mathématique permettant de représenter sous forme de carte plane la réalité tridimensionnelle de la Terre (Figure 3.11). Figure 3.11: Le système de coordonnées projeté. Il permet de représenter sur une surface plane bidimensionnelle la surface tridimensionnelle de la carte à l’aide d’une transformation mathématique \\((x,y) = f(\\phi, \\lambda)\\) Les systèmes de coordonnées projetés sont nécessaires pour la création de cartes géographiques. Cependant, puisqu’il est impossible de représenter parfaitement la surface d’un objet tridimensionnel sur une carte plane, les systèmes projetés génèrent certaines distorsions (ou déformations) : forme, distance, direction, etc. Par ailleurs, toutes les projections conservent un élément important de la cartographie : la précision de la localisation géographique. 3.1.3 Les projections On peut catégoriser les systèmes de coordonnées projetés selon la classe de transformations mathématiques utilisées, le type d’intersections entre le globe et le plan, l’orientation du plan, et le type de distorsions créé sur le plan. Classes de transformations On distingue trois classes principales de transformation pour créer un système de coordonnées projeté (Figure 3.12). Cylindrique : la surface de la Terre est projetée sur un plan enroulé comme un cylindre. Généralement le cylindre coïncide avec le globe le long d’un parallèle (p.ex. l’équateur). Conique : la surface de la Terre est projetée sur un cône. Le cône et le globe coïncident le long d’un ou de deux parallèles. Pour aplanir le cône, il est découpé le long d’un méridien, généralement le méridien opposé au méridien principal. Azimutale (ou plane) : la surface de la Terre est projetée directement sur un plan. Celui-ci touche généralement le globe à un seul point (p.ex. le pôle Nord). Figure 3.12: Classes de projection: cylindrique (gauche), conique (centre) et azimutale (droite). Toutes les projections illustrées utilisent un plan de projection qui est tangent à la surface de la Terre. Source : Esri. Image adaptée d’illustrations récupérées à https://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/projection-types.htm Types d’insersection Il existe deux types d’intersection entre un plan et la surface du globe (Figure 3.13). Tangente : le plan touche la surface du globe à un seul point (azimutal) ou le long d’une seule ligne (cylindrique et conique). Les transformations illustrées à la Figure classes sont toutes tangentes. Sécante : le plan traverse la surface du globe le long d’une seule ligne (azimutal) ou le long de deux lignes (cylindrique et conique). Ces lignes sont appelées les parallèles standards. Les transformations illustrées à la Figure intersection sont toutes sécantes. Notez qu’il n’y a pas de distorsion au point ou à la ligne d’intersection car à cet endroit les systèmes de coordonnées géographiques et projetés coïncident parfaitement. Figure 3.13: Plans de projection sécants avec le globe. Illustrations pour les classes de projection cylindrique (gauche), conique (centre) et azimutale (droit). Source : Esri. Image adaptée d’illustrations récupérées à https://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/projection-types.htm Orientation Le plan de projection peut être positionné selon trois différentes orientations par rapport au globe. Normale : le plan est parallèle par rapport à l’axe Nord-Sud du globe. Les transformations illustrées aux Figure classes et intersection sont toutes normales. Transverse : le plan est perpendiculaire à l’axe Nord-Sud du globe (Figure 3.14 gauche). Oblique : le plan est ni parallèle ni perpendiculaire à l’axe Nord-Sud du globe (Figure 3.14 droite). Figure 3.14: Orientations du plan de projection. Orientation transversale (gauche), aussi appelée équatoriale pour la projection azimutale, et orientation oblique (droit). Source : Esri. Image adaptée d’illustrations récupérées à https://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/projection-types.htm Distorsion Les projections produisent toutes une certaine forme de distorsion. On caractérise un système de coordonnées projeté selon la propriété qu’il conserve, c-à-d la propriété qu’il ne déforme pas. Il y a trois propriétés importantes qui sont ou non conservées (en tenant compte de l’échelle de la carte): la forme, la superficie et la distance. Conforme : la projection conserve localement les angles entre les droites. Les cartes de navigation, notamment, sont produites par des projections conformes pour mesurer adéquatement la direction de trajectoires. La conformité implique également la conservation de la forme des régions de petite superficie. Équivalente : la projection conserve localement l’aire des régions. Les atlas géographiques emplois souvent des cartes produites par des projections équivalentes pour éviter les biais dans la représentation des superficies de différentes régions du monde. Équidistante : la projection conserve les distances sur certaines lignes du globe, généralement les méridiens. Aucune projection ne peut être à la fois conforme et équivalente. Plusieurs projections offrent des compromis entre ces deux propriétés. Il existe plus de deux cent projections distinctes créées au cours de l’Histoire par les scientifiques, notamment des astronomes, des géographes, et des navigateurs. La figure 3.15 illustre un petit sous-ensemble de projections. La projection cylindrique équidistante (coin supérieur gauche de la figure 3.15 a été créée par Marinus de Tyr, un astronome d’origine phénicienne, vers l’an 100. Plusieurs projections sont identifiées par le nom de la personne qui en a fait la découverte. Par exemple, Gérard Mercator est un mathématicien et géographe flamand du 16e siècle, et Jean-Henri Lambert est un mathématicien, cartographe et astronome d’origine alsacienne du 18e siècle. Figure 3.15: Sélection de 12 projections. L’ensemble des cartes est tiré du site : https://map-projections.net/ Je vous invite à consulter le site très intéressant de Tobias Jung où un grand nombre de projections est répertorié. Vous pouvez connaître les propriétés des projections et aussi comparer deux projections entre elles. Jetez-y un coup d’œil! Sur ce site vous pourrez apprendre, par exemple, que les projections de Mollweide, de Bonne, Equal Earth et eumorphique de Boggs sont équivalentes, alors que les projections de Mercator et de Lagrange sont conformes. Les projections de Mercator et cylindrique équidistante, comme son nom l’indique, sont équidistantes. L’indicatrice de Tissot permet d’illustrer les déformations produites par une projection (Figure 3.16). Cette indicatrice porte le nom du cartographe français, Nicolas Auguste Tissot, qui l’a créé au 19e siècle. Le niveau de changement de la taille et de la forme des cercles rouges permet de repérer les endroits sur la carte de plus fortes déformations. Figure 3.16: Indicatrice de Tissot pour les 12 projections de la figure 3.15. L’ensemble des cartes est tiré du site : https://map-projections.net/ 3.1.4 Projections couramment utilisées Projection de Mercator La projection de Mercator (Figure Mercator, Figure projections et Figure tissot coin supérieur droit) est une projection cylindrique conforme. Les méridiens y sont parallèles et équidistants. Les parallèles (les lignes de latitude) sont aussi parallèles. Cependant, elles s’écartent les unes des autres au fur et à mesure qu’elles s’éloignent de l’équateur (Esri 2016). La projection de Mercator fût originalement conçue pour la navigation puisqu’elle préserve les angles. Elle préserve aussi les formes ce qui la rend très populaire pour la cartographie aux échelles régionales. Par ailleurs, la projection de Mercator ne préserve pas les superficies. Elle génère de grandes distorsions aux pôles (Figure 3.16 coin supérieur droit). Par exemple, la superficie du Groenland apparait être aussi grande que celle de l’Afrique sur une projection de Mercator (Figure 3.17, gauche). En vérité, la superficie du Groenland (2 166 086 km\\(^{2}\\), en mauve sur la Figure Mercator, droit) est inférieure à celle de l’Algérie (2 381 741 km\\(^{2}\\), en orange sur la Figure 3.17, droit). Ces distorsions rendent la projection de Mercator peu adéquate pour produire des cartes à l’échelle mondiale. Figure 3.17: Projection de Mercator. À gauche, on observe que les méridiens sont équidistants tandis que les parallèles s’écartent en se dirigeant vers les pôles (source : Tobias Jung, https://map-projections.net/). À droite, on observe que la superficie réelle du Groenland (en mauve) est similaire à celle de l’Algérie (source : https://thetruesize.com/ Les services de cartographie en ligne, comme Google Maps, OpenStreetMap, Bing Maps ou Mapquest, utilise la projection Web de Mercator (avec le datum WGS84). Cette projection est légèrement différente de la projection usuelle de Mercator (elle utilise la transformation sphérique plutôt que ellipsoïdal) produisant des cartes qui ne sont pas tout à fait conformes (PROJ contributors 2020). Projection Transverse universelle de Mercator La projection Transverse universelle de Mercator (en anglais Universal Transverse Mercator, UTM) est une projection cylindrique transverse sécante (Figure 3.18. Le globe est séparé en 60 zones au nord et au sud de l’équateur. Chaque zone couvre 6\\(^{\\circ}\\) et est défini en son centre par un méridien central. Les zones sont numérotées de 1 à 60 en suivant la convention selon laquelle la zone 1 couvre la région allant de 180\\(^{\\circ}\\) à 174\\(^{\\circ}\\) ouest (0\\(^{\\circ}\\) correspondant au méridien de Greenwich). Les zones ne couvrent pas les pôles, elles s’arrêtent à la latitude de 84\\(^{\\circ}\\) au nord et de 80\\(^{\\circ}\\) au sud. Figure 3.18: Projection transverse universelle de Mercator. Gauche : le globe est découpé en tranches de 6\\(^{\\circ}\\), 3\\(^{\\circ}\\) de part et d’autre d’un méridien central (source : https://www.swisstopo.admin.ch/). Droite : La surface entière de la Terre est représentée par 60 zones (source : https://www.icsm.gov.au/). La projection transverse de Mercator est réalisée sur chacune des zones de façon distincte. Nous obtenons donc 60 projections différentes. Chaque zone présente des distorsions, mais puisque les zones sont petites (6\\(^{\\circ}\\)), les distorsions sont limitées. Les coordonnées d’un point dans ce système projeté sont données d’abord par le numéro de la zone dans laquelle il se situe, puis par sa position au sein de la zone, c’est-à-dire par sa longitude et sa latitude mesurées en mètre. On utilise souvent les appellations anglaises pour désigner les longitudes, eastings, et les latitudes, northings. Par convention, on associe au méridien central la longitude de 500000 m (500 km). Si le point se situe à l’ouest du méridien central, sa longitude est déterminée en soustrayant la valeur 500000 m de la distance à laquelle il se trouve du méridien. À l’opposé, si le point se trouve à l’est du méridien central, sa longitude sera déterminée en ajoutant 500000 m à la distance qui le sépare du méridien. Les latitudes sont déterminées à partir de l’équateur. Dans l’hémisphère nord, l’équateur correspond à l’origine (0 m) et la latitude d’un point est déterminée par la distance qui le sépare de l’équateur. Dans l’hémisphère sud, l’équateur correspond à la valeur 10 000 000 m, et la latitude d’un point est déterminée en soustrayant à 10 000 000 m la distance qui le sépare de l’équateur (Figure 3.19). Ces conventions sont utilisées de manière à avoir toujours des coordonnées positives dans la zone couverte par la projection. Figure 3.19: Longitudes et latitudes à l’intérieur d’une zone de la projection UTM. Source : http://geokov.com/ Le Canada s’étend de la zone 7 à la zone 22, alors que le Québec couvre les zones 17 à 21 (Figure 3.20). Notez que les zones sont aussi appelées des fuseaux. Figure 3.20: Projection Universelle Transverse de Mercator au Québec. Source: Lapointe (2005) Pour réduire les problèmes liés aux déformations associées au système UTM, le Québec s’est doté de son propre système : la projection modifiée transverse de Mercator (MTM). Le système MTM est identique au système UTM à la différence que chaque zone couvre une longitude de 3\\(^{\\circ}\\). Les zones étant plus petites, les distorsions sont réduites. Les zones sont numérotées de 1 à 8 débutant aux Iles-de-la-Madeleine et se terminant en Abitibi (Figure 3.21). On associe au méridien central des zones MTM la longitude de 304800 m. Figure 3.21: Projection Mercator Transverse Modifiée au Québec. Source: Lapointe (2005) Projection conique conforme de Lambert La projection conique conforme de Lambert (LCC) conserve, comme son nom l’indique, la forme des régions ainsi que les angles. Cette projection est également sécante : il n’y a de distorsion le long des deux parallèles standards (Figure 3.22). La projection LCC est particulièrement utile pour représenter les régions de latitudes moyennes, comme l’Amérique du Nord, mais elle est également utilisée en Europe. Figure 3.22: Projection conique conforme de Lambert. Source : United States Geological Survey, récupérée sur Wikipedia La position des parallèles standards varie selon la région du globe représentée. Au Canada, elles sont généralement situées à 49 N et 77 N. La carte ci-dessous du Canada (Figure 3.23) utilise une projection LCC pour présenter les résultats des élections fédérales 2019. Figure 3.23: Un exemple de projection conique de Lambert. La carte des résultats des élections fédérales canadiennes de 2019. Source : Élections Canada. 3.1.5 Représentation d’un SCR Les données spatiales doivent toujours être accompagnées de l’information permettant de connaître le système de coordonnées de référence qui leur est associé. Ces métadonnées peuvent être représenter (ou encoder) de différentes façons. Le Well-known text Le format Well-known text (WKT) est une syntaxe standard utilisée pour représenter les données vectorielles et aussi les SCR des données vectorielles et matricielles. Ce format consiste en une série d’étiquette de la forme [...] associée à différentes informations relatives au SCR. Par exemple: Linking to GEOS 3.10.2, GDAL 3.4.3, PROJ 9.0.0; sf_use_s2() is TRUE Reading layer `pistes_cyclables_type&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module4/Module4_donnees/Montreal_Velo/pistes/pistes_cyclables_type.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 6395 features and 1 field Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: 268000 ymin: 5029000 xmax: 306300 ymax: 5063000 Projected CRS: Transverse_Mercator Coordinate Reference System: User input: Transverse_Mercator wkt: PROJCRS[&quot;Transverse_Mercator&quot;, BASEGEOGCRS[&quot;NAD83&quot;, DATUM[&quot;North American Datum 1983&quot;, ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, LENGTHUNIT[&quot;metre&quot;,1]], ID[&quot;EPSG&quot;,6269]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;Degree&quot;,0.0174532925199433]]], CONVERSION[&quot;unnamed&quot;, METHOD[&quot;Transverse Mercator&quot;, ID[&quot;EPSG&quot;,9807]], PARAMETER[&quot;Latitude of natural origin&quot;,0, ANGLEUNIT[&quot;Degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8801]], PARAMETER[&quot;Longitude of natural origin&quot;,-73.5, ANGLEUNIT[&quot;Degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8802]], PARAMETER[&quot;Scale factor at natural origin&quot;,0.9999, SCALEUNIT[&quot;unity&quot;,1], ID[&quot;EPSG&quot;,8805]], PARAMETER[&quot;False easting&quot;,304800, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8806]], PARAMETER[&quot;False northing&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8807]]], CS[Cartesian,2], AXIS[&quot;(E)&quot;,east, ORDER[1], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]], AXIS[&quot;(N)&quot;,north, ORDER[2], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]]] La syntaxe PROJ4 La syntaxe PROJ4 consiste en une liste de paramètres précédés par le symbole +. Elle donne une représentation du CRS de façon beaucoup plus concise. Voici un exemple: [1] &quot;+proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Les paramètres principaux ont la signification suivante: +proj : le nom de la projection +datum : le nom du datum +ellps : le nom de l’ellipsoïde +zone : le numéro de la zone pour une projection UTM +lat_0 : la latitude de l’origine +lat_1 : la latitude du premier parallèle standard25 +lat_2 : la latitude du deuxième parallèle standard +lon_0 : la longitude du méridien central +x_0 : le faux est (false easting; dans le cas de projection transverse comme UTM) +y_0 : le faux nord (false northing) +units : les unités (mètres, degrés, etc.) +k_0: facteur d’échelle Vous pouvez trouver d’autres paramètres ici. Les codes EPSG Le Comité de topographie et de positionnement (Surveying and Positionning Comittee) de l’Association internationale des producteurs de pétrole et de gaz (OGP), autrefois le European Petroleum Survey Group (EPSG), est une organisation scientifique liée à l’industrie pétrolière qui a mis en place une base de données répertoriant tous les systèmes de référence et les systèmes de coordonnées géographiques et projetés existants. Cette base de données, appelée le registre de codes EPSG, associe un code numérique à chaque système pour en faciliter l’identification et précise ses paramètres géodésiques et de projection. Vous pouvez consulter cette base de données ici. Vous pouvez aussi utiliser le site https://epsg.io/ et entrez ‘Quebec’ dans la fenêtre de recherche pour connaître les codes EPGS utilisés au Québec. Par exemple : NAD83 : 4269 NAD83 (SCRS): 4617 WGS84: 4326 Ou encore: Le fuseau 2 de la projection MTM basé sur le NAD83 : 32182 La projection Web de Mercator : 3857. 3.1.6 Résumé La figure ci-dessous (Figure 3.24) résume les étapes du processus utilisé pour définir un système de coordonnées géographique et un système de coordonnées projeté. Figure 3.24: Résumé. Les étapes du processus pour définir un système de coordonnées géographique et un système de coordonnées projeté. Source : la figure utilise des pictogrammes créés par T. Grajecta (Noun Project) Lorsqu’on représente des données spatiales par un système de coordonnées géographique, il faut toujours préciser le datum qui a été adopté. Lorsqu’on représente des données spatiales par un système de coordonnées projeté, il faut toujours préciser le datum et la projection. Lorsqu’on combine des couches de données différentes, on doit s’assurer qu’elles s’appuient sur le même datum et la même projection. Si ce n’est pas le cas, on peut transformer le système de référence et le système de projection. Nous verrons comment procéder à ces transformations dans le module 7 et e module 8. Source: Le Québec géographique↩︎ “Une surface où le potentiel est constant et qui est en tous points perpendiculaire à la direction dans laquelle s’exerce la pesanteur. Une surface équipotentielle est de niveau, c.-à-d. que l’eau y reste au repos”. Définition de Ressources Naturelles Canada↩︎ Définition selon Wikipédia↩︎ Souvenez-vous que pour une projection cylindrique ou conique, le plan intersecte le globe le long d’un ou de deux parallèles. Voir la leçon 2↩︎ "],["ex_markdown2.html", "3.2 Exercices", " 3.2 Exercices Dans cette section nous poursuivons l’introduction à R Markdown entamée dans la section Exercices du module 2. Rappelons les objectifs de cette introduction. Décrire en quoi consiste R Markdown; Décrire les liens entre R, Markdown et Pandoc; Utiliser la syntaxe Pandoc Markdown de base; Créer des documents dynamiques avec la bibliothèque rmarkdown. Cette introduction à RMarkdown a été rédigée par Kevin Cazelles, collobateur clé à réalisation de ce cours. Kevin est un chercheur en écologie computationnelle et fervent utilisateur des outils pour la science ouverte. Allez voir ses travaux sur son site https://kevcaz.insileco.io/ et son profil GitHub https://github.com/KevCaz. 3.2.1 Le variante Pandoc de Markdown Dans cette partie, nous détaillons les éléments de formatage du texte proposés par la syntaxe Pandoc de Markdown26 Informations de départ De façon générale, nous écrivons du texte dans un fichier R Markdown de la même façon que nous le ferions dans un document Word. Nous pouvons, par exemple, écrire des accents français sans problème. Les paragraphes Pour créer des paragraphes, il faut ajouter une ligne (ou plus) vide entre les paragraphes. Ainsi, avec les lignes suivantes : Un datum est un système de référence qui détermine la position d’un ellipsoïde sur la Terre : c’est-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont l’origine correspond au centre de masse de la Terre. nous obtenons : Un datum est un système de référence qui détermine la position d’un ellipsoïde sur la Terre : c’est-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont l’origine correspond au centre de masse de la Terre. Notez qu’avec un simple retour à la ligne, aucun saut de ligne n’est inséré. Les paragraphes sont alors affichés bout à bout. Par exemple, ce texte: Un datum est un système de référence qui détermine la position d’un ellipsoïde sur la Terre : c’est-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont l’origine correspond au centre de masse de la Terre. s’affiche comme ceci: Un datum est un système de référence qui détermine la position d’un ellipsoïde sur la Terre : c’est-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont l’origine correspond au centre de masse de la Terre. Il est cependant possible d’ajouter un retour à la ligne en utilisant un retour à la ligne et tabulation à la fin du premier paragraphe. Par exemple, ce texte: Un datum est un système de référence qui détermine la position d’un ellipsoïde sur la Terre : c’est-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont l’origine correspond au centre de masse de la Terre. s’affiche comme ceci: Un datum est un système de référence qui détermine la position d’un ellipsoïde sur la Terre : c’est-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont l’origine correspond au centre de masse de la Terre. La seule différence entre cet exemple et l’exemple précédent est l’ajout d’une tabulation après “orientation.”. Les symboles réservés Certains symboles sont réservés au formatage du texte. Lorsque leur affichage est requis, c’est-à-dire lorsque nous désirons les utiliser dans notre texte, nous devons les faire précéder du caractère d’échappement qui est, pour Markdown, l’antislash : “\\”. Par exemple, nous devons entrer  : \\\\ \\&amp; \\# \\$ \\[ Pour obtenir : \\ &amp; # $ [ Les commentaires Pour rédiger des commentaires dans le texte qui ne seront pas affichés dans le document final, nous utilisons &lt;!-- devant le commentaire et --&gt; après celui-ci. Décoration du texte Pour écrire du texte en italique, vous avez deux possibilités : *le texte à mettre en italique* _le texte à mettre en italique_ Pour écrire du texte en gras, vous avez aussi deux possibilités : **le texte à mettre en gras** __le texte à mettre en gras__ Pour écrire du texte en gras et italique, utilisez : **le _texte en italique et en gras_** Pour obtenir un texte rayé, entrez : ~~texte rayé~~ Pour écrire un élément en exposant, utilisez : ^texte en exposant^ Pour écrire un élément en indice, tapez : ~texte en indice~ Notez qu’il n’y a pas de balises pour le soulignement du texte. De manière générale, quand un élément de mise en page manque dans la syntaxe, il est toujours possible d’utiliser des commandes d’un langage. Par exemple, pour souligner dans un document qui sera produit en HTML, je peux utiliser &lt;u&gt;texte souligné&lt;/u&gt; mais cela ne me permettra pas d’avoir un texte souligné en Word ou en PDF. De même que si j’utilise \\underline{texte souligné} le texte sera souligné en PDF, mais pas en HTML ni en Word. Procéder de la sorte n’est pas toujours souhaité car le document R Markdown perd en généralité, en ce sens où il ne pourra pas être correctement généré dans tous les formats. Cela n’est cependant pas nécessairement un problème, par exemple, si vous souhaiteZ obtenir le document en un seul format, ce fonctionnement devient un atout puisque vous pouvez utiliser toute la gamme de mise en forme offert par le langage en question. Les titres La façon la plus simple de désigner les titres dans un texte se fait par l’utilisation du symbole # (ATX heading). Un seul # désigne un titre de premier niveau, et nous utilisons un nombre croissant de # pour descendre dans l’arborescence des titres: # Un titre d&#39;ordre 1 ## Un titre d&#39;ordre 2 ### Un titre d&#39;ordre 3 Il est aussi possible d’utiliser une série de “=” en dessous des titres de premier niveau et une ligne de “-” en dessous des titres de niveau 2. Cette option a la qualité de permettre de repérer facilement les titres dans le code source. Un titre d&#39;ordre 1 ================== Un titre d&#39;ordre 2 ------------------ ### Un titre d&#39;ordre 3 Les listes Les listes sont très intuitives en Markdown, alors qu’elles requièrent des balises un peu lourdes aussi bien en Latex qu’en HTML. Dans les exemples donnés, il faut toujours séparer le texte principal de la liste par des sauts de ligne. Listes non numérotées Pour obtenir une liste non numérotée, nous pouvons utiliser le symbole *  : * objet 1, * objet 2, * objet 3. ou bien le symbole +  : + objet 1, + objet 2, + objet 3. ou encore le symbole -  : - objet 1, - objet 2, - objet 3. et même  : + objet 1, * objet 2, - objet 3. Dans tous les cas, la liste produite s’affiche ainsi : objet 1, objet 2, objet 3. Listes espacées Pour produire une liste plus aérée, nous pouvons ajouter un espace entre les éléments de la liste. Lorsque le document produit est en HTML, ce formatage produit une balise paragraphe (c’est-à-dire que &lt;p&gt; &lt;/p&gt; est ajouté). * objet 1, * objet 2, * objet 3. devient: objet 1, objet 2, objet 3. Listes hiérarchisées Pour créer des listes hiérarchisées, il s’agit d’utiliser une indentation de quatre espaces (ou une tabulation) entre chaque niveau. Par exemple, ceci: - objet 1, + machin 1 - chose 1 - chose 2 + machin 2 - objet 2, - objet 3. produit cette liste: objet 1, machin 1 chose 1 chose 2 machin 2 objet 2, objet 3. Listes avec du texte ou du code Pour alterner des éléments d’une liste avec du texte ou du code, il faut utiliser des sauts de lignes avec l’indentation adéquate. Ainsi, avec les lignes suivantes : - élément 1&amp;nbsp;: Un petit texte qui pourrait expliciter ce qu&#39;est l&#39;élément 1. - machin 2: for (i in 1:2) print(i) nous obtenons : élément 1 : Un petit texte qui pourrait expliciter ce qu’est l’élément 1. machin 2: for (i in 1:2) print(i) Listes numérotées Pour créer une liste numérotée, il suffit de numéroter chaque élément de la liste. Par exemple: 1. machin 1, 2. machin 2, 3. machin 3. produit ceci: machin 1, machin 2, machin 3. Si les nombres ne sont pas écrits manière ordonnée, cela ne changera pas le résultat. Néanmoins, le premier nombre détermine le numéro de départ de la liste. En écrivant : 3. machin 1, 3. machin 2, 3. machin 3, 5. machin 4. nous obtenons: machin 1, machin 2, machin 3, machin 4. Pour ne pas se soucier des numéros, il existe un style par défaut : #. machin 1, #. machin 2, #. machin 3. Nous retrouvons bien la première liste numérotée : machin 1, machin 2, machin 3. Plusieurs styles de numérotation sont disponibles. Par exemple, en écrivant : #) élément 1 #) élément 2 #) élément 3 (1) truc 1 (2) truc 2 (5) truc 3 i. machin 1 i. machin 2 i. machin 3 nous obtenons : élément 1 élément 2 élément 3 truc 1 truc 2 truc 3 machin 1 machin 2 machin 3 Nous avons aussi la possibilité de mélanger les niveaux numérotés et les niveaux non-numérotés. Par exemple, cette liste 1. machin 1, 1. machin 1.1, 2. machin 1.2, 2. machin 2, - machin 2.1, - machin 2.2, - machin 3, 3. machin 4, 4. machin 5. donne ceci  : machin 1, machin 1.1, machin 1.2, machin 2, machin 2.1, machin 2.2, machin 3, machin 4, machin 5. Enfin, il possible de mettre manuellement fin à une liste en introduisant un commentaire entre les listes à séparer : (1) truc 1 (2) truc 2 (3) truc 2b &lt;!-- end --&gt; (1) truc 3 (2) truc 4 ces lignes sont rendues ainsi : truc 1 truc 2 truc 2b truc 3 truc 4 Blocs de citation Pour utiliser un bloc de citation (la balise “blockquote” en HTML), il suffit d’utiliser “&gt;” avant la citation. Ainsi les lignes suivantes : &gt; la citation est ajoutée comme ceci, elle nous donne une indentation adéquate pour une mise en page agréable dont le style peut être facilement travailler en HTML grâce au CSS. deviennent : La citation est ajoutée comme ceci, elle nous donne une indentation adéquate pour une mise en page agréable dont le style peut être facilement travailler en HTML grâce au CSS. Pour créer une hiérarchie dans les citations, nous ajoutons des “&gt;”  : &gt; La citation de départ &gt; &gt;&gt; une hiérarchie dans la citation ce qui donne : La citation de départ une hiérarchie dans la citation 3.2.2 Intégration de R dans le document L’intérêt du package rmarkdown est d’étendre la syntaxe Pandoc Markdown avec les fonctionnalités du package knitr pour insérer non seulement du code R mais aussi les sorties associées (sorties console et figures). Nous obtenons ainsi un document dynamique en ce sens que si les données associées et/ou le code R changent, le document évolue aussi. Cela permet, entre autres, de créer des rapports automatisés. Il y existe deux manières d’insérer des sorties R dans le document: directement dans le texte (“inline”); en utilisant un bloc de code dédié. Pour inclure une sortie texte directement dans un paragraphe, nous utilisons  : `r expression`. Par exemple, il est possible d’insérer l’heure et la date en utilisant la fonction R Sys.time(). Ainsi, l’utilisation de `r Sys.time()`  dans le texte affichera la sortie de cette fonction R, soit 2022-06-10 10:06:45. Le reste de cette section se concentre sur les blocs de code R (appelés code chunks en anglais). Typiquement, l’utilisation d’un tel bloc de code ressemble à ceci : ```{r, idbloc, param1 = val1, param2 = val2} ligne de code 1 ligne de code 2 ... ligne de code n ``` idbloc est le nom de l’identifiant que vous pouvez donner au bloc de code. Ceci permet de citer les blocs ou leurs sorties à l’intérieur du document. L’identifiant n’est pas obligatoire. En revanche, un identifiant donné ne peut être utilisé qu’une seule fois. param1 = val1 correspond à un paramètre permettant de préciser comment le code source sera affiché dans le document, ou comment la sortie du code sera affichée. Il existe un grand nombre de paramètres possibles. Ils permettent de mettre de l’avant certaines parties du code, et aussi de choisir finement les sorties R (figures, tables, etc.) à ajouter aux documents. L’ensemble des paramètres sont disponibles à l’URL suivante https://yihui.org/knitr/options/). Les commentaires Les commentaires sont introduits, comme dans R, sous la forme de lignes de codes commençant par un #. Débutons avec un exemple simple qui inclut un commentaire et une addition : ```{r, addition} # une addition avec R. 2+3 ``` Notez que le terme “addition” qui suit “r” dans l’accolade est l’identifiant du morceau de code (la virgule entre les deux premiers éléments est facultative). Ce morceau de code s’affiche ainsi: # une addition avec R. 2+3 [1] 5 Nous obtenons donc code R dans un environnement adéquate (voir la coloration du code) avec la sortie console associée, en l’occurrence, le résultat de l’addition. Modifier l’affichage du code source avec le paramètre echo Prenons le bloc de code suivant. ``{r} # une addition de variables avec R a &lt;- 2 b &lt;- 3 a + b &lt;br&gt; ```r # une addition de variables avec R a &lt;- 2 b &lt;- 3 a + b [1] 5 Afin de ne pas afficher le code source dans un document (parce que nous souhaitement uniquement afficher la sortie produite par le code), il suffit d’utiliser le paramètre echo = FALSE, (echo = TRUE par défaut). Ainsi, le bloc de code sanscode ``{r sanscode, echo = FALSE} # une addition de variables avec R a &lt;- 2 b &lt;- 3 a + b ``` nous donne: [1] 5 Le paramètre echo peut aussi être utilisé pour choisir les lignes à montrer. Pour cela, nous utilisons un vecteur indiquant les positions des lignes à montrer. Par exemple, pour montrer uniquement les lignes 1 et 4, nous utilisons: ``{r code14, echo = c(1, 4)} # une addition de variables avec R a &lt;- 2 b &lt;- 3 a + b ``` ce qui donne: # une addition de variables avec R a + b [1] 5 3.2.3 À vous de jouer ! À venir Vous pouvez également consulter le site de référence de Pandoc et le résumé à la première page du guide de référence R Markdown. Pour une source en français, le guide “Élaboration et conversion de documents avec Markdown et Pandoc” (http://enacit1.epfl.ch/markdown-pandoc/) écrit par Jean-Daniel Bonjour fournit un excellent tour d’horizon.↩︎ "],["vec.html", "Module 4 Données vectorielles", " Module 4 Données vectorielles Cette leçon est une introduction aux données spatiales vectorielles sous R. L’objectif principal de ce module est d’apprendre à créer, lire, interpréter et visualiser des données vectorielles27. La section 4.1 expliquera comment créer des données vectorielles. Les sections 4.2-4.4 porteront sur des données vectorielles en format shapefile puisque celles-ci sont couramment utilisées. La section 4.5 vous familiarisera avec les données vectorielles en format geodatabase puisque celles-ci sont de plus en plus utilisées au sein de grandes organisations comme des ministères. À la fin de ce module vous saurez: Créer des données vectorielles et comprendre leur structure. Lire un shapefile, explorer ses métadonnées et interpréter sa géométrie. Lire une geodatabase, et explorer ses couches. Visualiser des données vectorielles de type point, ligne et polygone. Visualiser des données vectorielles par attribut. Visualiser plusieurs données vectorielles au sein d’une même figure. Transformer le système de coordonnées de référence de données vectorielles. Vous utiliserez les bibliothèques suivantes: sf rgdal mapview leafsync spData Installez ces librairies si vous ne les avez pas: install.packages(c(&#39;sf&#39;, &#39;rgdal&#39;, &#39;mapview&#39;, &#39;leafsync&#39;, &#39;spData&#39;)) Vous apprendrez à utiliser les fonctions suivantes: st_point(), st_multipoint() st_linestring(), st_multilinestring() st_polygon(), st_multipolygon() st_sfc() st_sf() st_as_sf() st_read() st_write() st_geometry_type() st_crs() st_bbox() mapview() st_transform() latticeView() as.factor() levels() class() Vous utiliserez les données suivantes: Dans la section leçon, vous utiliserez deux ensembles de données vectorielles. Le premier ensemble contient des données shapefile relatives au réseau de pistes cyclables de la ville de Montréal et aux accidents routiers impliquant des bicyclettes. Le second ensemble constitue une géodatabase contenant des données du Ministère de l’Éducation et de l’Enseignement Supérieur du Québec relatives aux établissements d’enseignement sur le territoire québécois. Dans la section exercice, vous utiliserez les données vectorielles nz disponibles dans la bibliothèque spData. Le matériel pour ce cours est tiré du chapitre sur les données vectorielles du manuel Geocomputation with R (Lovelace, Nowosad, and Muenchow 2021) et du cours Introduction to Geospatial Raster and Vector Data with R (Wasser et al., n.d.) de l’organisme Data Carpentry. Data Carpentry développe et offre des formations variées et spécialisées sur le traitement et l’analyse de données. Ses formations s’adressent surtout aux chercheuses et chercheurs scientifiques, mais peuvent être consultées par quiconque car leur matériel est libre d’accès. N’hésitez donc pas à y jeter un coup d’œil.↩︎ "],["lecon_vec.html", "4.1 Leçon", " 4.1 Leçon 4.1.1 Télécharger les données Les données Dans les sections 4.1.3 à 4.1.6 du présent module vous apprendrez à lire et visualiser des données déjà existantes. Afin de faciliter le téléchargement de ces multiples données, l’ensemble des couches d’informations spatiales peuvent être téléchargées en cliquant sur un seul lien: données pour le module 4. Sauvegardez le dossier compressé (zip) dans votre répertoire de travail Module4_donnees pour ce module, et dézippez-le. Le dossier comprend lui même deux dossiers compressés et un fichier csv: Montreal_Velo.zip Donnees_Ouvertes_MEES.gbd.zip nz_capitales.csv Dézipper chacun des deux dossiers. Le premier dossier, Montreal_Velo sera utilisé aux sections 4.1.3-4.1.5. Il contient les données vectorielles relatives au réseau de pistes cyclables de la ville de Montréal et aux accidents routiers impliquant des bicyclettes. Il contient trois sous-dossiers: accidents pistes terre. Le deuxième dossier, Donnees_Ouvertes_MEES.gbd est la geodatabase du Ministère de l’Éducation et de l’Enseignement Supérieur du Québec (MEES); nous l’utiliserons à la section 4.1.6. Le fichier nz_capitales.csv contient les coordonnées géographiques des capitales des régions administratives de la Nouvelle-Zélande; nous l’utiliserons à la section exercices à la fin de ce module. 4.1.2 Créer des données vectorielles Pour créer, lire et manipuler des données vectorielles, nous allons utiliser la bibliothèque sf. Notez que la bibliothèque rgdal se charge automatiquement lorsque sf se charge. library(sf) Créer des géométries simples Nous avons appris à la leçon 2 que les données vectorielles peuvent avoir différentes géométries (point, ligne, polygone, etc.). La bibliothèque sf possède des fonctions pour créer ces géométries simples, c’est-à-dire pour créer des objects de la classe sfg (pour simple feature geometry). La fonction st_point() permet de transformer un vecteur numérique représentant les coordonnées d’un point en un objet de type point. Par exemple, p &lt;- c(3,5) point &lt;- st_point(p) point POINT (3 5) Remarquez que la classe de l’objet formé est sfg: class(point) [1] &quot;XY&quot; &quot;POINT&quot; &quot;sfg&quot; La fonction st_multipoint() permet de créer une géométrie multipoint. Nous devons fournir à cette fonction une matrice où chaque rangée définie les coordonnées d’un des points: M &lt;- rbind( c(3,5), c(5,5), c(4,1), c(2,3)) multi_point &lt;- st_multipoint(M) multi_point MULTIPOINT ((3 5), (5 5), (4 1), (2 3)) La fonction st_linestring() permet de créer une ligne. Nous devons également lui fournir une matrice contenant les coordonnées des extrémités de la ligne. ligne &lt;- st_linestring(M) ligne LINESTRING (3 5, 5 5, 4 1, 2 3) Un polygone se crée de façon similaire, cette fois en utilisant la fonction st_polygon(). Les coordonnées des extrémités du polygone doivent toutefois être définies dans une liste, et non une matrice. Il s’agit alors d’utiliser la fonction list() pour convertir une matrice en liste. L &lt;- list(rbind( c(3,5), c(5,5), c(4,1), c(2,3), c(3,5))) polygone &lt;-st_polygon(L) polygone POLYGON ((3 5, 5 5, 4 1, 2 3, 3 5)) Noter que pour créer un polygone la première extrémité doit être identique à la dernière. Dans un même ordre d’idées, pour créer des multi-lignes ou des multi-polygones nous devons aussi recourrir à des listes où chaque élément de la liste correspond à une ligne ou à un polygone respectivement. M1 &lt;- rbind( c(3,5), c(5,5), c(4,1), c(2,3)) M2 &lt;- rbind( c(1,2), c(2,2), c(2,1)) L &lt;- list(M1, M2) multi_ligne &lt;- st_multilinestring(L) multi_ligne MULTILINESTRING ((3 5, 5 5, 4 1, 2 3), (1 2, 2 2, 2 1)) L1 &lt;- list(rbind( c(3,5), c(5,5), c(4,1), c(2,3), c(3,5))) L2 &lt;- list(rbind( c(1,2), c(2,2), c(2,1), c(1,2))) L &lt;- list(L1, L2) multi_polygone &lt;- st_multipolygon(L) multi_polygone MULTIPOLYGON (((3 5, 5 5, 4 1, 2 3, 3 5)), ((1 2, 2 2, 2 1, 1 2))) Attribuer un SCR Nous venons d’apprendre les fonctions de base de la bibliothèque sf pour créer des géométries simples. Or, les données vectorielles ne sont pas uniquement des géométries, ce sont des géométries géoréférencées. Ceci signifie qu’on doit attribuer aux géométries un datum et une projection. Pour ce faire, nous devons créer des objets de la classe sfc, c’est-à-dire simple feature columns. Un objet sfc est une liste d’objets sfg qui permet, en plus, de contenir l’information relative au système de coordonnées de référence (SRC) utilisé. La fonction st_sfc() permet de transformer un objet de classe sfg en un objet de classe sfc. Par exemple, transformons le point créer plus haut: point_sfc &lt;- st_sfc(point) Alors que l’objet point contenait seulement la géométrie de l’objet: point POINT (3 5) L’objet point_sfc contient la géométrie de l’objet et il possède la structure pour définir le SCR (CRS en anglais), bien que pour l’instant ce dernier ne soit pas défini (valeur de NA): point_sfc Geometry set for 1 feature Geometry type: POINT Dimension: XY Bounding box: xmin: 3 ymin: 5 xmax: 3 ymax: 5 CRS: NA POINT (3 5) La fonction st_sfc() peut être utilisée sur les autres géométries. Elle permet également de combiner des géométries. Par exemple: L1 &lt;- list(rbind( c(3,5), c(5,5), c(4,1), c(2,3), c(3,5))) polygone1 &lt;- st_polygon(L1) L2 &lt;- list(rbind( c(1,2), c(2,2), c(2,1), c(1,2))) polygone2 &lt;- st_polygon(L2) polygone_sfc &lt;- st_sfc(polygone1, polygone2) polygone_sfc Geometry set for 2 features Geometry type: POLYGON Dimension: XY Bounding box: xmin: 1 ymin: 1 xmax: 5 ymax: 5 CRS: NA POLYGON ((3 5, 5 5, 4 1, 2 3, 3 5)) POLYGON ((1 2, 2 2, 2 1, 1 2)) Pour connaître le SCR d’un object vectoriel, il s’agit d’utiliser la fonction st_crs() de la bibliothèque st: st_crs(polygone_sfc) Coordinate Reference System: NA Dans le cas présent, le SCR est indéfini. Il existe plusieurs façons de définir le SCR. La façon la plus simple est d’utiliser le code EPSG associé au SCR que l’on désire utilisé. Par exemple, utilisons le EPSG 32198 correspondant au système de coordonnées conique conforme de Lambert dans le datum NAD83 pour définir le CRS de polygone_sfc: polygone_sfc &lt;- st_sfc(polygone1, polygone2, crs = 32198) st_crs(polygone_sfc) Coordinate Reference System: User input: EPSG:32198 wkt: PROJCRS[&quot;NAD83 / Quebec Lambert&quot;, BASEGEOGCRS[&quot;NAD83&quot;, DATUM[&quot;North American Datum 1983&quot;, ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, LENGTHUNIT[&quot;metre&quot;,1]]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ID[&quot;EPSG&quot;,4269]], CONVERSION[&quot;Quebec Lambert Projection&quot;, METHOD[&quot;Lambert Conic Conformal (2SP)&quot;, ID[&quot;EPSG&quot;,9802]], PARAMETER[&quot;Latitude of false origin&quot;,44, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8821]], PARAMETER[&quot;Longitude of false origin&quot;,-68.5, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8822]], PARAMETER[&quot;Latitude of 1st standard parallel&quot;,60, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8823]], PARAMETER[&quot;Latitude of 2nd standard parallel&quot;,46, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8824]], PARAMETER[&quot;Easting at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8826]], PARAMETER[&quot;Northing at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8827]]], CS[Cartesian,2], AXIS[&quot;easting (X)&quot;,east, ORDER[1], LENGTHUNIT[&quot;metre&quot;,1]], AXIS[&quot;northing (Y)&quot;,north, ORDER[2], LENGTHUNIT[&quot;metre&quot;,1]], USAGE[ SCOPE[&quot;Topographic mapping (medium and small scale).&quot;], AREA[&quot;Canada - Quebec.&quot;], BBOX[44.99,-79.85,62.62,-57.1]], ID[&quot;EPSG&quot;,32198]] Nous pouvons également utilisé la notation proj4string: st_crs(polygone_sfc)$proj4string [1] &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; st_sfc(point, crs = &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot;) Geometry set for 1 feature Geometry type: POINT Dimension: XY Bounding box: xmin: 3 ymin: 5 xmax: 3 ymax: 5 CRS: +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs POINT (3 5) Ou encore référé au SCR d’un autre objet: st_sfc(point, crs = st_crs(polygone_sfc)) Geometry set for 1 feature Geometry type: POINT Dimension: XY Bounding box: xmin: 3 ymin: 5 xmax: 3 ymax: 5 Projected CRS: NAD83 / Quebec Lambert POINT (3 5) Définir des attributs Les attributs sont les variables non-géographiques permettant de décrire les données vectorielles. Les attributs peuvent, par exemple, correspondre au nom de chaque objet ou à d’autres caractéristiques qualitatives ou numériques. Les attributs sont répertoriés dans un objet de classe data.frame, qui est en quelque sorte une matrice dont les colonnes peuvent accueillir des données de différents types (numérique, charactère, logique, facteur, etc.). Afin de démontrer comment joindre des attibuts à des géométries géoréférencées, créons d’abord un objet sfc constitué de quatre points. # Créer quatre vecteurs numériques p1 &lt;- c(3,5) p2 &lt;- c(5,5) p3 &lt;- c(4,1) p4 &lt;- c(2,3) # Créer des géométries de type point point1 &lt;- st_point(p1) point2 &lt;- st_point(p2) point3 &lt;- st_point(p3) point4 &lt;- st_point(p4) # Créer un simple feature column # et attribuer un SRC points_sfc &lt;- st_sfc(point1,point2,point3,point4, crs = 32198) points_sfc Geometry set for 4 features Geometry type: POINT Dimension: XY Bounding box: xmin: 2 ymin: 1 xmax: 5 ymax: 5 Projected CRS: NAD83 / Quebec Lambert POINT (3 5) POINT (5 5) POINT (4 1) POINT (2 3) Supposons que les points désignent des écoles primaires pouvant être publiques ou privées. Utilisons la fonction data.frame(), une fonction de base de R pour créer une table des attributs. points_attribut &lt;- data.frame( nom = c(&quot;École A&quot;, &quot;École B&quot;, &quot;École C&quot;, &quot;École D&quot;), nombre_eleves = c(403, 357, 280, 296), ecole_publique = as.logical(1, 1, 0, 1) ) points_attribut nom nombre_eleves ecole_publique 1 École A 403 TRUE 2 École B 357 TRUE 3 École C 280 TRUE 4 École D 296 TRUE Remarquer que chaque colonne est associée à un attribut de classe différente, comme le permet la classe data.frame. Pour associer cette table d’attributs à l’objet points_sfc, il s’agit d’utiliser la fonction st_sf() de la bilbiothèque sf: points_sf &lt;- st_sf(points_sfc, points_attribut) points_sf Simple feature collection with 4 features and 3 fields Geometry type: POINT Dimension: XY Bounding box: xmin: 2 ymin: 1 xmax: 5 ymax: 5 Projected CRS: NAD83 / Quebec Lambert nom nombre_eleves ecole_publique points_sfc 1 École A 403 TRUE POINT (3 5) 2 École B 357 TRUE POINT (5 5) 3 École C 280 TRUE POINT (4 1) 4 École D 296 TRUE POINT (2 3) L’objet points_sf résultant de cette opération contient deux classes: class(points_sf) [1] &quot;sf&quot; &quot;data.frame&quot; La composante de classe sf (pour simple feature) contient les attributs spatiaux des données tandis que la composante de classe data.frame contient les attributs non-spatiaux. Cette dualité est une caractéristique importante des objets de classe sf: ceux-ci sont essentiellement des data.frames avec une extension spatiale et nous pouvons ainsi les manipuler comme des data.frames. Nous reviendrons sur ce concept au Module 7 portant sur la manipulation de données vectorielles. La fonction st_as_sf() La fonction st_as_sf() de la bibliothèque sf permet de créer un objet de classe sf à partir d’un objet d’une autre classe. En particulier, elle permet de convertir en un objet sf de type points un data.frame qui contient des colonnes donnant les coordonnées de chaque élément. Donnons un exemple. Considérons le tableau suivant: point_df &lt;- data.frame( points = c(&quot;alpha&quot; ,&quot;beta&quot; ,&quot;gamma&quot;, &quot;delta&quot;), x = c(10, 20, 30, 40), y = c(25, 5, 15, 35) ) Utilisons la fonction st_as_sf() avec l’argument coords. points_sf &lt;- st_as_sf(point_df, coords = c(&quot;x&quot;,&quot;y&quot;)) points_sf Simple feature collection with 4 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: 10 ymin: 5 xmax: 40 ymax: 35 CRS: NA points geometry 1 alpha POINT (10 25) 2 beta POINT (20 5) 3 gamma POINT (30 15) 4 delta POINT (40 35) Nous pouvons également définir un SCR en utilisant l’argument crs. points_sf &lt;- st_as_sf(point_df, coords = c(&quot;x&quot;,&quot;y&quot;), crs = 32182) points_sf Simple feature collection with 4 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: 10 ymin: 5 xmax: 40 ymax: 35 Projected CRS: NAD83 / MTM zone 2 points geometry 1 alpha POINT (10 25) 2 beta POINT (20 5) 3 gamma POINT (30 15) 4 delta POINT (40 35) 4.1.3 Lire un shapefile et interpréter sa géométrie Lire les données Nous allons lire les trois shapefiles suivants : Des données vectorielles de type polygone représentant la frontière de notre zone d’étude, ici, l’île de Montréal. Des données vectorielles de type ligne représentant les pistes cyclables sur l’île de Montréal, et Des données vectorielles de type point représentant la position d’accidents impliquant des bicyclettes. Dans un premier temps, nous allons ouvrir les données vectorielles de type polygone qui contiennent les limites terrestres de l’île de Montréal. Pour lire ces données nous utiliserons la fonction st_read() de la bibliothèque sf. Pour utiliser st_read() nous devons spécifier le chemin menant au fichier shapefile à lire. limites_terrestres &lt;- st_read(&quot;Module4/Module4_donnees/Montreal_Velo/terre/terre_shp.shp&quot;) Reading layer `terre_shp&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module4/Module4_donnees/Montreal_Velo/terre/terre_shp.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 72 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: 267500 ymin: 5029000 xmax: 306700 ymax: 5063000 Projected CRS: NAD83 / MTM zone 8 La fonction st_read() vous permet d’ores et déjà d’obtenir certaines informations sur la structure des données vectorielles que vous venez de lire: le type de géométrie (Geometry type), la dimension des données (Dimension), l’étendue spatiale des données (Bounding box), et le système de coordonnées projetées (Projected CRS). Nous explorerons ces propriétés en détails plus bas. Nous allons maintenant lire les données vectorielles de type ligne, en utilisant encore la fonction st_read(). pistes_cyclables &lt;- st_read(&quot;Module4/Module4_donnees/Montreal_Velo/pistes/pistes_cyclables_type.shp&quot;) Reading layer `pistes_cyclables_type&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module4/Module4_donnees/Montreal_Velo/pistes/pistes_cyclables_type.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 6395 features and 1 field Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: 268000 ymin: 5029000 xmax: 306300 ymax: 5063000 Projected CRS: Transverse_Mercator Finalement, nous allons lire les données vectorielles de type point, en utilisant toujours la fonction st_read(). accidents_velo &lt;- st_read(&quot;Module4/Module4_donnees/Montreal_Velo/accidents/accidents2018_Mtl_velo.shp&quot;) Reading layer `accidents2018_Mtl_velo&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module4/Module4_donnees/Montreal_Velo/accidents/accidents2018_Mtl_velo.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 796 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: 269500 ymin: 5030000 xmax: 305400 ymax: 5059000 Projected CRS: Transverse_Mercator Remarquez que le type de géométrie (Geometry type) diffère pour les trois classes de données lues comme nous nous y attendions. Explorer les métadonnées d’un shapefile Les informations contenues dans un shapefile sont appelées des métadonnées. Nous sommes particulièrement intéressées aux métadonnées géospatiales. Les métadonnées fondamentales d’un shapefile sont : Le type de géométrie : le type de classes des données vectorielles téléchargées. La projection : le système de coordonnées de référence utilisé pour représenter les données. L’étendue spatiale : la superficie géographique couvrant les données vectorielles. Le type de géométrie Nous pouvons explorer chacune de ces métadonnées en utilisant des fonctions de la librairie sf. Le type de géométrie est obtenu par la fonction st_geometry_type(). Par exemple, pour les limites terrestres de la ville de Montréal, cette fonction nous donne: st_geometry_type(limites_terrestres) [1] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [7] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [13] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [19] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [25] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [31] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [37] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [43] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [49] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [55] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [61] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [67] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON 18 Levels: GEOMETRY POINT LINESTRING ... TRIANGLE Nous avons ainsi la confirmation que ces données vectorielles correspondent à des polygones (plus exactement, 72 polygones). Les 18 niveaux donnés en dessous constituent une liste des classes possibles de géométrie. En comparaison, pour les données de type ligne et de type point nous obtenons plutôt : st_geometry_type(pistes_cyclables) [1] MULTILINESTRING MULTILINESTRING MULTILINESTRING [4] MULTILINESTRING MULTILINESTRING MULTILINESTRING [7] MULTILINESTRING MULTILINESTRING MULTILINESTRING [10] MULTILINESTRING MULTILINESTRING MULTILINESTRING [13] MULTILINESTRING MULTILINESTRING MULTILINESTRING [16] MULTILINESTRING MULTILINESTRING MULTILINESTRING [19] MULTILINESTRING MULTILINESTRING MULTILINESTRING [22] MULTILINESTRING MULTILINESTRING MULTILINESTRING [25] MULTILINESTRING MULTILINESTRING MULTILINESTRING [28] MULTILINESTRING MULTILINESTRING MULTILINESTRING [31] MULTILINESTRING MULTILINESTRING MULTILINESTRING [34] MULTILINESTRING MULTILINESTRING MULTILINESTRING [37] MULTILINESTRING MULTILINESTRING MULTILINESTRING [40] MULTILINESTRING MULTILINESTRING MULTILINESTRING [43] MULTILINESTRING MULTILINESTRING MULTILINESTRING [46] MULTILINESTRING MULTILINESTRING MULTILINESTRING [49] MULTILINESTRING MULTILINESTRING MULTILINESTRING [52] MULTILINESTRING MULTILINESTRING MULTILINESTRING [55] MULTILINESTRING MULTILINESTRING MULTILINESTRING [58] MULTILINESTRING MULTILINESTRING MULTILINESTRING [61] MULTILINESTRING MULTILINESTRING MULTILINESTRING [64] MULTILINESTRING MULTILINESTRING MULTILINESTRING [67] MULTILINESTRING MULTILINESTRING MULTILINESTRING [70] MULTILINESTRING MULTILINESTRING MULTILINESTRING [73] MULTILINESTRING MULTILINESTRING MULTILINESTRING [76] MULTILINESTRING MULTILINESTRING MULTILINESTRING [79] MULTILINESTRING MULTILINESTRING MULTILINESTRING [82] MULTILINESTRING MULTILINESTRING MULTILINESTRING [85] MULTILINESTRING MULTILINESTRING MULTILINESTRING [88] MULTILINESTRING MULTILINESTRING MULTILINESTRING [91] MULTILINESTRING MULTILINESTRING MULTILINESTRING [94] MULTILINESTRING MULTILINESTRING MULTILINESTRING [97] MULTILINESTRING MULTILINESTRING MULTILINESTRING [100] MULTILINESTRING MULTILINESTRING MULTILINESTRING [103] MULTILINESTRING MULTILINESTRING MULTILINESTRING [106] MULTILINESTRING MULTILINESTRING MULTILINESTRING [109] MULTILINESTRING MULTILINESTRING MULTILINESTRING [112] MULTILINESTRING MULTILINESTRING MULTILINESTRING [115] MULTILINESTRING MULTILINESTRING MULTILINESTRING [118] MULTILINESTRING MULTILINESTRING MULTILINESTRING [121] MULTILINESTRING MULTILINESTRING MULTILINESTRING [124] MULTILINESTRING MULTILINESTRING MULTILINESTRING [127] MULTILINESTRING MULTILINESTRING MULTILINESTRING [130] MULTILINESTRING MULTILINESTRING MULTILINESTRING [133] MULTILINESTRING MULTILINESTRING MULTILINESTRING [136] MULTILINESTRING MULTILINESTRING MULTILINESTRING [139] MULTILINESTRING MULTILINESTRING MULTILINESTRING [142] MULTILINESTRING MULTILINESTRING MULTILINESTRING [145] MULTILINESTRING MULTILINESTRING MULTILINESTRING [148] MULTILINESTRING MULTILINESTRING MULTILINESTRING [151] MULTILINESTRING MULTILINESTRING MULTILINESTRING [154] MULTILINESTRING MULTILINESTRING MULTILINESTRING [157] MULTILINESTRING MULTILINESTRING MULTILINESTRING [160] MULTILINESTRING MULTILINESTRING MULTILINESTRING [163] MULTILINESTRING MULTILINESTRING MULTILINESTRING [166] MULTILINESTRING MULTILINESTRING MULTILINESTRING [169] MULTILINESTRING MULTILINESTRING MULTILINESTRING [172] MULTILINESTRING MULTILINESTRING MULTILINESTRING [175] MULTILINESTRING MULTILINESTRING MULTILINESTRING [178] MULTILINESTRING MULTILINESTRING MULTILINESTRING [181] MULTILINESTRING MULTILINESTRING MULTILINESTRING [184] MULTILINESTRING MULTILINESTRING MULTILINESTRING [187] MULTILINESTRING MULTILINESTRING MULTILINESTRING [190] MULTILINESTRING MULTILINESTRING MULTILINESTRING [193] MULTILINESTRING MULTILINESTRING MULTILINESTRING [196] MULTILINESTRING MULTILINESTRING MULTILINESTRING [199] MULTILINESTRING MULTILINESTRING MULTILINESTRING [202] MULTILINESTRING MULTILINESTRING MULTILINESTRING [205] MULTILINESTRING MULTILINESTRING MULTILINESTRING [208] MULTILINESTRING MULTILINESTRING MULTILINESTRING [211] MULTILINESTRING MULTILINESTRING MULTILINESTRING [214] MULTILINESTRING MULTILINESTRING MULTILINESTRING [217] MULTILINESTRING MULTILINESTRING MULTILINESTRING [220] MULTILINESTRING MULTILINESTRING MULTILINESTRING [223] MULTILINESTRING MULTILINESTRING MULTILINESTRING [226] MULTILINESTRING MULTILINESTRING MULTILINESTRING [229] MULTILINESTRING MULTILINESTRING MULTILINESTRING [232] MULTILINESTRING MULTILINESTRING MULTILINESTRING [235] MULTILINESTRING MULTILINESTRING MULTILINESTRING [238] MULTILINESTRING MULTILINESTRING MULTILINESTRING [241] MULTILINESTRING MULTILINESTRING MULTILINESTRING [244] MULTILINESTRING MULTILINESTRING MULTILINESTRING [247] MULTILINESTRING MULTILINESTRING MULTILINESTRING [250] MULTILINESTRING MULTILINESTRING MULTILINESTRING [253] MULTILINESTRING MULTILINESTRING MULTILINESTRING [256] MULTILINESTRING MULTILINESTRING MULTILINESTRING [259] MULTILINESTRING MULTILINESTRING MULTILINESTRING [262] MULTILINESTRING MULTILINESTRING MULTILINESTRING [265] MULTILINESTRING MULTILINESTRING MULTILINESTRING [268] MULTILINESTRING MULTILINESTRING MULTILINESTRING [271] MULTILINESTRING MULTILINESTRING MULTILINESTRING [274] MULTILINESTRING MULTILINESTRING MULTILINESTRING [277] MULTILINESTRING MULTILINESTRING MULTILINESTRING [280] MULTILINESTRING MULTILINESTRING MULTILINESTRING [283] MULTILINESTRING MULTILINESTRING MULTILINESTRING [286] MULTILINESTRING MULTILINESTRING MULTILINESTRING [289] MULTILINESTRING MULTILINESTRING MULTILINESTRING [292] MULTILINESTRING MULTILINESTRING MULTILINESTRING [295] MULTILINESTRING MULTILINESTRING MULTILINESTRING [298] MULTILINESTRING MULTILINESTRING MULTILINESTRING [301] MULTILINESTRING MULTILINESTRING MULTILINESTRING [304] MULTILINESTRING MULTILINESTRING MULTILINESTRING [307] MULTILINESTRING MULTILINESTRING MULTILINESTRING [310] MULTILINESTRING MULTILINESTRING MULTILINESTRING [313] MULTILINESTRING MULTILINESTRING MULTILINESTRING [316] MULTILINESTRING MULTILINESTRING MULTILINESTRING [319] MULTILINESTRING MULTILINESTRING MULTILINESTRING [322] MULTILINESTRING MULTILINESTRING MULTILINESTRING [325] MULTILINESTRING MULTILINESTRING MULTILINESTRING [328] MULTILINESTRING MULTILINESTRING MULTILINESTRING [331] MULTILINESTRING MULTILINESTRING MULTILINESTRING [334] MULTILINESTRING MULTILINESTRING MULTILINESTRING [337] MULTILINESTRING MULTILINESTRING MULTILINESTRING [340] MULTILINESTRING MULTILINESTRING MULTILINESTRING [343] MULTILINESTRING MULTILINESTRING MULTILINESTRING [346] MULTILINESTRING MULTILINESTRING MULTILINESTRING [349] MULTILINESTRING MULTILINESTRING MULTILINESTRING [352] MULTILINESTRING MULTILINESTRING MULTILINESTRING [355] MULTILINESTRING MULTILINESTRING MULTILINESTRING [358] MULTILINESTRING MULTILINESTRING MULTILINESTRING [361] MULTILINESTRING MULTILINESTRING MULTILINESTRING [364] MULTILINESTRING MULTILINESTRING MULTILINESTRING [367] MULTILINESTRING MULTILINESTRING MULTILINESTRING [370] MULTILINESTRING MULTILINESTRING MULTILINESTRING [373] MULTILINESTRING MULTILINESTRING MULTILINESTRING [376] MULTILINESTRING MULTILINESTRING MULTILINESTRING [379] MULTILINESTRING MULTILINESTRING MULTILINESTRING [382] MULTILINESTRING MULTILINESTRING MULTILINESTRING [385] MULTILINESTRING MULTILINESTRING MULTILINESTRING [388] MULTILINESTRING MULTILINESTRING MULTILINESTRING [391] MULTILINESTRING MULTILINESTRING MULTILINESTRING [394] MULTILINESTRING MULTILINESTRING MULTILINESTRING [397] MULTILINESTRING MULTILINESTRING MULTILINESTRING [400] MULTILINESTRING MULTILINESTRING MULTILINESTRING [403] MULTILINESTRING MULTILINESTRING MULTILINESTRING [406] MULTILINESTRING MULTILINESTRING MULTILINESTRING [409] MULTILINESTRING MULTILINESTRING MULTILINESTRING [412] MULTILINESTRING MULTILINESTRING MULTILINESTRING [415] MULTILINESTRING MULTILINESTRING MULTILINESTRING [418] MULTILINESTRING MULTILINESTRING MULTILINESTRING [421] MULTILINESTRING MULTILINESTRING MULTILINESTRING [424] MULTILINESTRING MULTILINESTRING MULTILINESTRING [427] MULTILINESTRING MULTILINESTRING MULTILINESTRING [430] MULTILINESTRING MULTILINESTRING MULTILINESTRING [433] MULTILINESTRING MULTILINESTRING MULTILINESTRING [436] MULTILINESTRING MULTILINESTRING MULTILINESTRING [439] MULTILINESTRING MULTILINESTRING MULTILINESTRING [442] MULTILINESTRING MULTILINESTRING MULTILINESTRING [445] MULTILINESTRING MULTILINESTRING MULTILINESTRING [448] MULTILINESTRING MULTILINESTRING MULTILINESTRING [451] MULTILINESTRING MULTILINESTRING MULTILINESTRING [454] MULTILINESTRING MULTILINESTRING MULTILINESTRING [457] MULTILINESTRING MULTILINESTRING MULTILINESTRING [460] MULTILINESTRING MULTILINESTRING MULTILINESTRING [463] MULTILINESTRING MULTILINESTRING MULTILINESTRING [466] MULTILINESTRING MULTILINESTRING MULTILINESTRING [469] MULTILINESTRING MULTILINESTRING MULTILINESTRING [472] MULTILINESTRING MULTILINESTRING MULTILINESTRING [475] MULTILINESTRING MULTILINESTRING MULTILINESTRING [478] MULTILINESTRING MULTILINESTRING MULTILINESTRING [481] MULTILINESTRING MULTILINESTRING MULTILINESTRING [484] MULTILINESTRING MULTILINESTRING MULTILINESTRING [487] MULTILINESTRING MULTILINESTRING MULTILINESTRING [490] MULTILINESTRING MULTILINESTRING MULTILINESTRING [493] MULTILINESTRING MULTILINESTRING MULTILINESTRING [496] MULTILINESTRING MULTILINESTRING MULTILINESTRING [499] MULTILINESTRING MULTILINESTRING MULTILINESTRING [502] MULTILINESTRING MULTILINESTRING MULTILINESTRING [505] MULTILINESTRING MULTILINESTRING MULTILINESTRING [508] MULTILINESTRING MULTILINESTRING MULTILINESTRING [511] MULTILINESTRING MULTILINESTRING MULTILINESTRING [514] MULTILINESTRING MULTILINESTRING MULTILINESTRING [517] MULTILINESTRING MULTILINESTRING MULTILINESTRING [520] MULTILINESTRING MULTILINESTRING MULTILINESTRING [523] MULTILINESTRING MULTILINESTRING MULTILINESTRING [526] MULTILINESTRING MULTILINESTRING MULTILINESTRING [529] MULTILINESTRING MULTILINESTRING MULTILINESTRING [532] MULTILINESTRING MULTILINESTRING MULTILINESTRING [535] MULTILINESTRING MULTILINESTRING MULTILINESTRING [538] MULTILINESTRING MULTILINESTRING MULTILINESTRING [541] MULTILINESTRING MULTILINESTRING MULTILINESTRING [544] MULTILINESTRING MULTILINESTRING MULTILINESTRING [547] MULTILINESTRING MULTILINESTRING MULTILINESTRING [550] MULTILINESTRING MULTILINESTRING MULTILINESTRING [553] MULTILINESTRING MULTILINESTRING MULTILINESTRING [556] MULTILINESTRING MULTILINESTRING MULTILINESTRING [559] MULTILINESTRING MULTILINESTRING MULTILINESTRING [562] MULTILINESTRING MULTILINESTRING MULTILINESTRING [565] MULTILINESTRING MULTILINESTRING MULTILINESTRING [568] MULTILINESTRING MULTILINESTRING MULTILINESTRING [571] MULTILINESTRING MULTILINESTRING MULTILINESTRING [574] MULTILINESTRING MULTILINESTRING MULTILINESTRING [577] MULTILINESTRING MULTILINESTRING MULTILINESTRING [580] MULTILINESTRING MULTILINESTRING MULTILINESTRING [583] MULTILINESTRING MULTILINESTRING MULTILINESTRING [586] MULTILINESTRING MULTILINESTRING MULTILINESTRING [589] MULTILINESTRING MULTILINESTRING MULTILINESTRING [592] MULTILINESTRING MULTILINESTRING MULTILINESTRING [595] MULTILINESTRING MULTILINESTRING MULTILINESTRING [598] MULTILINESTRING MULTILINESTRING MULTILINESTRING [601] MULTILINESTRING MULTILINESTRING MULTILINESTRING [604] MULTILINESTRING MULTILINESTRING MULTILINESTRING [607] MULTILINESTRING MULTILINESTRING MULTILINESTRING [610] MULTILINESTRING MULTILINESTRING MULTILINESTRING [613] MULTILINESTRING MULTILINESTRING MULTILINESTRING [616] MULTILINESTRING MULTILINESTRING MULTILINESTRING [619] MULTILINESTRING MULTILINESTRING MULTILINESTRING [622] MULTILINESTRING MULTILINESTRING MULTILINESTRING [625] MULTILINESTRING MULTILINESTRING MULTILINESTRING [628] MULTILINESTRING MULTILINESTRING MULTILINESTRING [631] MULTILINESTRING MULTILINESTRING MULTILINESTRING [634] MULTILINESTRING MULTILINESTRING MULTILINESTRING [637] MULTILINESTRING MULTILINESTRING MULTILINESTRING [640] MULTILINESTRING MULTILINESTRING MULTILINESTRING [643] MULTILINESTRING MULTILINESTRING MULTILINESTRING [646] MULTILINESTRING MULTILINESTRING MULTILINESTRING [649] MULTILINESTRING MULTILINESTRING MULTILINESTRING [652] MULTILINESTRING MULTILINESTRING MULTILINESTRING [655] MULTILINESTRING MULTILINESTRING MULTILINESTRING [658] MULTILINESTRING MULTILINESTRING MULTILINESTRING [661] MULTILINESTRING MULTILINESTRING MULTILINESTRING [664] MULTILINESTRING MULTILINESTRING MULTILINESTRING [667] MULTILINESTRING MULTILINESTRING MULTILINESTRING [670] MULTILINESTRING MULTILINESTRING MULTILINESTRING [673] MULTILINESTRING MULTILINESTRING MULTILINESTRING [676] MULTILINESTRING MULTILINESTRING MULTILINESTRING [679] MULTILINESTRING MULTILINESTRING MULTILINESTRING [682] MULTILINESTRING MULTILINESTRING MULTILINESTRING [685] MULTILINESTRING MULTILINESTRING MULTILINESTRING [688] MULTILINESTRING MULTILINESTRING MULTILINESTRING [691] MULTILINESTRING MULTILINESTRING MULTILINESTRING [694] MULTILINESTRING MULTILINESTRING MULTILINESTRING [697] MULTILINESTRING MULTILINESTRING MULTILINESTRING [700] MULTILINESTRING MULTILINESTRING MULTILINESTRING [703] MULTILINESTRING MULTILINESTRING MULTILINESTRING [706] MULTILINESTRING MULTILINESTRING MULTILINESTRING [709] MULTILINESTRING MULTILINESTRING MULTILINESTRING [712] MULTILINESTRING MULTILINESTRING MULTILINESTRING [715] MULTILINESTRING MULTILINESTRING MULTILINESTRING [718] MULTILINESTRING MULTILINESTRING MULTILINESTRING [721] MULTILINESTRING MULTILINESTRING MULTILINESTRING [724] MULTILINESTRING MULTILINESTRING MULTILINESTRING [727] MULTILINESTRING MULTILINESTRING MULTILINESTRING [730] MULTILINESTRING MULTILINESTRING MULTILINESTRING [733] MULTILINESTRING MULTILINESTRING MULTILINESTRING [736] MULTILINESTRING MULTILINESTRING MULTILINESTRING [739] MULTILINESTRING MULTILINESTRING MULTILINESTRING [742] MULTILINESTRING MULTILINESTRING MULTILINESTRING [745] MULTILINESTRING MULTILINESTRING MULTILINESTRING [748] MULTILINESTRING MULTILINESTRING MULTILINESTRING [751] MULTILINESTRING MULTILINESTRING MULTILINESTRING [754] MULTILINESTRING MULTILINESTRING MULTILINESTRING [757] MULTILINESTRING MULTILINESTRING MULTILINESTRING [760] MULTILINESTRING MULTILINESTRING MULTILINESTRING [763] MULTILINESTRING MULTILINESTRING MULTILINESTRING [766] MULTILINESTRING MULTILINESTRING MULTILINESTRING [769] MULTILINESTRING MULTILINESTRING MULTILINESTRING [772] MULTILINESTRING MULTILINESTRING MULTILINESTRING [775] MULTILINESTRING MULTILINESTRING MULTILINESTRING [778] MULTILINESTRING MULTILINESTRING MULTILINESTRING [781] MULTILINESTRING MULTILINESTRING MULTILINESTRING [784] MULTILINESTRING MULTILINESTRING MULTILINESTRING [787] MULTILINESTRING MULTILINESTRING MULTILINESTRING [790] MULTILINESTRING MULTILINESTRING MULTILINESTRING [793] MULTILINESTRING MULTILINESTRING MULTILINESTRING [796] MULTILINESTRING MULTILINESTRING MULTILINESTRING [799] MULTILINESTRING MULTILINESTRING MULTILINESTRING [802] MULTILINESTRING MULTILINESTRING MULTILINESTRING [805] MULTILINESTRING MULTILINESTRING MULTILINESTRING [808] MULTILINESTRING MULTILINESTRING MULTILINESTRING [811] MULTILINESTRING MULTILINESTRING MULTILINESTRING [814] MULTILINESTRING MULTILINESTRING MULTILINESTRING [817] MULTILINESTRING MULTILINESTRING MULTILINESTRING [820] MULTILINESTRING MULTILINESTRING MULTILINESTRING [823] MULTILINESTRING MULTILINESTRING MULTILINESTRING [826] MULTILINESTRING MULTILINESTRING MULTILINESTRING [829] MULTILINESTRING MULTILINESTRING MULTILINESTRING [832] MULTILINESTRING MULTILINESTRING MULTILINESTRING [835] MULTILINESTRING MULTILINESTRING MULTILINESTRING [838] MULTILINESTRING MULTILINESTRING MULTILINESTRING [841] MULTILINESTRING MULTILINESTRING MULTILINESTRING [844] MULTILINESTRING MULTILINESTRING MULTILINESTRING [847] MULTILINESTRING MULTILINESTRING MULTILINESTRING [850] MULTILINESTRING MULTILINESTRING MULTILINESTRING [853] MULTILINESTRING MULTILINESTRING MULTILINESTRING [856] MULTILINESTRING MULTILINESTRING MULTILINESTRING [859] MULTILINESTRING MULTILINESTRING MULTILINESTRING [862] MULTILINESTRING MULTILINESTRING MULTILINESTRING [865] MULTILINESTRING MULTILINESTRING MULTILINESTRING [868] MULTILINESTRING MULTILINESTRING MULTILINESTRING [871] MULTILINESTRING MULTILINESTRING MULTILINESTRING [874] MULTILINESTRING MULTILINESTRING MULTILINESTRING [877] MULTILINESTRING MULTILINESTRING MULTILINESTRING [880] MULTILINESTRING MULTILINESTRING MULTILINESTRING [883] MULTILINESTRING MULTILINESTRING MULTILINESTRING [886] MULTILINESTRING MULTILINESTRING MULTILINESTRING [889] MULTILINESTRING MULTILINESTRING MULTILINESTRING [892] MULTILINESTRING MULTILINESTRING MULTILINESTRING [895] MULTILINESTRING MULTILINESTRING MULTILINESTRING [898] MULTILINESTRING MULTILINESTRING MULTILINESTRING [901] MULTILINESTRING MULTILINESTRING MULTILINESTRING [904] MULTILINESTRING MULTILINESTRING MULTILINESTRING [907] MULTILINESTRING MULTILINESTRING MULTILINESTRING [910] MULTILINESTRING MULTILINESTRING MULTILINESTRING [913] MULTILINESTRING MULTILINESTRING MULTILINESTRING [916] MULTILINESTRING MULTILINESTRING MULTILINESTRING [919] MULTILINESTRING MULTILINESTRING MULTILINESTRING [922] MULTILINESTRING MULTILINESTRING MULTILINESTRING [925] MULTILINESTRING MULTILINESTRING MULTILINESTRING [928] MULTILINESTRING MULTILINESTRING MULTILINESTRING [931] MULTILINESTRING MULTILINESTRING MULTILINESTRING [934] MULTILINESTRING MULTILINESTRING MULTILINESTRING [937] MULTILINESTRING MULTILINESTRING MULTILINESTRING [940] MULTILINESTRING MULTILINESTRING MULTILINESTRING [943] MULTILINESTRING MULTILINESTRING MULTILINESTRING [946] MULTILINESTRING MULTILINESTRING MULTILINESTRING [949] MULTILINESTRING MULTILINESTRING MULTILINESTRING [952] MULTILINESTRING MULTILINESTRING MULTILINESTRING [955] MULTILINESTRING MULTILINESTRING MULTILINESTRING [958] MULTILINESTRING MULTILINESTRING MULTILINESTRING [961] MULTILINESTRING MULTILINESTRING MULTILINESTRING [964] MULTILINESTRING MULTILINESTRING MULTILINESTRING [967] MULTILINESTRING MULTILINESTRING MULTILINESTRING [970] MULTILINESTRING MULTILINESTRING MULTILINESTRING [973] MULTILINESTRING MULTILINESTRING MULTILINESTRING [976] MULTILINESTRING MULTILINESTRING MULTILINESTRING [979] MULTILINESTRING MULTILINESTRING MULTILINESTRING [982] MULTILINESTRING MULTILINESTRING MULTILINESTRING [985] MULTILINESTRING MULTILINESTRING MULTILINESTRING [988] MULTILINESTRING MULTILINESTRING MULTILINESTRING [991] MULTILINESTRING MULTILINESTRING MULTILINESTRING [994] MULTILINESTRING MULTILINESTRING MULTILINESTRING [997] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1000] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1003] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1006] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1009] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1012] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1015] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1018] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1021] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1024] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1027] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1030] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1033] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1036] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1039] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1042] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1045] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1048] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1051] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1054] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1057] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1060] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1063] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1066] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1069] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1072] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1075] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1078] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1081] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1084] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1087] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1090] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1093] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1096] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1099] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1102] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1105] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1108] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1111] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1114] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1117] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1120] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1123] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1126] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1129] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1132] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1135] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1138] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1141] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1144] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1147] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1150] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1153] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1156] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1159] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1162] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1165] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1168] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1171] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1174] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1177] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1180] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1183] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1186] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1189] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1192] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1195] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1198] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1201] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1204] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1207] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1210] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1213] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1216] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1219] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1222] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1225] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1228] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1231] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1234] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1237] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1240] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1243] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1246] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1249] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1252] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1255] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1258] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1261] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1264] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1267] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1270] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1273] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1276] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1279] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1282] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1285] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1288] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1291] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1294] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1297] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1300] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1303] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1306] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1309] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1312] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1315] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1318] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1321] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1324] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1327] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1330] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1333] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1336] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1339] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1342] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1345] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1348] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1351] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1354] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1357] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1360] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1363] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1366] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1369] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1372] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1375] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1378] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1381] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1384] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1387] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1390] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1393] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1396] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1399] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1402] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1405] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1408] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1411] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1414] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1417] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1420] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1423] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1426] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1429] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1432] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1435] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1438] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1441] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1444] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1447] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1450] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1453] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1456] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1459] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1462] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1465] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1468] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1471] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1474] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1477] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1480] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1483] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1486] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1489] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1492] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1495] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1498] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1501] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1504] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1507] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1510] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1513] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1516] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1519] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1522] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1525] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1528] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1531] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1534] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1537] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1540] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1543] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1546] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1549] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1552] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1555] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1558] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1561] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1564] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1567] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1570] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1573] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1576] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1579] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1582] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1585] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1588] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1591] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1594] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1597] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1600] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1603] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1606] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1609] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1612] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1615] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1618] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1621] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1624] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1627] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1630] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1633] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1636] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1639] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1642] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1645] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1648] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1651] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1654] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1657] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1660] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1663] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1666] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1669] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1672] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1675] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1678] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1681] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1684] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1687] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1690] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1693] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1696] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1699] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1702] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1705] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1708] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1711] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1714] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1717] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1720] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1723] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1726] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1729] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1732] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1735] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1738] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1741] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1744] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1747] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1750] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1753] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1756] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1759] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1762] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1765] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1768] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1771] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1774] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1777] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1780] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1783] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1786] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1789] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1792] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1795] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1798] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1801] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1804] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1807] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1810] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1813] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1816] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1819] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1822] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1825] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1828] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1831] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1834] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1837] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1840] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1843] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1846] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1849] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1852] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1855] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1858] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1861] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1864] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1867] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1870] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1873] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1876] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1879] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1882] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1885] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1888] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1891] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1894] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1897] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1900] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1903] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1906] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1909] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1912] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1915] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1918] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1921] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1924] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1927] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1930] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1933] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1936] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1939] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1942] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1945] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1948] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1951] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1954] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1957] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1960] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1963] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1966] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1969] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1972] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1975] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1978] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1981] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1984] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1987] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1990] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1993] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1996] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1999] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2002] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2005] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2008] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2011] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2014] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2017] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2020] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2023] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2026] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2029] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2032] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2035] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2038] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2041] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2044] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2047] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2050] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2053] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2056] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2059] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2062] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2065] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2068] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2071] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2074] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2077] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2080] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2083] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2086] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2089] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2092] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2095] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2098] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2101] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2104] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2107] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2110] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2113] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2116] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2119] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2122] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2125] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2128] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2131] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2134] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2137] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2140] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2143] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2146] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2149] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2152] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2155] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2158] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2161] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2164] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2167] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2170] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2173] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2176] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2179] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2182] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2185] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2188] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2191] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2194] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2197] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2200] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2203] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2206] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2209] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2212] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2215] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2218] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2221] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2224] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2227] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2230] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2233] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2236] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2239] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2242] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2245] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2248] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2251] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2254] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2257] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2260] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2263] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2266] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2269] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2272] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2275] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2278] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2281] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2284] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2287] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2290] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2293] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2296] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2299] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2302] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2305] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2308] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2311] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2314] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2317] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2320] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2323] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2326] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2329] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2332] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2335] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2338] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2341] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2344] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2347] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2350] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2353] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2356] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2359] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2362] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2365] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2368] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2371] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2374] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2377] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2380] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2383] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2386] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2389] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2392] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2395] MULTILINESTRING MULTILINESTRING MULTILINESTRING [2398] MULTILINESTRING MULTILINESTRING MULTILINESTRING [ reached getOption(&quot;max.print&quot;) -- omitted 3995 entries ] 18 Levels: GEOMETRY POINT LINESTRING ... TRIANGLE st_geometry_type(accidents_velo) [1] POINT POINT POINT POINT POINT POINT POINT POINT [9] POINT POINT POINT POINT POINT POINT POINT POINT [17] POINT POINT POINT POINT POINT POINT POINT POINT [25] POINT POINT POINT POINT POINT POINT POINT POINT [33] POINT POINT POINT POINT POINT POINT POINT POINT [41] POINT POINT POINT POINT POINT POINT POINT POINT [49] POINT POINT POINT POINT POINT POINT POINT POINT [57] POINT POINT POINT POINT POINT POINT POINT POINT [65] POINT POINT POINT POINT POINT POINT POINT POINT [73] POINT POINT POINT POINT POINT POINT POINT POINT [81] POINT POINT POINT POINT POINT POINT POINT POINT [89] POINT POINT POINT POINT POINT POINT POINT POINT [97] POINT POINT POINT POINT POINT POINT POINT POINT [105] POINT POINT POINT POINT POINT POINT POINT POINT [113] POINT POINT POINT POINT POINT POINT POINT POINT [121] POINT POINT POINT POINT POINT POINT POINT POINT [129] POINT POINT POINT POINT POINT POINT POINT POINT [137] POINT POINT POINT POINT POINT POINT POINT POINT [145] POINT POINT POINT POINT POINT POINT POINT POINT [153] POINT POINT POINT POINT POINT POINT POINT POINT [161] POINT POINT POINT POINT POINT POINT POINT POINT [169] POINT POINT POINT POINT POINT POINT POINT POINT [177] POINT POINT POINT POINT POINT POINT POINT POINT [185] POINT POINT POINT POINT POINT POINT POINT POINT [193] POINT POINT POINT POINT POINT POINT POINT POINT [201] POINT POINT POINT POINT POINT POINT POINT POINT [209] POINT POINT POINT POINT POINT POINT POINT POINT [217] POINT POINT POINT POINT POINT POINT POINT POINT [225] POINT POINT POINT POINT POINT POINT POINT POINT [233] POINT POINT POINT POINT POINT POINT POINT POINT [241] POINT POINT POINT POINT POINT POINT POINT POINT [249] POINT POINT POINT POINT POINT POINT POINT POINT [257] POINT POINT POINT POINT POINT POINT POINT POINT [265] POINT POINT POINT POINT POINT POINT POINT POINT [273] POINT POINT POINT POINT POINT POINT POINT POINT [281] POINT POINT POINT POINT POINT POINT POINT POINT [289] POINT POINT POINT POINT POINT POINT POINT POINT [297] POINT POINT POINT POINT POINT POINT POINT POINT [305] POINT POINT POINT POINT POINT POINT POINT POINT [313] POINT POINT POINT POINT POINT POINT POINT POINT [321] POINT POINT POINT POINT POINT POINT POINT POINT [329] POINT POINT POINT POINT POINT POINT POINT POINT [337] POINT POINT POINT POINT POINT POINT POINT POINT [345] POINT POINT POINT POINT POINT POINT POINT POINT [353] POINT POINT POINT POINT POINT POINT POINT POINT [361] POINT POINT POINT POINT POINT POINT POINT POINT [369] POINT POINT POINT POINT POINT POINT POINT POINT [377] POINT POINT POINT POINT POINT POINT POINT POINT [385] POINT POINT POINT POINT POINT POINT POINT POINT [393] POINT POINT POINT POINT POINT POINT POINT POINT [401] POINT POINT POINT POINT POINT POINT POINT POINT [409] POINT POINT POINT POINT POINT POINT POINT POINT [417] POINT POINT POINT POINT POINT POINT POINT POINT [425] POINT POINT POINT POINT POINT POINT POINT POINT [433] POINT POINT POINT POINT POINT POINT POINT POINT [441] POINT POINT POINT POINT POINT POINT POINT POINT [449] POINT POINT POINT POINT POINT POINT POINT POINT [457] POINT POINT POINT POINT POINT POINT POINT POINT [465] POINT POINT POINT POINT POINT POINT POINT POINT [473] POINT POINT POINT POINT POINT POINT POINT POINT [481] POINT POINT POINT POINT POINT POINT POINT POINT [489] POINT POINT POINT POINT POINT POINT POINT POINT [497] POINT POINT POINT POINT POINT POINT POINT POINT [505] POINT POINT POINT POINT POINT POINT POINT POINT [513] POINT POINT POINT POINT POINT POINT POINT POINT [521] POINT POINT POINT POINT POINT POINT POINT POINT [529] POINT POINT POINT POINT POINT POINT POINT POINT [537] POINT POINT POINT POINT POINT POINT POINT POINT [545] POINT POINT POINT POINT POINT POINT POINT POINT [553] POINT POINT POINT POINT POINT POINT POINT POINT [561] POINT POINT POINT POINT POINT POINT POINT POINT [569] POINT POINT POINT POINT POINT POINT POINT POINT [577] POINT POINT POINT POINT POINT POINT POINT POINT [585] POINT POINT POINT POINT POINT POINT POINT POINT [593] POINT POINT POINT POINT POINT POINT POINT POINT [601] POINT POINT POINT POINT POINT POINT POINT POINT [609] POINT POINT POINT POINT POINT POINT POINT POINT [617] POINT POINT POINT POINT POINT POINT POINT POINT [625] POINT POINT POINT POINT POINT POINT POINT POINT [633] POINT POINT POINT POINT POINT POINT POINT POINT [641] POINT POINT POINT POINT POINT POINT POINT POINT [649] POINT POINT POINT POINT POINT POINT POINT POINT [657] POINT POINT POINT POINT POINT POINT POINT POINT [665] POINT POINT POINT POINT POINT POINT POINT POINT [673] POINT POINT POINT POINT POINT POINT POINT POINT [681] POINT POINT POINT POINT POINT POINT POINT POINT [689] POINT POINT POINT POINT POINT POINT POINT POINT [697] POINT POINT POINT POINT POINT POINT POINT POINT [705] POINT POINT POINT POINT POINT POINT POINT POINT [713] POINT POINT POINT POINT POINT POINT POINT POINT [721] POINT POINT POINT POINT POINT POINT POINT POINT [729] POINT POINT POINT POINT POINT POINT POINT POINT [737] POINT POINT POINT POINT POINT POINT POINT POINT [745] POINT POINT POINT POINT POINT POINT POINT POINT [753] POINT POINT POINT POINT POINT POINT POINT POINT [761] POINT POINT POINT POINT POINT POINT POINT POINT [769] POINT POINT POINT POINT POINT POINT POINT POINT [777] POINT POINT POINT POINT POINT POINT POINT POINT [785] POINT POINT POINT POINT POINT POINT POINT POINT [793] POINT POINT POINT POINT 18 Levels: GEOMETRY POINT LINESTRING ... TRIANGLE Vous remarquez alors que les pistes cyclables sont composées de nombreuses multilignes. Une multiligne étant elle-même un ensemble de lignes. Quant aux accidents de vélo, ce sont des points qui désignent la position précise des accidents. On en compte 796 en 2018. La projection Vérifions maintenant la projection des shapefiles en utilisant la fonction st_crs() de la bibliothèque sf. Pour le shapefile limites_terrestres nous obtenons: st_crs(limites_terrestres) Coordinate Reference System: User input: NAD83 / MTM zone 8 wkt: PROJCRS[&quot;NAD83 / MTM zone 8&quot;, BASEGEOGCRS[&quot;NAD83&quot;, DATUM[&quot;North American Datum 1983&quot;, ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, LENGTHUNIT[&quot;metre&quot;,1]]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ID[&quot;EPSG&quot;,4269]], CONVERSION[&quot;MTM zone 8&quot;, METHOD[&quot;Transverse Mercator&quot;, ID[&quot;EPSG&quot;,9807]], PARAMETER[&quot;Latitude of natural origin&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8801]], PARAMETER[&quot;Longitude of natural origin&quot;,-73.5, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8802]], PARAMETER[&quot;Scale factor at natural origin&quot;,0.9999, SCALEUNIT[&quot;unity&quot;,1], ID[&quot;EPSG&quot;,8805]], PARAMETER[&quot;False easting&quot;,304800, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8806]], PARAMETER[&quot;False northing&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8807]]], CS[Cartesian,2], AXIS[&quot;easting (E(X))&quot;,east, ORDER[1], LENGTHUNIT[&quot;metre&quot;,1]], AXIS[&quot;northing (N(Y))&quot;,north, ORDER[2], LENGTHUNIT[&quot;metre&quot;,1]], USAGE[ SCOPE[&quot;Engineering survey, topographic mapping.&quot;], AREA[&quot;Canada - Quebec between 75°W and 72°W.; Canada - Ontario - east of 75°W.&quot;], BBOX[44.98,-75,62.53,-72]], ID[&quot;EPSG&quot;,32188]] La fonction st_crs() donne beaucoup d’informations. Pour connaitre la projection utilisée, le datum, le code ESPG, ou l’unité de mesure de la projection nous pouvons préciser la sortie désirée de la fonction, de la manière suivante: st_crs(limites_terrestres)$Name [1] &quot;NAD83 / MTM zone 8&quot; st_crs(limites_terrestres)$proj4string [1] &quot;+proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; st_crs(limites_terrestres)$epsg [1] 32188 st_crs(limites_terrestres)$units [1] &quot;m&quot; Ainsi, la projection du shapefile pistes_cyclables est: st_crs(pistes_cyclables)$proj4string [1] &quot;+proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Et la projection du shapefile accidents_velo est: st_crs(accidents_velo)$proj4string [1] &quot;+proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Les données de tous les shapefiles sont dans la projection de Mercator transverse (+proj=tmerc) et utilisent le Système de référence géodésique nord-américain de 1983 (+datum=NAD83). L’étendue spatiale L’étendue spatiale d’un objet spatial dans R, appelée le Bounding box, représente les limites géographiques des données, ou la localisation des données les plus au sud, nord, est et ouest. Pour connaître l’étendue spatiale des shapefiles nous utilisons la fonction st_bbox() de la librairie sf : st_bbox(limites_terrestres) xmin ymin xmax ymax 267517 5029232 306669 5062642 st_bbox(pistes_cyclables) xmin ymin xmax ymax 267984 5029291 306349 5062582 st_bbox(accidents_velo) xmin ymin xmax ymax 269489 5029752 305368 5059058 Les attributs Finalement, nous pouvons visualiser toutes les métadonnées et les attributs d’un shapefile simplement en écrivant son nom dans la console R: limites_terrestres Simple feature collection with 72 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: 267500 ymin: 5029000 xmax: 306700 ymax: 5063000 Projected CRS: NAD83 / MTM zone 8 First 10 features: DefaultAtt geometry 1 &lt;NA&gt; POLYGON ((299608 5038364, 2... 2 &lt;NA&gt; POLYGON ((301350 5036978, 3... 3 &lt;NA&gt; POLYGON ((300403 5038997, 3... 4 &lt;NA&gt; POLYGON ((300744 5039496, 3... 5 &lt;NA&gt; POLYGON ((302032 5043372, 3... 6 &lt;NA&gt; POLYGON ((302299 5043145, 3... 7 &lt;NA&gt; POLYGON ((302508 5040978, 3... 8 &lt;NA&gt; POLYGON ((304719 5062024, 3... 9 &lt;NA&gt; POLYGON ((304927 5062499, 3... 10 &lt;NA&gt; POLYGON ((305396 5062622, 3... pistes_cyclables Simple feature collection with 6395 features and 1 field Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: 268000 ymin: 5029000 xmax: 306300 ymax: 5063000 Projected CRS: Transverse_Mercator First 10 features: TYPE_VOIE 1 Piste cyclable sur rue 2 Piste cyclable en site propre 3 Chaussée désignée 4 Bande cyclable 5 Piste cyclable en site propre 6 Piste cyclable en site propre 7 Piste cyclable en site propre 8 Chaussée désignée 9 Piste cyclable en site propre 10 Piste cyclable en site propre geometry 1 MULTILINESTRING ((297752 50... 2 MULTILINESTRING ((305050 50... 3 MULTILINESTRING ((299076 50... 4 MULTILINESTRING ((287779 50... 5 MULTILINESTRING ((300752 50... 6 MULTILINESTRING ((300953 50... 7 MULTILINESTRING ((299010 50... 8 MULTILINESTRING ((276415 50... 9 MULTILINESTRING ((293077 50... 10 MULTILINESTRING ((304787 50... accidents_velo Simple feature collection with 796 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: 269500 ymin: 5030000 xmax: 305400 ymax: 5059000 Projected CRS: Transverse_Mercator First 10 features: FID geometry 1 0 POINT (279673 5041015) 2 1 POINT (277292 5039169) 3 2 POINT (275581 5036314) 4 3 POINT (274728 5035946) 5 4 POINT (283935 5040875) 6 5 POINT (280442 5039871) 7 6 POINT (279626 5040700) 8 7 POINT (277734 5038853) 9 8 POINT (276487 5038090) 10 9 POINT (278357 5040125) 4.1.4 Visualisation de shapefiles sous R Visualisation avec la librairie Mapview Vous allez maintenant apprendre à visualiser des données shapefile en utilisant la fonction mapview() de la librairie mapview. Cette bibliothèque est une des plus simples à utiliser pour visualiser rapidement des données spatiales. Commençons par charger cette bibliothèque dans la console R: library(mapview) Dans un premier temps, visualisons les limites terrestres de la ville de Montréal. mapview(limites_terrestres, col.regions = &quot;white&quot;) Remarquez que nous avons choisi la couleur blanche pour représenter l’intérieur des polygones délimitant la ville de Montréal. La couleur par défaut (c-à-d si on ne précise pas de couleur) est bleue. Passez votre curseur sur la carte ainsi créée et remarquez que vous pouvez cliquer sur chacun des polygones contenus dans cette couche de données. Remarquez aussi la légende dans le coin supérieur gauche de la carte créée et approchez-y votre curseur. Vous pouvez alors sélectionner une ou l’autre des arrières-plans disponibles. L’option “OpenStreetMap” affichera la carte produite par ce gratuitiel de cartographie pour la région entourant le polygone illustré. L’option “ESRI.WorldImagery”, quant à elle, affichera une image satellitaire de la région. Dans un deuxième temps, visualisons les pistes cyclables. Utilisons toujours la fonction mapview() et demandons que la couleur du trait des lignes soit verte foncée. Pour définir la couleur des lignes, nous utilisons l’argument color et non l’argument col.regions. mapview(pistes_cyclables, color = &quot;darkgreen&quot;) Il existe 657 couleurs prédéfinies dans R. Taper la commande colors() dans votre console R pour voir afficher le nom des couleurs. Celles-sont sont listées par ordre alphabétique sauf pour la première couleur, qui est le blanc (white). Ainsi, vous pouvez utiliser une couleur en assignant son nom ou son numéro. Pour produire la figure précédente, color = \"darkgreen\" aurait pu être remplacé par color = colors()[81]. Essayez pour voir. Pour en apprendre davantage sur les couleurs dans R, vous êtes invité à consulter le site Earl Glynn et à conserver dans vos notes son tableau synthèse des couleurs dans R. Nous discuterons plus en détails des couleurs dans le Module 6 portant sur la cartographie. Dans la carte des pistes cyclables, remarquez la légende apparue dans le coin supérieur droit. Celle-ci identifie les différentes catégories de pistes cyclables. Cette information correspond aux différentes valeurs que peut prendre l’attribut “TYPE_VOIE” du shapefile pistes_cyclables. Nous y reviendrons plus bas. Finalement, visualisons les accidents de la route impliquant des bicyclettes. mapview(accidents_velo, color = &quot;red&quot;, col.regions = &quot;red&quot;, cex = 1, legend = NULL) La position des accidents est représentée par des points dont le contour et l’intérieur, dénotés par les arguments color et col.regions respectivement, sont de couleur rouge. L’argument cex, quant à lui, indique la taille des cercles, la taille par défaut utilisée dans mapview est 2. Ici, nous avons demandé une taille plus petite afin de mieux différencier chacun des points. Visualiser des données vectorielles par attribut Lorsque nous avons affiché les métadonnées du shapefile pistes_cyclables, vous avez peut-être observé que ce dernier comprenait l’attribut TYPE_VOIE qui caractérise le type de pistes cyclables de chaque multiligne. Affichons les métadonnées à nouveau: pistes_cyclables Simple feature collection with 6395 features and 1 field Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: 268000 ymin: 5029000 xmax: 306300 ymax: 5063000 Projected CRS: Transverse_Mercator First 10 features: TYPE_VOIE 1 Piste cyclable sur rue 2 Piste cyclable en site propre 3 Chaussée désignée 4 Bande cyclable 5 Piste cyclable en site propre 6 Piste cyclable en site propre 7 Piste cyclable en site propre 8 Chaussée désignée 9 Piste cyclable en site propre 10 Piste cyclable en site propre geometry 1 MULTILINESTRING ((297752 50... 2 MULTILINESTRING ((305050 50... 3 MULTILINESTRING ((299076 50... 4 MULTILINESTRING ((287779 50... 5 MULTILINESTRING ((300752 50... 6 MULTILINESTRING ((300953 50... 7 MULTILINESTRING ((299010 50... 8 MULTILINESTRING ((276415 50... 9 MULTILINESTRING ((293077 50... 10 MULTILINESTRING ((304787 50... Utilisons la fonction factor() pour convertir la classe de l’attribut TYPE_VOIE de charactère (chr) à facteur (Factor). Puis, utilisons la fonction levels() pour connaître ces types de voie cyclables. La fonction levels donne les différentes valeurs que peuvent prendre un attribut. pistes_cyclables$TYPE_VOIE &lt;- factor(pistes_cyclables$TYPE_VOIE) levels(pistes_cyclables$TYPE_VOIE) [1] &quot;Bande cyclable&quot; [2] &quot;Chaussée désignée&quot; [3] &quot;Piste cyclable au niveau du trottoir&quot; [4] &quot;Piste cyclable en site propre&quot; [5] &quot;Piste cyclable sur rue&quot; [6] &quot;Sentier polyvalent&quot; Si vous ne connaissez pas la distinction entre ces types d’aménagement cyclable, consulter ce document sommaire de la Ville de Montréal28 Dans la figure précédente illustrant les pistes cyclables, celles-ci étaient illustrées en vert peu importe leur type. Nous voulons maintenant représenter les six types de voie cyclable par six couleurs différentes. Un des avantages de la fonction mapview() est qu’elle est capable d’emblée de distinguer les différentes valeurs que peuvent prendre un attribut. Ainsi, nous pouvons simplement demander: mapview(pistes_cyclables) Le shapefile pistes_cyclables contient un seul attribut, “TYPE_VOIE”. Si un shapefile contient plus d’un attribut, il faut spécifier celui qu’on veut représenter en argument à la fonction mapview(). Dans le cas présent, nous aurions plutôt demandé: `mapview(pistes_cyclables, z = “TYPE_VOIE”). Par défaut, la fonction mapview() pour les données vectorielles utilise la palette de couleur viridis. Une palette de couleur est un ensemble de plusieurs couleurs prédéfinies et stocké dans un vecteur. Il existe plusieurs palettes de couleur prédéfinies et nous y reviendrons également au Module 6 portant sur la cartographie. La palette viridis forme un gradient allant du mauve au jaune en passant pas le bleu et le vert (Fig 4.1): Figure 4.1: Palette viridis contenant 20 couleurs différentes Un utilisateur de R peut utiliser des palettes prédéfinies, ou encore définir les siennes. Par exemple, si nous trouvons que les couleurs de la palette viridis ne permettent pas de bien différencier les différents types de piste cyclable, nous pouvons nous-même créer une palette contenant six couleurs (car il y a six valeurs possibles pour cet attribut). couleurs_voie &lt;- c(&quot;black&quot;,&quot;goldenrod&quot;, &quot;cornflowerblue&quot;, &quot;darkcyan&quot;, &quot;hotpink&quot;, &quot;mediumpurple&quot;) Nous pouvons ajouter cet argument à la fonction mapview(): mapview(pistes_cyclables, color=couleurs_voie, layer.name = &quot;Types de pistes cyclables&quot;, lwd = 1 ) Remarquez que nous avons changé le titre de la légende en utilisant l’argument layer.name, et que nous avons réduit l’épaisseur des lignes en utilisant l’argument lwd. Visualiser plusieurs shapefiles Nous allons maintenant représenter les données vectorielles limites terrestres, pistes_cyclables et accidents_velo au sein d’une même figure. Il s’agit de définir individuellement chacune des cartes comme un objet mapview et de les additionner en utilisant l’opérateur +. map_limites_terrestres &lt;- mapview(limites_terrestres, col.regions = &quot;darkgray&quot;, legend = NULL) map_pistes_cyclables &lt;- mapview(pistes_cyclables, color=couleurs_voie, layer.name = &quot;Types de pistes cyclables&quot;, lwd = 1) map_accidents &lt;- mapview(accidents_velo, color = &quot;red&quot;, col.regions = &quot;red&quot;, cex = 1, legend = NULL) map_limites_terrestres + map_pistes_cyclables + map_accidents 4.1.5 Reprojection de données vectorielles sous R Dans cette section vous apprendrez à manipuler le système de coordonnées de référence de données vectorielles. Nous avons vu en début de leçon que les données utilisées sont dans la projection de Mercator transverse (tmerc) et utilisent le Système de référence géodésique nord-américan de 1983 (NAD83). Par exemple, pour connaître la projection des données limites_terrestres, nous avions fait: st_crs(limites_terrestres)$proj4string [1] &quot;+proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Nous allons maintenant transformer le SCR vers la projection de Robinson (robin) et le Système géodésique mondial de 1984 (WGS84). Pour se faire nous utilisons la fonction st_transform() de la bibliothèque st. ##limites_terrestres_rob &lt;- st_transform(limites_terrestres, ## CRS(&quot;+proj=robin +datum=WGS84&quot;)) limites_terrestres_rob &lt;- st_transform(limites_terrestres, CRS(&quot;+proj=robin +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs&quot; )) Comparons les données transformées avec les données initiales. Pour se faire, nous voulons représenter les deux cartes une à côté de l’autre. La bibliothèque leafsync associée à la bibliothèque leaflet permet de créer facilement des figures avec des panneaux multiples. Nous discuterons plus en détails de ces bibliothèques dans le Module 6 portant sur la cartographie. Installez la bibliothèque leafsync si ce n’est pas déjà fait, et chargez-là dans votre session de travail. library(leafsync) Représentons mainteant les deux projections différentes en utilisant la fonction latticeView() de la bibliothèque leafsync. Puisque cette fonction existe à la fois dans la bibliothèque leafsync et dans la bibliothèque mapview mais qu’elle est obsolète dans cette dernière, nous devons préciser que nous voulons la fonction latticeView()de la bibliothèqueleafsyncen utilisant la notation suivante:leafsync::latticeView` map_mercator &lt;- mapview(limites_terrestres, legend = FALSE, col.regions = &quot;red&quot;) map_robinson &lt;- mapview(limites_terrestres_rob, legend = FALSE) Map &lt;- leafsync::latticeView(map_mercator,map_robinson, ncol = 2) Map Nous remarquons que les deux cartes sont identiques (outre la couleur)! Comment cela est-ce possible sachant que nous venons de transformer la projection ? Ceci s’explique par le fait que la fonction mapview() représente par défaut toutes données spatiales dans la projection Pseudo-Mercator (ou Mercator Web), qui est la projection utilisée par l’application OpenStreetMap. Ainsi, la fonction mapview calcule elle-même le changement de projection avant de représenter des données spatiales. Pour conserver la projection originale il faut utiliser l’argument native.crs=TRUE. Représentons à nouveau les cartes des limites terrestres de la région de Montréal, cette fois en précisant que nous voulons conserver le CRS d’orgine. map_web &lt;- mapview(limites_terrestres, col.regions = &quot;red&quot;, legend = NULL, layer.name = &quot;Mercator Web&quot;) map_mercator &lt;- mapview(limites_terrestres, col.regions = &quot;yellow&quot;, legend = NULL, layer.name = &quot;Mercator&quot;, native.crs=TRUE) map_robinson &lt;- mapview(limites_terrestres_rob, legend = NULL, layer.name = &quot;Robinson&quot;, native.crs=TRUE) Map &lt;- leafsync::latticeView(map_web,map_mercator,map_robinson, ncol = 3) Map Remarquez que nous avons utilisé l’argument ncol dans la fonction latticeview pour spécifier le nombre de colonnes - c-à-d le nombre de panneaux verticaux qu’aura cette image. Finalement, pour sauvegarder des données vectorielles, nous utilisons la fonction st_write() de la bibliothèque st, de la même façon que nous avons utilisé la fonction st_read() en début de leçon. Par exemple, sauvons les données limites_terrestres_rob que nous venons de créer. 4.1.6 Lire une géodatabase et explorer ses couches Dans cette section, nous allons explorer les données vectorielles d’une géodatabase du Ministère de l’Éducation et de l’Enseignement supérieur du Québec (MEES). Ces données se trouvent dans le dossier Donnees_Ouvertes_MEES.gbd que vous avez normalement téléchargé au début de la leçon. Lire les données Dans la section portant sur le format des données vectorielles du Module 2, nous avons expliqué qu’une géodatabase est une façon de rassembler et d’organiser des données propres à un sujet dans une unique base de données. La géodatabase Donnees_Ouvertes_MEES.gdb contient plusieurs couches de données vectorielles (layers) sur les établissements d’enseignement au Québec. Pour lire et explorer une géodatabase, on continue à utiliser la bibliothèques sf. Chaque couche peut être lue individuellement en utilisant la fonction st_read(): st_read(\"nom_de_la_geodatabase.gdb\", layer = \"nom_de_la_couche\"). Il est donc nécessaire de connaître d’abord les noms donnés aux couches composants la géodatabase - information qui nous est, pour l’instant, inconnue. Pour connaître les couches d’une géodatabase, nous utilisons la fonction st_layers() couches_mees &lt;- st_layers(&quot;Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&quot;) couches_mees Driver: OpenFileGDB Available layers: layer_name geometry_type features 1 CS_STA Multi Polygon 3 2 CS_FRA Multi Polygon 60 3 CS_ANG Multi Polygon 9 4 CS_STA_GEN Multi Polygon 3 5 CS_ANG_GEN Multi Polygon 9 6 CS_FRA_GEN Multi Polygon 60 7 CS_FRA_SDA Multi Polygon 60 8 CS_ANG_SDA Multi Polygon 9 9 CS_STA_SDA Multi Polygon 3 10 PPS_Public_SSocial_Org Point 2748 11 PPS_Prive_Installation Point 350 12 PPS_Prive_Etablissement Point 261 13 PPS_Gouvernemental Point 37 14 PPS_Public_SSocial_CS Point 72 15 ES_Universitaire Point 22 16 PPS_Public_Ecole Point 5202 17 PPS_Public_Immeuble Point 4641 18 ES_Collegial Point 311 fields 1 9 2 9 3 9 4 9 5 9 6 9 7 9 8 9 9 9 10 24 11 24 12 15 13 22 14 16 15 17 16 29 17 22 18 17 Nous observons que la géodatabase contient 18 couches différentes. Nous pouvons connaître le nom donné à chaque couche (layer_name), leur géométrie (geometry_type), le nombre d’objets vectoriels qu’elles contiennent (features), et le nombre d’attributs qu’elles décrivent (fields). Les couches dont le nom commence par CS_ contiennent des données vectorielles relatives aux centres de services scolaires29. Puisque chacun de ces centres couvre un territoire qui leur est propre, ces données sont des multi-polygones. Les couches dont le nom commence par PPS_ et ES_ contiennent des données vectorielles relatives aux établissements d’enseignement primaire, secondaire et supérieure. Puisque chacun de ces établissements est identifié par une paire de coordonnées, ces données sont des points. Lisons les données vectorielles de la couche PPS_Public_Ecole en utilisant la fonction st_read(). ecoles_pub &lt;- st_read(&quot;Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&quot;, layer = &quot;PPS_Public_Ecole&quot;) Reading layer `PPS_Public_Ecole&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&#39; using driver `OpenFileGDB&#39; Simple feature collection with 5202 features and 29 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -8849000 ymin: 5623000 xmax: -6360000 ymax: 8958000 Projected CRS: WGS 84 / Pseudo-Mercator Cette couche donne la localisation des 5202 écoles primaires et secondaires publiques de la province ainsi que 28 autres attributs associés à ces établissements. Notez le système de coordonnées de référence: le datum WGS84 et la projection Pseudo-Mercator (ou Mercator Web) sont utilisés. Notez aussi que cette couche de la géodatabase possède la même structure que celle d’un shapefile. Nous pouvons visualiser la position des écoles publiques du Québec en utilisant la fonction mapview() de la bibliothèque mapview. mapview(ecoles_pub) Nous remarquons qu’il est difficile de visualiser la position des écoles dans la région Sud du Québec car il y a énormément de points. Explorer les attributs d’une couche Pour explorer les attributs associés à la couche ecoles_pub, commençons d’abord par utiliser la fonction names() qui retourne le nom associé à chaque attribut de la couche. names(ecoles_pub) [1] &quot;DT_MAJ_GDUNO&quot; [2] &quot;COMBINE_NUO_NUI&quot; [3] &quot;CD_ORGNS&quot; [4] &quot;NOM_COURT_ORGNS&quot; [5] &quot;NOM_OFFCL_ORGNS&quot; [6] &quot;ADRS_GEO_L1_GDUNO_ORGNS&quot; [7] &quot;ADRS_GEO_L2_GDUNO_ORGNS&quot; [8] &quot;CD_POSTL_GDUNO_ORGNS&quot; [9] &quot;CD_MUNCP_GDUNO_ORGNS&quot; [10] &quot;NOM_MUNCP_GDUNO_ORGNS&quot; [11] &quot;CD_IMM&quot; [12] &quot;NOM_IMM&quot; [13] &quot;ADRS_GEO_L1_GDUNO_IMM&quot; [14] &quot;ADRS_GEO_L2_GDUNO_IMM&quot; [15] &quot;CD_MUNCP_GDUNO_IMM&quot; [16] &quot;NOM_MUNCP_GDUNO_IMM&quot; [17] &quot;CD_POSTL_GDUNO_IMM&quot; [18] &quot;PRESC&quot; [19] &quot;PRIM&quot; [20] &quot;SEC&quot; [21] &quot;FORM_PRO&quot; [22] &quot;ADULTE&quot; [23] &quot;SITE_WEB_ORGNS&quot; [24] &quot;COORD_X_LL84_IMM&quot; [25] &quot;COORD_Y_LL84_IMM&quot; [26] &quot;ORDRE_ENS&quot; [27] &quot;CD_CS&quot; [28] &quot;TYPE_CS&quot; [29] &quot;STYLE_CART&quot; [30] &quot;SHAPE&quot; Notre première réaction à la lecture de ces noms est qu’ils ne sont pas tous intuitifs! Examinons les quatre attributs suivants: “NOM_OFFCL_ORGNS”, “NOM_MUNCP_GDUNO_IMM”, “TYPE_CS”, et “SHAPE”. L’attribut “NOM_OFFCL_ORGNS” correspond au nom de chaque école publique. On peut lire les premières entrées de cette liste de noms en utilisant la fonction head(): head(ecoles_pub$NOM_OFFCL_ORGNS) [1] &quot;Centre de formation professionnelle de Mont-Joli-Mitis&quot; [2] &quot;Centre de formation des adultes de Mont-Joli-Mitis&quot; [3] &quot;École des Alizés&quot; [4] &quot;École de l&#39;Écho-des-Montagnes-Lavoie&quot; [5] &quot;École de Mont-Saint-Louis-Saint-Rosaire&quot; [6] &quot;École des Sources&quot; L’attribut “NOM_MUNCP_GDUNO_IMM” correspond au nom de la municipalité dans laquelle se trouve une école publique. Pour avoir un aperçu des valeurs données, on utilise encore la fonction head: head(ecoles_pub$NOM_MUNCP_GDUNO_IMM) [1] &quot;Mont-Joli&quot; [2] &quot;Mont-Joli&quot; [3] &quot;Mont-Joli&quot; [4] &quot;Saint-Fabien&quot; [5] &quot;Rimouski&quot; [6] &quot;Saint-Anaclet-de-Lessard&quot; L’attribut “TYPE_CS” identifie les écoles selon leur appartenance à une commision scolaire francophone, anglophone ou à statut linguistique particulier. head(ecoles_pub$TYPE_CS) [1] &quot;Franco&quot; &quot;Franco&quot; &quot;Franco&quot; &quot;Franco&quot; &quot;Franco&quot; [6] &quot;Franco&quot; Il y a trois types de commissions scolaires possibles: Anglo, Franco, et Statut. Il est possible d’obtenir cette information en utilisant la fonction levels() précédée de la fonction as.factor(): levels(as.factor(ecoles_pub$TYPE_CS)) [1] &quot;Anglo&quot; &quot;Franco&quot; &quot;Statut&quot; Finalement, l’attribut “SHAPE” donne la position géographique de chaque école publique et les métadonnées spatiales associées à cette couche: head(ecoles_pub$SHAPE) Geometry set for 6 features Geometry type: POINT Dimension: XY Bounding box: xmin: -7666000 ymin: 6156000 xmax: -7590000 ymax: 6205000 Projected CRS: WGS 84 / Pseudo-Mercator First 5 geometries: POINT (-7590676 6204635) POINT (-7590676 6204635) POINT (-7590441 6205128) POINT (-7665998 6156083) POINT (-7648497 6168694) Sélection d’un sous-ensemble de données Pour simplifier la visualisation de cette couche, nous allons nous concentrer sur les écoles de la municipalité de Montréal. Pour ce faire, nous créons un nouveau shapefile en sélectionnant les données propres à la municipalité de Montréal: ecoles_pub_Mtl&lt;- ecoles_pub[ecoles_pub$NOM_MUNCP_GDUNO_IMM == &quot;Montréal&quot;,] Interprétons cette ligne de commande: elle utilise l’opérateur logique == pour sélectionner les écoles publiques de la municipalité de Montréal, ainsi que tous les autres attributs au sein de la couche ecoles_pub. Visualisons maintenant ce nouveau shapefile en utilisant la fonction mapview(). map_pub_mtl&lt;-mapview(ecoles_pub_Mtl, cex = 2) map_pub_mtl Ici, nous avons utilisé l’argument cex pour diminuer la taille des points sur la carte (la taille par défaut est 6). En cliquant sur l’un ou l’autre des points vous obtiendrez l’ensemble des attributs propres à l’école sélectionnée. Nous pouvons également assigner des couleurs aux données vectorielles en fonction des valeurs d’un de ses attributs. Ceci est possible en utilisant l’argument zcol de la fonction mapview() et en lui assignant de nom de l’attribut que nous désirons illustrer. Utilisons, par exemple, l’attribut “TYPE_CS” qui indique la langue de la commission scolaire. mapview(ecoles_pub_Mtl, zcol = &quot;TYPE_CS&quot;, cex = 2, layer.name = &#39;Commissions scolaires&#39;) De façon similaire, nous aurions pu représenter les écoles de l’île de Montréal selon le niveau d’enseignement qu’on y dispense. Cette information est donnée par l’attribut “ORDRE_ENS”. mapview(ecoles_pub_Mtl, zcol = &quot;ORDRE_ENS&quot;, cex = 2, layer.name = &#39;Enseignement&#39;) Visualisation de plusieurs couches d’une géodatabse Nous voulons visualiser d’autres types d’établissement d’enseignement donnés dans la géodatabase du Ministère de l’Éducation et de l’Enseignement supérieur du Québec. Choisissons les écoles privées, les établissements de niveau collégial (e.g. CÉGEP) et les universités. Pour se faire nous utilisons encore la fonction st_read en spécifiant le nom de la couche (layer) désirée. ecoles_priv &lt;- st_read(&quot;Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&quot;, layer = &quot;PPS_Prive_Etablissement&quot;) Reading layer `PPS_Prive_Etablissement&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&#39; using driver `OpenFileGDB&#39; Simple feature collection with 261 features and 15 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -8442000 ymin: 5623000 xmax: -7391000 ymax: 6484000 Projected CRS: WGS 84 / Pseudo-Mercator college&lt;- st_read(&quot;Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&quot;, layer = &quot;ES_Collegial&quot;) Reading layer `ES_Collegial&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&#39; using driver `OpenFileGDB&#39; Simple feature collection with 311 features and 17 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -8795000 ymin: 5661000 xmax: -6892000 ymax: 6486000 Projected CRS: WGS 84 / Pseudo-Mercator univ &lt;- st_read(&quot;Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&quot;, layer = &quot;ES_Universitaire&quot;) Reading layer `ES_Universitaire&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&#39; using driver `OpenFileGDB&#39; Simple feature collection with 22 features and 17 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -8795000 ymin: 5679000 xmax: -7627000 ymax: 6182000 Projected CRS: WGS 84 / Pseudo-Mercator Toujours dans le but de simplifier la visualisation, sélectionnons au sein des couches ecoles_priv, college et univ les établissements situés à Montréal. Attention, pour ces couches le nom de l’attribut associé à la municipalié où se situe les établissements listés est “NOM_MUNCP” et non “NOM_MUNCP_GDUNO_IMM”. ecoles_priv_Mtl &lt;- ecoles_priv[ecoles_priv$NOM_MUNCP == &quot;Montréal&quot;,] college_Mtl &lt;- college[college$NOM_MUNCP == &quot;Montréal&quot;,] univ_Mtl &lt;- univ[univ$NOM_MUNCP == &quot;Montréal&quot;,] Nous pouvons visualiser chacun de ces nouveaux shapefile individuellement en utilisant la fonction mapview(), mais plus intéressant encore est de les visualiser ensemble au sein d’une même carte. Pour se faire nous créons d’abord des cartes individuelles. map_priv_mtl &lt;- mapview(ecoles_priv_Mtl, color = &quot;red&quot;, col.regions = &quot;red&quot;, cex = 2) map_college_mtl &lt;- mapview(college_Mtl, color = &quot;green&quot;, col.regions = &quot;green&quot;, cex = 4) map_univ_mtl &lt;- mapview(univ_Mtl, color = &quot;orange&quot;, col.regions = &quot;orange&quot;, cex = 6) Remarquez que nous utilisons différentes tailles de points et différentes couleurs pour bien différencier le type d’institution dans la carte qui les combinera. La couleur du contour du point est donnée par l’argument color et celle de l’intérieur du point par l’argument col.regions. Nous combinons toutes les couches par une simple addition des cartes individuelles map_pub_mtl + map_priv_mtl + map_college_mtl + map_univ_mtl Dans le menu du coin supérieur gauche de la carte, remarquez que vous pouvez sélectionner/désélectionner chaque couche selon l’information que vous désirez explorer. Il serait intéressant de créer une nouvelle géodatabase pour sauvegarder les quatre nouveaux shapefiles des institutions d’enseignement à Montréal au sein d’une même structure. Malheureusement R peut seulement lire des géodatabases mais ne peut pas sauvegarder ce format qui est propriétaire de ESRI. Ainsi, il faudrait utiliser la fonction st_write() pour sauvegarder chacun des shapefiles individuellement. Ville de Montréal. Aménagements cyclables. Repéré le 19 mars 2020↩︎ Les centres de services scolaires (qui remplacent les commissions scolaires depuis 2020) ont pour rôle d’épauler les établissements d’enseignement situés sur leur territoire. Pour plus d’informations, consultez le site web du MEES, https://www.quebec.ca/education/prescolaire-primaire-et-secondaire/gouvernance-scolaire/#c42437↩︎ "],["ex_vec.html", "4.2 Exercices", " 4.2 Exercices Dans cette section, vous mettrez en pratique certains concepts vus dans la section leçon de ce module. Bien que la réponse à chaque question soit disponible, il est très important de tenter d’y répondre par vous même! Question 1 Créer une géométrie simple de type polygone qui a la forme d’un carré de 10 unités de long avec un trou en son centre qui a la forme d’un carré de 4 unités de long. Réponse Définir deux matrices de coordonnées, une pour le grand et l’autre pour le petit carré. Les coordonnées exactes peuvent prendre n’importe quelles valeurs du moment que la taille de chaque carré respecte les dimensions demandées. matrice_carre_grand &lt;- rbind(c(1,1), c(1,11), c(11,11), c(11,1), c(1,1)) matrice_carre_petit &lt;- rbind(c(4,4),c(4,8),c(8,8),c(8,4),c(4,4)) Créer une liste avec ces deux matrices et créer le polygone en utilisant la fonction st_polygon() polygone &lt;- st_polygon(list(matrice_carre_grand, matrice_carre_petit)) polygone POLYGON ((1 1, 1 11, 11 11, 11 1, 1 1), (4 4, 4 8, 8 8, 8 4, 4 4)) Visualiser le polygone pour confirmer votre réponse: mapview(polygone) Question 2 a) Créer 3 géométries simples de type ligne en utilisant les matrices de coordonnées suivantes: matrice_ligne1 &lt;- rbind(c(1,1), c(2,2), c(3,1), c(4,2), c(5,1), c(6,2), c(7,1)) matrice_ligne2 &lt;- rbind(c(1,5), c(3,3), c(7,5), c(3,5), c(4,4)) matrice_ligne3 &lt;- rbind(c(1,3), c(3,7), c(7,8), c(10,10)) Réponse Utiliser la fonction st_lignestring() pour créer les 3 géométries simples de type ligne. ligne1 &lt;- st_linestring(matrice_ligne1) ligne2 &lt;- st_linestring(matrice_ligne2) ligne3 &lt;- st_linestring(matrice_ligne3) b) Définir une couche de données vectorielles comprenant ces 3 lignes, et lui attribuer la projection Web de Mercator. Réponse Créer d’abord un objet sfc, c’est-à-dire une simple feature column, en utilisant la fonction st_sfc(): lignes &lt;- st_sfc(ligne1, ligne2, ligne3) Ajouter maintenant le SCR demandé. La projection Web de Mercator possède le code EPSG 3857 (revoir le Module 3 pour trouver cette information). lignes &lt;- st_sfc(ligne1, ligne2, ligne3, crs = 3857) lignes Geometry set for 3 features Geometry type: LINESTRING Dimension: XY Bounding box: xmin: 1 ymin: 1 xmax: 10 ymax: 10 Projected CRS: WGS 84 / Pseudo-Mercator LINESTRING (1 1, 2 2, 3 1, 4 2, 5 1, 6 2, 7 1) LINESTRING (1 5, 3 3, 7 5, 3 5, 4 4) LINESTRING (1 3, 3 7, 7 8, 10 10) c) Ajouter deux attributs à cette couche de données. Le premier attribut correspond à un nom de votre choix pour désigner chaque ligne, et le deuxième attribut correspond au nombre d’extrémités dans chaque ligne. Réponse Créer une table d’attribut en utilisant la fonction data.frame(). lignes_att &lt;- data.frame( nom = c(&quot;Zigzag&quot;, &quot;Tourbillon&quot;, &quot;Tordu&quot;), nombre = c(nrow(matrice_ligne1), nrow(matrice_ligne2), nrow(matrice_ligne3)) ) lignes_att nom nombre 1 Zigzag 7 2 Tourbillon 5 3 Tordu 4 Créer un objet sf, c’est-à-dire un simple feature, en utilisant la fonction st_sf() pour unir la table d’attributs des lignes à leur composante spatiale. lignes_sf &lt;- st_sf(lignes, lignes_att) lignes_sf Simple feature collection with 3 features and 2 fields Geometry type: LINESTRING Dimension: XY Bounding box: xmin: 1 ymin: 1 xmax: 10 ymax: 10 Projected CRS: WGS 84 / Pseudo-Mercator nom nombre lignes 1 Zigzag 7 LINESTRING (1 1, 2 2, 3 1, ... 2 Tourbillon 5 LINESTRING (1 5, 3 3, 7 5, ... 3 Tordu 4 LINESTRING (1 3, 3 7, 7 8, ... d) Visualiser cette couche de données vectorielles. Assurez-vous d’avoir une légende identifiant chaque ligne par son nom. Réponse Utiliser la fonction mapview() et spécifier que l’argument z correspond à l’attribut “nom” de l’objet lignes_sf. mapview(lignes_sf, z=&quot;nom&quot;, layer.name = &quot;Nom des lignes&quot;) Question 3 Pour cette question, vous utiliserez les données vectorielles décrivant les régions administratives de la Nouvelle-Zélande. Ces données se nomment nz et sont disponibles dans la bibliothèque spData. library(spData) To access larger datasets in this package, install the spDataLarge package with: `install.packages(&#39;spDataLarge&#39;, repos=&#39;https://nowosad.github.io/drat/&#39;, type=&#39;source&#39;)` data(nz) a) Combien d’éléments spatiaux contient la couche nz et de quel type de géométrie sont ces éléments ? Réponse Pour répondre à cette question, nous pouvons simplement repérer l’information demandée dans l’affichage général de l’objet nz nz Simple feature collection with 16 features and 6 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: 1090000 ymin: 4749000 xmax: 2090000 ymax: 6192000 Projected CRS: NZGD2000 / New Zealand Transverse Mercator 2000 First 10 features: Name Island Land_area Population 1 Northland North 12501 175500 2 Auckland North 4942 1657200 3 Waikato North 23900 460100 4 Bay of Plenty North 12071 299900 5 Gisborne North 8386 48500 6 Hawke&#39;s Bay North 14138 164000 7 Taranaki North 7254 118000 8 Manawatu-Wanganui North 22221 234500 9 Wellington North 8049 513900 10 West Coast South 23245 32400 Median_income Sex_ratio 1 23400 0.9425 2 29600 0.9443 3 27900 0.9521 4 26200 0.9280 5 24400 0.9350 6 26100 0.9238 7 29100 0.9569 8 25000 0.9388 9 32700 0.9336 10 26900 1.0139 geom 1 MULTIPOLYGON (((1745493 600... 2 MULTIPOLYGON (((1803822 590... 3 MULTIPOLYGON (((1860345 585... 4 MULTIPOLYGON (((2049387 583... 5 MULTIPOLYGON (((2024489 567... 6 MULTIPOLYGON (((2024489 567... 7 MULTIPOLYGON (((1740438 571... 8 MULTIPOLYGON (((1866732 566... 9 MULTIPOLYGON (((1881590 548... 10 MULTIPOLYGON (((1557042 531... Nous pouvons y lire qu’il y a 16 éléments (features) et que la géométrie est de type multipolygone. Nous pouvons également trouver les réponses en utilisant les deux fonctions spécifiques suivantes: nrow(nz) [1] 16 Effectivement, nz étant un data.frame, nous pouvons utilisé les manipulations usuelles pour cette classe d’objet. Chaque élément dans un data.frame occupe une rangée. st_geometry_type(nz) [1] MULTIPOLYGON MULTIPOLYGON MULTIPOLYGON [4] MULTIPOLYGON MULTIPOLYGON MULTIPOLYGON [7] MULTIPOLYGON MULTIPOLYGON MULTIPOLYGON [10] MULTIPOLYGON MULTIPOLYGON MULTIPOLYGON [13] MULTIPOLYGON MULTIPOLYGON MULTIPOLYGON [16] MULTIPOLYGON 18 Levels: GEOMETRY POINT LINESTRING ... TRIANGLE Cette commande nous confirme que la couche nz contient bien des multipolygones. b) Trouver le nombre d’attributs de nz et leur nom. Réponse Pour trouver le nombre d’attributs, nous pouvons nous référer à l’affichage général de nz (voir plus haut) qui nous informe que l’objet contient 6 attributs (ou champs, fields en anglais). Nous pouvons également utiliser la fonction ncol() qui donne le nombre de colonnes dans le data.frame. ncol(nz) [1] 7 L’objet nz contient bel et bien 7 colonnes. Cependant, la dernière colonne correspond à la géométrie de chaque élément de nz (qui est en fait, un attribut spatial). Ainsi, le nombre d’attribut est 6. Pour trouver le nom des attributs, nous pouvons encore s’appuyer sur le fait que nz est un data.frame et utiliser la fonction names(): names(nz) [1] &quot;Name&quot; &quot;Island&quot; &quot;Land_area&quot; [4] &quot;Population&quot; &quot;Median_income&quot; &quot;Sex_ratio&quot; [7] &quot;geom&quot; c) Trouver le code EPSG, le nom et l’unité de mesure de la projection utilisée. Réponse Ces trois informations se trouvent en utilisant les fonctions suivantes: st_crs(nz)$epsg [1] 2193 st_crs(nz)$Name [1] &quot;NZGD2000 / New Zealand Transverse Mercator 2000&quot; st_crs(nz)$units [1] &quot;m&quot; La projection utilisée est le New Zealand Transverse Mercator 2000. NZGD 2000 réfère au datum utilisé, appelé le New Zealand Geodetic Datum. d) Transformer la projection de nz pour la projection conique conforme de Lambert (LCC). Réponse La projection conique conforme de Lambert est donnée par le code EPSG 32198. nz_lcc &lt;- st_transform(nz, crs = 32198) Vérifions que notre transformation est correcte. st_crs(nz_lcc)$proj4string [1] &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; e) Chaque polygone de la couche nz correspond à une région. Visualiser la couche nz en illustrant chaque région avec une couleur différente. Réponse mapview(nz, zcol = &quot;Name&quot;, layer.name = &quot;Régions&quot;) f) Importer le fichier nz_capitales.cvs contenu dans le dossier Module4_donnees. Ce fichier donne le nom et la localisation des capitales de chaque région de la Nouvelle-Zélande. Créer une carte illustrant les frontières des régions ainsi que la position de leur capitale respective. Réponse Tout d’abord, vous devez importer le fichier nz_capitales.cvs dans votre session de travail R. Utiliser la fonction de base read.table() afin de stocker les coordonnées des capitales dans un object de classe data.frame. nz_capitales &lt;- read.table(&quot;Module4/Module4_donnees/nz_capitales.csv&quot;, header = TRUE, sep = &quot;,&quot;) nz_capitales Capitales Longitude Latitude 1 Auckland 174.8 -36.85 2 Wellington 174.8 -41.29 3 Christchurch 172.6 -43.53 4 Hamilton 175.3 -37.78 5 Dunedin 170.5 -45.87 6 Palmerston North 175.6 -40.35 7 Napier 176.9 -39.48 8 Whangarei 174.3 -35.73 9 Invercargill 168.4 -46.43 10 Nelson 173.2 -41.29 11 Gisborne 178.0 -38.66 12 Blenheim 173.9 -41.52 13 Richmond 173.2 -41.33 14 Whakatane 177.0 -37.96 15 Greymouth 171.2 -42.47 16 Stratford 174.3 -39.34 Nous observons que les coordonnées sont en format longitude/latitude. Utiliser la fonction st_as_sf() pour transformer cette table de coordonnées en données vectorielles de type points. Puisque les coordonnées sont en format longitude/latitude, nous ne pouvons pas assigner un système de coordonnées projecté cartésien. Utilisons simplement le datum WGS 84 pour définir le SCR. Ce dernier est associé au code EPSG 4326. nz_capitales_points &lt;- st_as_sf(x = nz_capitales, coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = 4126) Utiliser la fonction mapview() pour visualiser les polygones des régions et les points correspondants aux capitales de ces régions. mapview(nz, col.regions = &quot;blue&quot;, legend = FALSE) + mapview(nz_capitales_points) Notez que nous n’avons pas besoin de nous assurer que les deux couches soient dans le même SCR puisque la fonction mapview() représente par défaut toutes données spatiales dans la projection Mercator Web. "],["mat.html", "Module 5 Données matricielles", " Module 5 Données matricielles Cette leçon est une introduction aux données spatiales matricielles sous R. Son objectif principal est d’apprendre à lire, interpréter et visualiser des données matricielles. Notez que la section 2.3 Raster data du livre Geocomputation with R des auteurs Robin Lovelace, Jakub Nowosad, et Jannes Muenchow (Lovelace, Nowosad, and Muenchow 2021) est un bon accompagnement à ce module. À la fin de ce module vous saurez: Créer et lire un raster. Interpréter la géométrie d’un raster. Comprendre la structure d’un raster. Obtenir des statistiques simples sur les données contenues dans un raster. Visualiser un raster. Transformer le système de coordonnées de référence d’un raster. Transformer la résolution d’un raster. Lire et visualiser un raster multi-bande. Vous utiliserez les bibliothèques suivantes: raster mapview leafsync Vous apprendrez à utiliser les fonctions suivantes: raster() getValues() maxValue() cellStats() ncell() res() extent() crs() aggregate() projectRaster() writeRaster() brick() stack() viewRGB() mapview() et latticeView(), que vous connaissez déjà. Vous utiliserez les données suivantes: Vous utiliserez aussi les fonctions suivantes, qui ne sont pas spécifiques aux données spatiales: dim() class() levels() factor() plot(), hist(), boxplot() as.data.frame() head() max(), min(), median(), median() summary() names() Dans la section leçon, vous utiliserez deux ensembles de données matricielles. Le premier ensemble contient des données spatiales relatives aux îlots de chaleur urbain dans la région de la ville de Québec. Le second ensemble contient des données spatiales satellites captées par Landsat près de la ville de La Tuque en Mauricie. "],["lecon_mat.html", "5.1 Leçon", " 5.1 Leçon 5.1.1 Télécharger les données Les données Dans les sections 5.1.5 à 5.1.10 du présent module vous apprendrez à lire et visualiser des données déjà existantes. Afin de faciliter le téléchargement de ces multiples données, l’ensemble des couches d’informations spatiales peuvent être téléchargées en cliquant sur un seul lien: données pour le module 5. Sauvegardez le dossier compressé (zip) dans votre répertoire de travail Module5_donnees pour ce module, et dézippez-le. Le dossier comprend deux fichiers tif: Temp_vdq.tif Landsat_LaTuque.tif Les données matricielles Temp_vdq.tif présentent la température de surface sur le territoire de la ville de Québec. Le fichier Landsat_LaTuque.tif contient des données captées par le satellite Landsat sur une section du territoire de la Haute Mauricie, près de la ville de La Tuque. 5.1.2 Créer des données matricielles Les données matricielles représentent la surface terrestre par une grille régulière, communément appelé un raster. Dans cette leçon, nous utiliserons les expressions «raster» et «données matricielles» de façon interchangeable. Pour créer, lire et manipuler des données matricielles, nous allons utiliser la bibliothèque raster. Commençons par charger la bibliothèque raster dans notre session de travail R. # Installez la bibliothèque si ce n&#39;est pas déjà fait # install.packages(&quot;raster&quot;) # Chargez la bibliothèque library(raster) Créer un raster simple et le visualiser Au module 2, nous avons expliqué qu’un raster est formé de rectangles de même forme et de même dimension appelés cellules ou pixels. À chaque cellule de cette matrice correspond une valeur numérique (ou une valeur manquante) associée à un attribut d’intérêt. On appelle couche (« layer » en anglais) l’information recueillie dans la matrice. La fonction raster() de la bibliothèque raster permet de créer un raster. Par exemple: M &lt;- raster(nrows=8, ncols=8, xmn = 1, xmx = 5, ymn = 1, ymx = 5, vals = 1:64) Où nrows et ncols correspondent respectivement au nombre de lignes et au nombre de colonnes du raster M, xmn et xmx correspondent respectivement aux coordonnées-x minimale et maximale du raster, ymn et ymx aux coordonnées-y minimale et maximale, et vals est un vecteur comprenant la valeur de chaque pixel du raster. Dans le cas présent, le raster M contient 64 pixels. Le premier pixel a la valeur 1, le deuxième pixel a la valeur 2 et ainsi de suite. Voyons les informations données, lorsque nous appelons le raster M que nous venons de créer: M class : RasterLayer dimensions : 8, 8, 64 (nrow, ncol, ncell) resolution : 0.5, 0.5 (x, y) extent : 1, 5, 1, 5 (xmin, xmax, ymin, ymax) crs : +proj=longlat +datum=WGS84 +no_defs source : memory names : layer values : 1, 64 (min, max) Nous remarquons que des informations additionnelles apparaissent: ncell correspond au nombre de cellules (ou de pixels) dans le raster, resolution correspond à la résolution des pixels, extent correspond à l’étendue du raster définie par ses coordonnées maximales et minimales, et crs correspond aux paramètres du système de coordonnées de référence utilisé. Si le SCR d’un raster n’est pas défini au moment de sa création, comme dans le cas présent, alors le SCR WGS84 sera attribué par défaut. Remarquez que la classe (class) de l’objet M est défini comme étant un RasterLayer. Nous verrons dans la dernière section de cette leçon qu’il existe d’autres classes de raster, soit les RasterBrick et les RasterStack. Remarquez aussi que la résolution d’un pixel est de 0.5 x 0.5, car les 64 pixels du raster occupent le carré d’aire 16 délimité par les quatre points (1,1), (1,5), (5,1) et (5,5). Ainsi, une façon équivalente de créer le raster M est: M &lt;- raster(res = 0.5, xmn = 1, xmx = 5, ymn = 1, ymx = 5, vals = 1:64) M class : RasterLayer dimensions : 8, 8, 64 (nrow, ncol, ncell) resolution : 0.5, 0.5 (x, y) extent : 1, 5, 1, 5 (xmin, xmax, ymin, ymax) crs : +proj=longlat +datum=WGS84 +no_defs source : memory names : layer values : 1, 64 (min, max) Dans cette notation, nous avons spécifié la résolution et non la dimension du raster. Nous pouvons également connaître les paramètres d’un raster en utilisant les fonctions correspondantes. dim(M) [1] 8 8 1 ncell(M) [1] 64 nrow(M) [1] 8 ncol(M) [1] 8 res(M) [1] 0.5 0.5 extent(M) class : Extent xmin : 1 xmax : 5 ymin : 1 ymax : 5 crs(M) Coordinate Reference System: Deprecated Proj.4 representation: +proj=longlat +datum=WGS84 +no_defs WKT2 2019 representation: GEOGCRS[&quot;unknown&quot;, DATUM[&quot;World Geodetic System 1984&quot;, ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563, LENGTHUNIT[&quot;metre&quot;,1]], ID[&quot;EPSG&quot;,6326]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8901]], CS[ellipsoidal,2], AXIS[&quot;longitude&quot;,east, ORDER[1], ANGLEUNIT[&quot;degree&quot;,0.0174532925199433, ID[&quot;EPSG&quot;,9122]]], AXIS[&quot;latitude&quot;,north, ORDER[2], ANGLEUNIT[&quot;degree&quot;,0.0174532925199433, ID[&quot;EPSG&quot;,9122]]]] Il existe plusieurs fonctions permettant de visualiser les rasters. Nous pouvons simplement utiliser la fonction plot(). plot(M) Figure 5.1: Visualisation du raster M avec la fonction plot() Nous pouvons aussi utiliser la fonction mapview() de la bibliothèque mapview: library(mapview) library(leaflet) mapview(M) Figure 5.2: Visualisation du raster M avec la fonction mapview() Nous avons une certaine préférence pour l’esthétique qu’offre mapview(), n’est-ce pas? Peu importe la fonction choisie, celle-ci transforme la valeur de chaque cellule en couleur. Différentes pallettes de couleur peuvent être utilisées, mais pour l’instant, limitons-nous à la palette de couleur par défaut, qui est inferno de la bibliothèque viridis, inclue automatiquement dans la bibliothèque mapview. Remarquez que le premier pixel, qui porte la valeur 1 dans le cas présent, se trouve en haut à gauche. Le dernier pixel, quant à lui, se trouve dans le coin inférieur droit. L’identité des pixels suit donc les lignes d’un raster. Raster de différents types de données Les rasters peuvent prendre des valeurs de type discrètes (integer) et des nombres réelles (numeric). Ils peuvent également prendre des valeurs logiques (logical). Par exemple, remplaçons les valeurs discrètes du raster M défini plus haut par des valeurs logiques. z &lt;- 1:64 class(z) #la fonction class() renvoie le type de données de l&#39;objet z [1] &quot;integer&quot; # Créons un nombre logique qui est vrai lorsque z est un multiple de trois, et faux autrement z_mult3 &lt;- z %% 3 == 0 # La fonction modulo, s&#39;exprime par le symbole %%, # L&#39;expression x %% y vaut 0 si y est un multiple de x, # L&#39;expression x %% y vaut r si y n&#39;est pas un multiple de x. # r correspond alors au reste de la division x/y z_mult3 [1] FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE [9] TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE [17] FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE [25] FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE [33] TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE [41] FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE [49] FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE [57] TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE class(z_mult3) #vérifions que les valeurs sont bien de type logique [1] &quot;logical&quot; # utilisons le vecteur logique z_mult3 pour créer un raster logique M_logique &lt;- raster(nrows = 8, ncols = 8, xmn = 1, xmx = 5, ymn = 1, ymx = 5, vals = z_mult3) M_logique class : RasterLayer dimensions : 8, 8, 64 (nrow, ncol, ncell) resolution : 0.5, 0.5 (x, y) extent : 1, 5, 1, 5 (xmin, xmax, ymin, ymax) crs : +proj=longlat +datum=WGS84 +no_defs source : memory names : layer values : 0, 1 (min, max) Visualisons maintenant ce raster de type logique: Figure 5.3: Raster dont les valeurs sont de type logique Les rasters ne peuvent pas prendre des valeurs de type caractères (character) mais ils peuvent tout de même prendre des valeurs catégoriques. Petit rappel, avec R, les données catégoriques sont représentées par des données de type facteurs (factor). Plus précisément, les données catégoriques sont emmagasinées comme étant des nombres entiers auxquels sont associés des étiquettes - des identifiants uniques. Nous référons à ces identifiants comme étant des niveaux (levels). Par exemple: # Définissons un vecteur de caractères mois_hiver &lt;- c(&quot;décembre&quot;, &quot;janvier&quot;, &quot;février&quot;, &quot;mars&quot;) # Ce vecteur est bel et bien de type caractère class(mois_hiver) [1] &quot;character&quot; # Maintenant transformons ce vecteur en vecteur de type facteur mois_hiver_facteur &lt;- factor(mois_hiver) # Ce vecteur transformé est bien de type facteur class(mois_hiver_facteur) [1] &quot;factor&quot; # Ce nouveau vecteur possède 4 niveaux différents mois_hiver_facteur [1] décembre janvier février mars Levels: décembre février janvier mars # ou encore levels(mois_hiver_facteur) [1] &quot;décembre&quot; &quot;février&quot; &quot;janvier&quot; &quot;mars&quot; Revenons maintenant aux rasters. Reprenons l’exemple du raster des multiples de 3. Nous allons le transformer en raster de type facteur. # Nous transformons d&#39;abord le vecteur z de nombres entiers de 1 à 64, # en vecteur de type caractère z_char &lt;- z z_char[z%%3 == 0] &lt;- &quot;Multiple de 3&quot; z_char[z%%3 != 0] &lt;- &quot;Autre&quot; class(z_char) [1] &quot;character&quot; # Transformons le vecteur z_char en vecteur de type facteur z_fact &lt;- factor(z_char) class(z_fact) [1] &quot;factor&quot; # Obtenons maintenant un raster de type facteur M_factor &lt;- raster(nrows = 8, ncols = 8, xmn = 1, xmx = 5, ymn = 1, ymx = 5, vals = z_fact) M_factor class : RasterLayer dimensions : 8, 8, 64 (nrow, ncol, ncell) resolution : 0.5, 0.5 (x, y) extent : 1, 5, 1, 5 (xmin, xmax, ymin, ymax) crs : +proj=longlat +datum=WGS84 +no_defs source : memory names : layer values : 1, 2 (min, max) attributes : ID VALUE 1 Autre 2 Multiple de 3 Visualisons maintenant ce raster de type facteur: mapview(M_factor) Figure 5.4: Raster dont les valeurs sont de type facteur 5.1.3 Comprendre la structure d’un raster Les objets de type raster disposent d’une structure d’objet particulière. Si l’on veut accéder aux valeurs stockées, on doit procéder d’une certaine manière. La valeur d’une cellule peut être obtenue en référant à l’identifiant (indice) de son pixel; c’est-à-dire un numéro entre 1 et le nombre total de cellules, ncell, dans le raster. La valeur d’une cellule peut aussi être obtenue en référant à sa position (ligne, colonne) dans sa structure matricielle. Par exemple, considérons le raster G suivant, de dimensions 5 par 5, former de nombres aléatoires entre 0 et 1. class : RasterLayer dimensions : 5, 5, 25 (nrow, ncol, ncell) resolution : 0.5, 0.5 (x, y) extent : 1, 3.5, 1, 3.5 (xmin, xmax, ymin, ymax) crs : +proj=longlat +datum=WGS84 +no_defs source : memory names : layer values : 0.1, 1 (min, max) La figure suivante illustre comment les cellules sont indexées et positionnées dans un raster. La cellule supérieure gauche, de position [1,1] est toujours celle portant l’indice 1. Figure 5.5: Structure d’un raster: indice, position et valeur des pixels Ainsi, pour accéder à des valeurs spécifiques du raster, on procède de la façon suivante: # Accéder à la première valeur G[1] [1] 0.2 # Accéder à la valeur de la cellule à la position (3,2) G[3, 2] [1] NA # Accéder aux valeurs de 5 à 10 G[5:10] [1] 0.4 0.3 0.6 0.4 0.6 0.4 # Accéder à des valeurs spécifiques G[c(7, 13, 17:20)] [1] 0.6 1.0 0.6 0.4 NA 0.2 Il est souvent plus simple d’utiliser l’indice lorsque nous voulons accéder aux valeurs de plusieurs cellules. Par ailleurs, l’utilisation de la position, est souvent plus intuitive. Notons toutefois qu’il peut être dangereux d’extraire des valeurs en utilisant les indices des cellules. En effet, nous perdons une information précieuse: la localisation de la cellule dans l’espace; c’est-à-dire ses coordonnées X et Y. C’est pourquoi, il est souvent privilégié de convertir le raster en data.frame. La fonction as.data.frame(..., xy = TRUE), appliquée à un objet de classe raster, présente l’avantage de retourner les coordonnées associées à l’indice. G_df &lt;- as.data.frame(G, xy = TRUE) head(G_df) x y layer 1 1.25 3.25 0.2 2 1.75 3.25 0.3 3 2.25 3.25 NA 4 2.75 3.25 NA 5 3.25 3.25 0.4 6 1.25 2.75 0.3 Ainsi, en référant à l’indice d’une cellule, nous pouvons connaître non seulement sa valeur mais aussi sa localisation dans l’espace. G_df[13, ] x y layer 13 2.25 2.25 1 Notez que par défaut, la coordonnée renvoyée par la fonction as.data.frame() correspond au coin inférieur gauche de chaque pixel. Il est cependant possible de renvoyer le centroid du pixel en utilisant l’argument as.data.frame(..., xy = TRUE, centroids = TRUE). Figure 5.6: (A) Coordonnées renvoyées par défaut par la fonction as.data.frame; (B) Coordonnées des centroïdes des pixels renvoyées lorsque l’argument centroids = TRUE est utilisé dans la fonction as.data.frame 5.1.4 Statistiques de base sur un raster Voyons maintenant comment calculer des statistiques de base sur les valeurs contenues dans un raster. Tout d’abord, pour connaître l’ensemble des valeurs d’un raster, nous pouvons utiliser la fonction getValues(). getValues(G) [1] 0.2 0.3 NA NA 0.4 0.3 0.6 0.4 0.6 0.4 1.0 NA [13] 1.0 0.1 0.3 0.4 0.6 0.4 NA 0.2 0.1 1.0 0.1 0.3 [25] 0.5 Cette fonction est équivalente à G[] [1] 0.2 0.3 NA NA 0.4 0.3 0.6 0.4 0.6 0.4 1.0 NA [13] 1.0 0.1 0.3 0.4 0.6 0.4 NA 0.2 0.1 1.0 0.1 0.3 [25] 0.5 Nous pouvons alors calculer des statistiques élémentaires sur ces valeurs. Par exemple, quelle est la valeur maximale du raster G? max(getValues(G), na.rm = TRUE) [1] 1 Noter que nous devons préciser que les valeurs NA ne soient pas prises en considération lors du calcul de statistiques. En effet, na.rm = TRUE signifie que les valeurs NA sont retirées (remove en anglais, abrégé par rm). Plus simplement, nous pouvons utiliser la fonction équivalente maxValue exclusive aux données de classe raster. maxValue(G) [1] 1 De la même façon, nous pouvons obtenir d’autres statistiques élémentaires: minValue(G) [1] 0.1 min(getValues(G), na.rm = TRUE) [1] 0.1 mean(getValues(G), na.rm = TRUE) [1] 0.4381 median(getValues(G), na.rm = TRUE) [1] 0.4 quantile(getValues(G), na.rm = TRUE) 0% 25% 50% 75% 100% 0.1 0.3 0.4 0.6 1.0 La fonction summary() permet d’obtenir plusieurs statistiques: summary(G) layer Min. 0.1 1st Qu. 0.3 Median 0.4 3rd Qu. 0.6 Max. 1.0 NA&#39;s 4.0 En plus du minimum, du maximum, et de la médiane, la fonction summary() retourne le premier et le troisième quantile, ainsi que le nombre de cellules de valeur NA contenu dans le raster. La fonction cellStats permet également d’obtenir des statistiques sur les rasters. La statistique désirée doit être précisée dans les options de la fonction cellStats. Par exemple: cellStats(G, mean, na.rm = TRUE) [1] 0.4381 cellStats(G, sd, na.rm = TRUE) #la déviation standard [1] 0.2801 cellStats(G, max, na.rm = TRUE) [1] 1 cellStats(G, min, na.rm = TRUE) [1] 0.1 cellStats(G, median, na.rm = TRUE) [1] 0.4 cellStats(G, quantile, na.rm = TRUE) 0% 25% 50% 75% 100% 0.1 0.3 0.4 0.6 1.0 cellStats(G, range, na.rm = TRUE) #le minimum et le maximum [1] 0.1 1.0 cellStats(G, sum, na.rm = TRUE) [1] 9.2 Nous pouvons également visualiser la distribution des valeurs contenues dans un raster en utilisant les fonctions R usuelles telles que hist() ou boxplot. Par exemple, hist(G, main = &quot;&quot;, xlab = &quot;Valeurs&quot;, ylab = &quot;Fréquence&quot;, col = &quot;darkorange&quot;) Figure 5.7: Histogramme de la distribution des valeurs dans le raster G Ou encore, boxplot(G, main = &quot;&quot;, ylab = &quot;Valeurs&quot;, col = &quot;darkorange&quot;) Figure 5.8: Valeur moyenne et intervalle de confiance du raster G 5.1.5 Lire un raster et explorer son contenu Dans les sections précédentes, nous avons créé et manipulé des rasters très simples et peu volumineux. Dans cette section, nous manipulerons un raster plus substantiel, constitué de données réelles sur les îlots de chaleur urbains. Les îlots de chaleur urbains (ICU) sont des “zones urbaines où les températures sont plus chaudes que dans la région rurale voisine” (Santé Canada 2020). Les ICU amplifient les effets négatifs sur la santé humaine pendant les vagues de chaleur. Les ICU se produisent surtout dans les zones où les humains ont fortement altéré le couvert du sol, par exemple pour y aménager des infrastructures en béton (bâtiments, stationnement, route, etc.). L’absence de végétation, la présence de surfaces imperméables et non-réfléchissantes contribuent à la formation d’ICU (Santé Canada 2020). La température de surface mesurée sur les territoires urbains permet d’identifier la présence d’îlots de chaleur30. Les données sur les ICU pour l’ensemble du territoire québécois sont disponibles sur le site gouvernemental Données Québec en format GeoTIFF. Puisque cette base de données spatiales est particulièrement volumineuse, nous allons travailler seulement avec les données matricielles relatives à la région de la ville de Québec. Lire les données Nous allons maintenant lire les données matricielles en utilisant la fonction raster() de la bibliothèque raster. T_vdq &lt;- raster(&quot;Module5/Module5_donnees/Temp_vdq.tif&quot;) Nous pouvons d’emblée reconnaître les informations relatives à la dimension, la résolution, l’étendue, le CRS, et aux valeurs minimale et maximale du raster T_vdq. Nous pouvons également utiliser les fonctions dim(), ncell(), res(), extent(), crs(), et cellStats(, range) pour retrouver ces informations: dim(T_vdq) [1] 857 860 1 ncell(T_vdq) [1] 737020 res(T_vdq) [1] 40 40 extent(T_vdq) class : Extent xmin : -230083 xmax : -195683 ymin : 300611 ymax : 334891 cellStats(T_vdq, range) [1] 1 9 crs(T_vdq) Coordinate Reference System: Deprecated Proj.4 representation: +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=46 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs WKT2 2019 representation: PROJCRS[&quot;unnamed&quot;, BASEGEOGCRS[&quot;NAD83&quot;, DATUM[&quot;North American Datum 1983&quot;, ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101004, LENGTHUNIT[&quot;metre&quot;,1]]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ID[&quot;EPSG&quot;,4269]], CONVERSION[&quot;Lambert Conic Conformal (2SP)&quot;, METHOD[&quot;Lambert Conic Conformal (2SP)&quot;, ID[&quot;EPSG&quot;,9802]], PARAMETER[&quot;Latitude of false origin&quot;,44, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8821]], PARAMETER[&quot;Longitude of false origin&quot;,-68.5, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8822]], PARAMETER[&quot;Latitude of 1st standard parallel&quot;,46, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8823]], PARAMETER[&quot;Latitude of 2nd standard parallel&quot;,60, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8824]], PARAMETER[&quot;Easting at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8826]], PARAMETER[&quot;Northing at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8827]]], CS[Cartesian,2], AXIS[&quot;easting&quot;,east, ORDER[1], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]], AXIS[&quot;northing&quot;,north, ORDER[2], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]]] Le nom de la couche de données matricielles contenue dans ce raster, c’est-à-dire son attribut, est obtenu en utilisant la fonction names(). names(T_vdq) [1] &quot;Temp_vdq&quot; Nous pouvons changer ce nom pour un nouveau: names(T_vdq) &lt;- &quot;ICU&quot; T_vdq class : RasterLayer dimensions : 857, 860, 737020 (nrow, ncol, ncell) resolution : 40, 40 (x, y) extent : -230083, -195683, 300611, 334891 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=46 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs source : Temp_vdq.tif names : ICU values : 1, 9 (min, max) Explorer les statistiques de base Utilisons la fonction summary() pour déterminer les statistiques de base du raster T_vdq: summary(T_vdq) Warning in .local(object, ...): summary is an estimate based on a sample of 1e+05 cells (13.57% of all cells) ICU Min. 1.00 1st Qu. 2.00 Median 3.75 3rd Qu. 6.25 Max. 9.00 NA&#39;s 310116.00 Remarquez le message retourné par R: “summary is an estimate based on a sample of 1e+05 cells (3.39% of all cells)”. Ce message nous prévient que, par défaut, les calculs de la fonction summary() sont réalisés sur un échantillon de 100 000 cellules choisies aléatoirement. Dans le cas présent, puisque le raster T_vdq contient ncells(T_vdq) = 2946366 cellules, un échantillon de 100 000 cellules correspond donc seulement à 3.39% de toutes les cellules. La limite par défaut du nombre de cellules sélectionnées pour calculer les statistiques dans la fonction summary() est très utile pour obtenir des résultats rapides, surtout lorsque raster est volumineux. Cependant, dans certains cas, cet échantillonnage limité pourrait mener à un estimé trompeur. Ainsi, il est toujours possible de spécifier la taille désirée de l’échantillon en utilisant l’option maxsamp. Par exemple, summary(T_vdq, maxsamp = ncell(T_vdq)) ICU Min. 1.00 1st Qu. 2.00 Median 3.75 3rd Qu. 6.25 Max. 9.00 NA&#39;s 311157.00 Vous remarquerez que l’exécution de la fonction summary() peut prendre plus de temps lorsque le nombre de cellules échantillonnées est plus grand. Dans le cas présent du raster T_vdq, les statistiques demeurent inchangées mais le nombre de valeurs NA a été corrigées. Nous pouvons également visualiser l’histogramme des valeurs de température de surface. hist(getValues(T_vdq), breaks = 10, main = &quot;&quot;, xlab = &quot;Valeurs&quot;, ylab = &quot;Fréquence&quot;, col = &quot;darkorange&quot;) Figure 5.9: Distribution des températures de surface dans la ville de Québec Remarquez que nous avons spécifié que la distribution soit calculée sur l’ensemble des valeurs contenues dans le raster T_vdq en utilisant la fonction getValues(). Autrement, la fonction hist() appliquée à un raster utilise un échantillonnage aléatoire de 100 000 cellules, similairement à la fonction summary(). 5.1.6 Visualiser les données matricielles avec mapview() Nous allons visualiser la carte des températures de surface de la région de la ville de Québec en utilisant la fonction mapview(). Afin de situer plus facilement la région illustrée sur le territoire du Québec, nous allons demander d’ajouter la carte d’OpenStreetMap31 comme carte de fonds. mapview(T_vdq, map.types = &quot;OpenStreetMap&quot;, legend = TRUE, layer.name = &#39;ICU&#39;) Figure 5.10: Carte de la température de surface dans la ville de Québec L’échelle de la légende indique des niveaux de température. Le niveau 1 correspond aux températures les plus fraîches, et le niveau 9 aux température les plus chaudes. Vous remarquerez que la résolution de cette carte n’est pas parfaite. En effet, par défaut, la fonction mapview() appliquée à un raster utilise 500 000 pixels. Pour que l’ensemble des pixels soient pris en compte, nous devons le préciser en définissant l’option maxpixels. mapview(T_vdq, maxpixels = ncell(T_vdq), map.types = &quot;OpenStreetMap&quot;, legend = TRUE, layer.name = &#39;ICU&#39;) Figure 5.11: Carte de la température de surface dans la ville de Québec (visualisation de tous les pixels) Naturellement, le temps nécessaire pour générer la carte est alors plus long. Visualiser une section d’un raster Nous voulons maintenant nous concentrer sur une petite section de la carte de la région de la ville de Québec. Nous pouvons le faire en spécifiant les lignes et les colonnes qui nous intéressent dans le raster. Par exemple, choisissons une région carrée de 100 x 100 cellules dans le quartier Sainte-Foy. T_sec &lt;- T_vdq[351:450, 351:450, drop = FALSE] mapview(T_sec, map.types = &quot;OpenStreetMap&quot;) Figure 5.12: Carte de la température de surface dans le secteur de Sainte-Foy Notez que l’option drop = FALSE est importante car elle permet au nouvel objet T de demeurer un raster comme T_vdq. Autrement, T deviendrait un simple vecteur. Nous observons sur la carte que les températures les plus chaudes (pixels de couleur jaune) sont situées sur les grandes infrastructures bétonnées comme les axes routiers ainsi que les bâtiments et les stationnements (par exemple ceux de la Place Laurier et Sainte-Foy). D’autre part, les températures les plus fraîches (pixels de couleur mauve foncé) sont situés sur des zones boisées comme celles sur le campus de l’Université Laval. 5.1.7 Changer la résolution d’un raster Il est possible d’augmenter la résolution d’un raster. Cela peut s’avérer utile lorsque la résolution de ce dernier est trop petite (c’est-à-dire que la résolution est fine) pour exécuter rapidement des calculs sur celui-ci. Aussi, cela peut s’avérer utile lorsque nous devons travailler avec des rasters de résolution différente, il peut alors être nécessaire que tous les rasters aient la même résolution. Pour augmenter la résolution d’un raster nous utilisons la fonction aggregate(). Nous devons alors spécifier le facteur, fact, par lequel nous voulons augmenter la résolution. Par exemple, fact = 4 augmentera la résolution par un facteur de \\(4 * 4\\). C’est-à-dire qu’une cellule de taille \\(x * y\\) aura, dans le nouveau raster, une taille \\(4x * 4y\\). Elle aura donc une taille 16 fois plus grande que dans le raster initial. Quelle valeur prendra alors une cellule de plus grande résolution? Par défaut, la cellule aura comme valeur la moyenne des valeurs des cellules groupées par l’agrégation. Par ailleurs, il est aussi possible de specifier d’autres fonctions pour calculer la valeur des cellules de plus grande résolution en utilisant l’option fun. Par exemple, nous pourrions choisir que la valeur agrégée corresponde à la valeur maximum des valeurs des cellules groupées. T_fact4_moy &lt;- aggregate(T_sec, fact = 4) T_fact4_max &lt;- aggregate(T_sec, fact = 4, fun = &#39;max&#39;) T_fact8_moy &lt;- aggregate(T_sec, fact = 8) T_fact8_max &lt;- aggregate(T_sec, fact = 8, fun = &#39;max&#39;) mapviewOptions(basemaps = &quot;OpenStreetMap&quot;) map_fact4_moy &lt;- mapview(T_fact4_moy, legend = FALSE, homebutton = FALSE) map_fact4_max &lt;- mapview(T_fact4_max, legend = FALSE, homebutton = FALSE) map_fact8_moy &lt;- mapview(T_fact8_moy, legend = FALSE, homebutton = FALSE) map_fact8_max &lt;- mapview(T_fact8_max, legend = FALSE, homebutton = FALSE) leafsync::latticeView(map_fact4_moy, map_fact4_max, map_fact8_moy, map_fact8_max, ncol = 2) Remarquez que nous avons utilisé la fonction latticeView() pour visualiser ces quatre cartes sur deux colonnes. 5.1.8 Changer la projection d’un raster Comme pour les données vectorielles, il est possible de manipuler le système de coordonnées de référence de données matricielles. Rappelons que pour connaître le SCR d’un raster il s’agit d’utiliser la fonction crs() de la bibliothèque raster. crs(T_vdq) Coordinate Reference System: Deprecated Proj.4 representation: +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=46 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs WKT2 2019 representation: PROJCRS[&quot;unnamed&quot;, BASEGEOGCRS[&quot;NAD83&quot;, DATUM[&quot;North American Datum 1983&quot;, ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101004, LENGTHUNIT[&quot;metre&quot;,1]]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ID[&quot;EPSG&quot;,4269]], CONVERSION[&quot;Lambert Conic Conformal (2SP)&quot;, METHOD[&quot;Lambert Conic Conformal (2SP)&quot;, ID[&quot;EPSG&quot;,9802]], PARAMETER[&quot;Latitude of false origin&quot;,44, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8821]], PARAMETER[&quot;Longitude of false origin&quot;,-68.5, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8822]], PARAMETER[&quot;Latitude of 1st standard parallel&quot;,46, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8823]], PARAMETER[&quot;Latitude of 2nd standard parallel&quot;,60, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8824]], PARAMETER[&quot;Easting at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8826]], PARAMETER[&quot;Northing at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8827]]], CS[Cartesian,2], AXIS[&quot;easting&quot;,east, ORDER[1], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]], AXIS[&quot;northing&quot;,north, ORDER[2], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]]] Nous pouvons également utiliser la fonction st_crs() de la bibliothèque sf sur un raster. Cela nous permet d’obtenir, entre autres, le SCR selon la syntaxe PROJ4. library(sf) st_crs(T_vdq)$proj4string [1] &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=46 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Rappelons que les arguments de la notation PROJ4 ont la signification suivante: +proj : le nom de la projection +lat_0 : la latitude de l’origine +lon_0 : la longitude du méridien central +lat_1 : la latitude du premier parallèle standard32 +lat_2 : la latitude du deuxième parallèle standard +x_0 : le faux est (false easting; dans le cas de projection transverse comme UTM) +y_0 : le faux nord (false northing) +datum : le nom du datum +units : les unités (mètres, pieds, etc.) Nous remarquons que les données matricielles sur les îlots de chaleur de la ville de Québec sont dans la projection conique conforme de Lambert (+proj=lcc). Cette dernière est appropriée pour représenter des données à l’échelle de la province. Celle-ci est basée sur le datum NAD83 qui être très proche du datum WGS84. Retournez voir le Module 2 pour un rappel des systèmes de coordonnées de référence! Nous voulons maintenant transformer le système de coordonnées de référence du raster T_vdq vers le système MTM, c’est-à-dire la projection Mercator transverse modifiée. Celle-ci est basée aussi sur le datum NAD83. Dans le système MTM, la ville de Québec ce situe dans le fuseau 7. Pour savoir comment définir cette projection, c’est-à-dire quels paramètres utilisés, vous pouvez vous rendre sur le site web spatialreference.org. Dans la fenêtre de recherche Search tapez “MTM zone 7”. Une liste de de code EPSG apparaîtra. Sélectionnez le code “EPSG:2949: NAD83(CSRS) / MTM zone 7”. Le carré gris qui apparaît propose différents formats possibles pour définir une projection. Choisissez “Proj4”. La liste des paramètres qui définissent la projection MTM pour le fuseau 7 est alors donnée. Vous pouvez donc copier cette définition, et l’utiliser pour définir la nouvelle projection. proj_mtm7 &lt;- &quot;+proj=tmerc +lat_0=0 +lon_0=-70.5 +k=0.9999 +x_0=304800 +y_0=0 +ellps=GRS80 +units=m +no_defs&quot; Pour transformer la projection d’un raster, nous devons utiliser la fonction projectRaster() de la bibliothèque Raster. T_mtm7 &lt;- projectRaster(T_vdq, crs = proj_mtm7) Comparons les deux cartes utilisant des projections différentes: par(mfrow = c(1,2)) plot(T_vdq, main = &quot;Québec Lambert&quot;, legend = FALSE) plot(T_mtm7, main = &quot;MTM fuseau 7&quot;) Figure 5.13: Rasters de projections Québec Lambert et MTM Il est difficile de percevoir une différence, car celle-ci est légère. Pour s’en convaincre, visualisons une plus petite section de la carte de la ville de Québec: Figure 5.14: Section des rasters de projections Québec Lambert et MTM Remarquez que la carte de droite, utilisant la projection MTM, est, en effet, inclinée par rapport à la carte utilisant la projection Québec Lambert. Remarquez aussi que les coordonnées des axes x et y sont différentes. De plus, vous aurez sans doute remarqué que nous avons utilisé la fonction plot() et non mapview() pour afficher ces cartes. En effet, au moment d’écrire ces lignes, la fonction mapview() ne permet pas d’afficher des données matricielles dans leur CRS d’origine. Les données matricielles sont automatiquement transformées selon la projection Web de Mercator au moment de la visualisation, si bien qu’il est impossible de percevoir les différences provenant de projections différentes. Ce problème n’existe pas pour les données vectorielles pour lesquelles nous pouvons utiliser l’option crs.native = TRUE. Pour sélectionner une région précise dans un raster, nous avons utilisé la fonction crop(). Nous reviendrons en détails sur cette fonction dans le module 8 qui traite de la manipulation de données matricielles. 5.1.9 Sauvegarder un raster Finalement, pour sauvegarder des données matricielles, nous utilisons la fonction writeRaster() de la bibliothèque raster. Par exemple, sauvons les données matricielles T_vdq que nous avons transformées dans le système de projection MTM. nom_du_fichier&lt;- &quot;Module5/Module5_donnees/ICU_vdq_MTM7.tif&quot; writeRaster(T_mtm7,nom_du_fichier) 5.1.10 Lire et visualiser des données matricielles multi-bande Les données matricielles peuvent contenir plusieurs couches, appelées aussi des bandes ou des canaux. C’est le cas des images de couleurs qui contiennent souvent trois bandes: une bande de rouge, une bande de vert et une bande de bleu. Dans cette section, nous apprendrons à lire et visualiser ce type de raster en utilisant des données satellitaires. Le gouvernement québécois abrite sur son site Données Québec les données satellites, captées par Sentinel-2 et Landsat, couvrant l’ensemble de la province. Nous parlons alors d’une mosaïque d’images. Sentinel-2 est une mission d’observation de la Terre de l’Agence spatiale européenne, tandis que Landsat est une mission développée par l’Agence spatiale américaine. Pour en apprendre davantage sur ces programmes d’observation et sur les satellites utilisés, consultez les sites de Sentinel-2 et de Landsat ou encore les sites respectifs de Wikipédia (Sentinel-2 et Landsat). La résolution des images captées par Sentinel-2 est de 10 m par 10 m, et celle de Landsat est de 30 m par 30 m. Ces images permettent ainsi d’identifier la couverture du sol avec beaucoup de précisions. On les utilise alors pour décrire comment les milieux forestiers, agricoles, humides et anthropisés sont distribués sur le territoire et comment ils évoluent dans le temps. Ces images sont utilisées lors de la planification et l’aménagement du territoire et de ses ressources. Lire des données multi-bande Nous allons maintenant lire le fichier Landsat_LaTuque.tif qui correspond aux données satellitaires captées par Landsat sur une section du territoire de la Haute Mauricie, près de la ville de La Tuque. Pour ce faire, nous utilisons la fonction raster() de la bibliothèque `raster’: S &lt;- raster(&quot;Module5/Module5_donnees/Landsat_LaTuque.tif&quot;) S class : RasterLayer band : 1 (of 3 bands) dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : Landsat_LaTuque.tif names : Landsat_LaTuque values : 0, 254.8 (min, max) Nous remarquons qu’une information supplémentaire est apparue dans le description du raster. Il s’agit de band : 1 (of 3 bands). Cette information nous précise que nous venons de lire une seule bande alors que ces données matricielles en contiennent trois. Lorsque nous rencontrons un raster de plusieurs bandes, il faut plutôt utiliser la fonction brick() ou la fonction stack() de la bibliothèque raster pour lire l’ensemble des bandes. S_mult &lt;- brick(&quot;Module5/Module5_donnees/Landsat_LaTuque.tif&quot;) Remarquez que la classe de l’objet S_mult est RasterBrick et non pas simplement Raster comme l’objet S précédent. De plus, dimensions spécifie maintenant que S_mult contient trois couches (nlayers). Le nom de chaque couche est également donné: Landsat_LaTuque.1, Landsat_LaTuque.2 et Landsat_LaTuque.3. Finalement, les valeurs minimum (0) et maximum (255) sont données pour chacune des trois couches. Nous pouvons sélectionner chacune des bandes à partir du raster multi-bande de la façon suivante: SR &lt;- S_mult$Landsat_LaTuque.1 SG &lt;- S_mult$Landsat_LaTuque.2 SB &lt;- S_mult$Landsat_LaTuque.3 Par ailleurs, nous pouvons également lire chacune des bandes individuellement avec la fonction raster(): nom_fichier &lt;- &quot;Module5/Module5_donnees/Landsat_LaTuque.tif&quot; SR &lt;- raster(nom_fichier, band = 1) #lecture de la bande rouge SG &lt;- raster(nom_fichier, band = 2) #lecture de la bande verte (green) SB &lt;- raster(nom_fichier, band = 3) #lecture de la bande bleu SR class : RasterLayer band : 1 (of 3 bands) dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : Landsat_LaTuque.tif names : Landsat_LaTuque values : 0, 254.8 (min, max) SG class : RasterLayer band : 2 (of 3 bands) dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : Landsat_LaTuque.tif names : Landsat_LaTuque values : 2, 255 (min, max) SB class : RasterLayer band : 3 (of 3 bands) dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : Landsat_LaTuque.tif names : Landsat_LaTuque values : 0, 254.8 (min, max) Ainsi, SR correspond à la première bande (la rouge), SG à la deuxième bande (la verte), et SB à la troisième bande (la bleu). Chaque raster comprend des valeurs entre 0 et 255. Ces valeurs correspondent au format RGB, et ensemble ces trois couches permettent de visualiser des images couleurs. RasterBrick et RasterStack Un RasterBrick correspond généralement a différentes bandes spectrales stockées dans un seul objet ou un seul fichier dans la mémoire de votre ordinateur. D’autre part, un RasterStack qu’on obtient par l’utilisation de la fonction stack() permet de combiner des couches provenant de fichiers différents ou d’objets logés à différents endroits de la mémoire de votre ordinateur. Une condition essentielle pour combiner des couches dans un RasterStack est que celles-ci possèdent la même étendue, la même résolution, et le même SCR. Démontrons en quoi consiste unRasterStack par un exemple. Définissons deux couches provenant d’objets différents que nous combinerons par l’utilisation de la fonction stack(). D’abord, utilisons la fonction raster() pour créer un raster qui possède la même géométrie que les couches du raster S_mult. raster_1 &lt;- raster(res = res(SR), ext = extent(SR), crs = crs(SR)) Attribuons des values aux pixels de raster_1. Par exemple, values(raster_1) = 1:ncell(SR) Ici, chaque pixel a comme valeur le numéro de son indice dans la matrice. Ensuite, définissons un deuxième couche correspondant à une bande du raster S_mult: raster_2 &lt;- SR Remarquez que la source de chaque couche ainsi créée diffère: raster_1 class : RasterLayer dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : memory names : layer values : 1, 63001 (min, max) raster_2 class : RasterLayer band : 1 (of 3 bands) dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : Landsat_LaTuque.tif names : Landsat_LaTuque values : 0, 254.8 (min, max) Maintenant, combinons ces deux couches pour former un RasterStack en utilisant la fonction stack(): R_stack &lt;- stack(raster_1, raster_2) R_stack class : RasterStack dimensions : 251, 251, 63001, 2 (nrow, ncol, ncell, nlayers) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs names : layer, Landsat_LaTuque min values : 1, 0 max values : 63001.0, 254.8 Nous avons ainsi créé un raster de classe RasterStack. Visualiser un raster multi-bande Visualisons individuellement les bandes d’un raster multi-bande en utilisant la fonction mapview() de la bibliothèque mapview. # Définissons une palette de gris de 256 tons différents mapviewOptions(raster.palette = gray.colors(256)) # Créons une carte pour chaque bande Map_SR &lt;- mapview(SR, homebutton = FALSE) Map_SG &lt;- mapview(SG, homebutton = FALSE) Map_SB &lt;- mapview(SB, homebutton = FALSE) # Visualisons les trois cartes côte à côte leafsync::latticeView(Map_SR, Map_SG, Map_SB, ncol = 3) Nous pouvons également visualiser les trois bandes ensemble en utilisant la fonction viewRGB() de la librarie mapview. Cette fonction s’applique au raster multibande, et demande qu’on spécifie quelle couche du raster est associée à chacune des couleurs rouge, vert et bleu. viewRGB(S_mult, r = 1, g = 2, b = 3) Les diverses teintes observées sur l’image Landsat peuvent être interprétées pour déduire le type de végétation ou d’utilisation du sol présents. Par exemple, les teintes de vert varient selon l’âge d’un peuplement forestier, sa densité, et s’il est composé de feuillus ou de conifères. Les teintes roses, brunes ou bourgognes sont associées à des perturbations, comme des épidémies d’insecte ou des feux de forêt. Ici, les pixels roses signalent la présence de coupes forestières33. Finalement, pour sauvegarder un raster multi-bande, nous pouvons encore utiliser la fonction writeRaster() de la bibliothèque raster. writeRaster(S_mult, &quot;Module5/Module5_donnees/LaTuque-copie.tif&quot;) Si vous désirez comprendre la méthodologie utilisée pour déterminer la température de surface à partir d’images satellitaires, consulter cette note technique produite par le Centre d’enseignement et de recherche en foresterie de Sainte-Foy inc.↩︎ OpenStreetMap est un outil collaboratif et libre d’accès de cartographie en ligne.↩︎ Souvenez-vous que pour une projection cylindrique ou conique, le plan intersecte le globe le long d’un ou de deux parallèles. Voir la leçon 2↩︎ Pour plus d’informations sur l’interprétation des images Landsat, consultez ce guide produit par le Ministère des Forêts, de la Faune et des Parcs du Québec (Direction des inventaires forestiers 2015).↩︎ "],["ex_mat.html", "5.2 Exercices", " 5.2 Exercices Exercices à venir! "],["carto.html", "Module 6 Cartographie", " Module 6 Cartographie Ce module porte sur la cartographie et il comporte deux objectifs principaux. Le premier objectif est d’apprendre les principes fondamentaux de la cartographie. Le deuxième objectif est d’apprendre les fonctionnalités de la bibliothèque R tmap pour créer divers types de carte avec des données vectorielles et matricielles. À la fin de ce module vous saurez: Décrire les principes fondamentaux à respecter lors de la création d’une carte. Identifier les éléments cartographiques indispensables et optionnels. Décrire les types de cartes générale et thématique. Définir la symbologie utilisée en cartographie. Comprendre le fonctionnement de base de la bibliothèque tmap. Utiliser les fonctions de tmap pour ajouter des éléments cartographiques et ajuster la mise en page d’une carte. Utiliser les fonctions de tmap pour cartographier des données vectorielles de type points, lignes et polygones. Utiliser les fonctions de tmap pour cartographier des données matricielles. Utiliser les fonctions de tmap pour créer des cartes avec symboles proportionnels et choroplèthes. Utiliser les fonctions de tmap pour créer des cartes à panneaux multiples Vous utiliserez les bibliothèques suivantes: tmap grid Vous apprendrez à utiliser les fonctions suivantes: tm_shape() tm_fill() tm_scale_bar() tm_compass() tm_grid() tm_graticules() tm_credits() tmap_arrange() tm_borders() tm_polygons() tm_layout() tm_style() tm_text() tm_lines() tm_markers() tm_raster() tm_legend() tm_symbols() tm_bubbles() tm_facets() viewport() print() Vous utiliserez les données suivantes: Dans la section leçon, vous utiliserez cinq ensembles de données différents. Quatre ensembles sont formés de données vectorielles. Il s’agit de données sur les régions administratives du Québec et la taille de leur population (polygones), des routes du Québec (lignes), des municipalités du Québec (points), et des cas de COVID dans les régions socio-sanitaires du Québec (polygones). L’ensemble de données matricielles correspond à des données d’élévation sur tout le territoire québécois. Dans la section exercice, vous utiliserez des données disponibles dans les bibliothèques tmap et spData. "],["lecon_carto.html", "6.1 Leçon", " 6.1 Leçon 6.1.1 Télécharger les données Les données Importez l’ensemble des données utilisées dans ce module. Sauvegardez le dossier compressé (Module6_donnees.zip) dans votre répertoire de travail pour ce module, et dézippez-le. Ce dossier comprend lui-même cinq sous-dossiers que vous devez également dézipper: COVID Elevation Population Routes Villes Nous utiliserons ces données à partir de la section 6.1.3. Commençons d’abord par une introduction sur les principes de bases de la cartographie. 6.1.2 Principes de base en cartographie 6.1.3 Cartes statiques avec tmap Il existe plusieurs bibliothèques R permettant de visualiser des données spatiales. La bibliothèque mapview, que nous avons déjà utilisée, en est un exemple. La bibliothèque ggplot2, que vous connaissez peut-être, permet de créer des cartes qui peuvent être peaufinées par l’utilisation de fonctions des bibliothèques sf et ggspatial34. Dans le cadre de ce cours, nous nous concentrerons sur la bibliothèque tmap et l’apprentissage de ses fonctions principales. Nous avons choisi tmap parce que cette bibliothèque est relativement simple à utiliser et que ses fonctions sont intuitives. Le fonctionnement de tmap est très similaire à celui de la bibliothèque ggplot2 qui est fort populaire pour la visualisation de données de toutes sortes. Si vous connaissez déjà ggplot2, alors l’apprentissage de tmap vous sera familié. Si vous ne connaissez pas ggplot2, vous pourriez être amenés à l’utiliser dans le futur, et dans ce cas votre connaissance de tmap vous sera utile. De façon générale, nous utilisons tmap pour cartographier des données spatiales de la façon suivante: tm_shape(DonneesSpatiales) + tm_fonction1() + tm_fonction2() + ... La fonction tm_shape() est suivi d’une ou de plusieurs fonctions qui précisent les objets ou les attributs des données à cartographier ainsi que les éléments cartographiques à ajouter et la mise en page souhaitée. Télécharger la bibliothèque tmap: install.packages(&quot;tmap&quot;) Chargez tmap dans votre session de travail R ainsi que les bibliothèques sf et raster dont nous aurons besoin pour lire et manipuler les données vectorielles et matricielles respectivement: library(tmap) library(sf) library(raster) 6.1.4 Les polygones Données sur les régions administratives du Québec Pour débuter notre exploration des fonctions de cartographie offertes avec tmap nous utiliserons les données vectorielles sur les limites des régions administratives du Québec ainsi que la taille de leur population. La taille des populations des régions administratives provient de la Banque de données des statistiques officielles sur le Québec (https://bdso.gouv.qc.ca/), et les limites géographiques des régions proviennent du site Données Québec (https://www.donneesquebec.ca/recherche/dataset/decoupages-administratifs). Utiliser la fonction st_read() de la bibliothèque sf pour lire le shapefile QC_RegAdm_Pop.shp contenu dans le dossier Population: Q &lt;- st_read(&quot;Module6/Module6_donnees/Population/QC_RegAdm_Pop.shp&quot;) Reading layer `QC_RegAdm_Pop&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module6/Module6_donnees/Population/QC_RegAdm_Pop.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 17 features and 8 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -830300 ymin: 118000 xmax: 783300 ymax: 2091000 Projected CRS: NAD83 / Quebec Lambert Observer la structure et les attributs du shapefile Q. Celui-ci contient 17 multipolygones, un pour chacune des régions administratives du territoire québécois. De plus, Q contient 8 attributs: NUM_REG: le numéro associé à la région administrative, NOM_REG: le nom de la région administrative, AREA_REG: la superficie de la région, Pop_tot: la population totale en 2019 dans la région, Pop_0_14: la population agée de 0 à 14 ans, Pop_15_24: la population agée de 15 à 24 ans, Pop_25_64: la population agée de 25 à 64 ans, Pop_65_: la population agée de 65 ans et plus. Intérieur des polygones Fonction tm_fill Créons tout d’abord une carte simple du shapefile Q que nous venons de charger. La fonction tm_fill() permet de remplir de façon homogène l’intérieur des limites d’un polygone. Elle s’applique donc aux données vectorielles de type polygone, et on l’ajoute à la donction tm_shape(). tm_shape(Q)+ tm_fill() Objet tmap La bibliothèque tmap comprend sa propre classe d’objets: map_Q &lt;- tm_shape(Q)+ tm_fill() class(map_Q) [1] &quot;tmap&quot; En créant un objet tmap, la carte est seulement affichée lorsqu’on appelle l’objet. La création d’objet tmap est utile car, comme nous le verrons, elle permet de constituer une carte de base à laquelle nous pouvons ajouter des éléments cartographiques. Frontières des polygones Fonction tm_borders() La fonction tm_borders() permet d’illustrer les frontières des polygones: # frontiere des regions admin tm_shape(Q) + tm_borders() La fonction tm_borders() peut s’utiliser conjointement avec la fonction tm_fill(): # Quebec + frontiere tm_shape(Q) + tm_fill() + tm_borders() Fonction tm_polygons() Par ailleurs, la fonction tm_polygons() est équivalente l’utilisation conjointe de tm_borders() et tm_fill(): # tm_polygons = tm_fill + tm_borders tm_shape(Q) + tm_polygons() Paramètres esthétiques Les fonctions tm_borders() et tm_fill() possèdent plusieurs arguments pour ajuster l’apparence de la carte. Voici des exemples: # couleur des polygones Q1 &lt;- tm_shape(Q) + tm_fill(col=&quot;green&quot;) # transparence Q2 &lt;- tm_shape(Q) + tm_fill(col=&quot;green&quot;, alpha = 0.4) # couleur des frontières Q3 &lt;- tm_shape(Q) + tm_borders(col=&quot;green&quot;) # épaisseur du trait Q4 &lt;- tm_shape(Q) + tm_borders(col=&quot;pink&quot;, lwd = 4) # type de trait Q5 &lt;- tm_shape(Q) + tm_borders(col=&quot;blue&quot;, lty = 2) # couleur des polygones et des frontières Q6 &lt;- tm_shape(Q) + tm_fill(col=&quot;blue&quot;, alpha = 0.3) + tm_borders(col=&quot;black&quot;) tmap_arrange(Q1,Q2,Q3,Q4,Q5,Q6) Figure 6.1: Cette figure est inspirée de la figure 9.3 du livre Geocomputation with R (Lovelace, Nowosad, and Muenchow 2021). Attributs des polygones La création de cartes, à partir de données vectorielles de type polygone, nécessite parfois de colorer individuellement les polygones. Par exemple, la couleur d’un polygone peut représenter la valeur d’un de ses attributs. Dans ce cas, nous utilisons la fonction tm_fill() en associat à l’argument col le nom de l`attribut que nous désirons illustrer. tm_shape(Q) + tm_fill(col=&quot;NUM_REG&quot;, title = &quot;Régions&quot;) Dans le cas ci-dessus, l’attribut illustré (NUM_REG) est catégorique et distinct pour chaque polygone. Nous pouvons aussi choisir d’illustrer un seul des polygones d’un shapefile. Dans un tel cas, nous devons isoler le polygone désiré et n’illustrer que ce dernier avec la fonction tm_shape(). Par exemple, isolons le polygone correspondant à la région de l’Outaouais: Q_Outaouais &lt;- Q[Q$NOM_REG == &quot;Outaouais&quot;,] tm_shape(Q_Outaouais) + tm_fill(col=&quot;blue&quot;, alpha = 0.4) Nous pouvons également vouloir mettre l’emphase sur un polygone en particulier, en assignant une couleur seulement à celui-ci, tout en cartographiant l’ensemble des polygones. Dans ce cas, nous pouvons utiliser le caractère additif des objets tmap. Nous créons un premier objet représentant l’ensemble des polygones et nous lui additionnons un deuxième objet représentant le polygone que nous souhaitons mettre en évidence. # Une option Q1 &lt;- tm_shape(Q) + tm_borders(col=&quot;black&quot;) Q2 &lt;- tm_shape(Q_Outaouais) + tm_fill(col=&quot;blue&quot;, alpha = 0.4) Q12 &lt;- Q1 + Q2 # Une autre option Q3 &lt;- tm_shape(Q) + tm_fill() Q4 &lt;- tm_shape(Q_Outaouais) + tm_borders(col=&quot;blue&quot;, lwd = 4) Q34 &lt;- Q3 + Q4 tmap_arrange(Q12,Q34) Remarquer l’usage de la fonction tmap_arrange() pour afficher des cartes côte-à-côte. 6.1.5 Spécificités cartographiques Barre d’échelle et rose des vents Fonctions tm_scale_bar() et tm_compass L’ajout d’un barre d’échelle et d’une rose des vents, se fait par l’utilisation des fonctions tm_scale_bar() et tm_compass() respectivement: map_Q + # la carte du Québec que nous avons créée plus haut # ajout d&#39;une barre d&#39;échelle tm_scale_bar(breaks = c(0,250,500), text.size = 0.8, position=c(&quot;right&quot;,&quot;bottom&quot;)) + # ajout d&#39;une rose des vents tm_compass(type = &quot;arrow&quot;, position = c(&quot;right&quot;, &quot;top&quot;)) où l’argument break précise les divisions sur la barre d’échelle, text.size la taille du texte sous la barre, et position la position de la barre sur la carte (gauche ou droite, haut ou bas). Plusieurs options d’arguments sont possibles. Utilisez help(tm_scale_bar) ou help(tm_compass) pour connaître les autres arguments possibles pour ces fonctions. Par exemple, map_Q + tm_scale_bar(width = 2, position=c(&quot;right&quot;,&quot;bottom&quot;)) + tm_compass(type = &quot;4star&quot;, size = 2, show.labels = 2, position = c(&quot;right&quot;, &quot;top&quot;)) Scale bar width set to 0.25 of the map width Grille et graticules Fonctions tm_grid() et tm_borders() La fonction tm_grid() ajoute une grille à la carte selon le système de coordonnées projetées des données. Dans le cas présent, le shapefile Q est exprimé dans le système de coordonnées projetée Conique conforme de Lambert (epsg:32198) qui est métrique. La fonction tm_graticules ajoute les lignes de longitude et de latitude du système de coordonnées géographiques, c’est-à-dire non-projetées. Dans le cas présent, le shapefile Q est exprimé dans le système de coordonnées géographiques du Datum North Américain de 1983 (NAD83, espg:4269). Q1 &lt;- map_Q + tm_grid() Q2 &lt;- map_Q + tm_graticules() tmap_arrange(Q1,Q2) Plusieurs options d’arguments existent pour les fonctions tm_grid() et tm_graticules(). Par exemple, il est possible de préciser le nombre de divisions sur l’axe des x (n.x) et sur l’axe des y (n.y)35, l’épaisseur du trait (lwd), la couleur (col) ou encore la taille de l’écriture (labels.size). Q1 &lt;- map_Q + tm_grid(labels.size=0.5, col=&quot;yellow&quot;, lwd=3, n.x = 10, n.y = 4) Q2 &lt;- map_Q + tm_graticules(labels.col = &quot;darkblue&quot;, alpha = 0.3, labels.cardinal = FALSE) tmap_arrange(Q1,Q2) Attribuer les crédits ou la source des données Fonction tm_credits() Il faut utiliser la fonction tm_credits() pour ajouter à la carte une mention sur la source des données, ou toute autre information comme l’auteur ou l’autrice de la carte et son organisation d’attache. Par défaut, la mention apparaît dans le coin inférieur droit. map_Q + tm_credits(&quot;Données récupérées \\nsur le site donneesquebec.ca&quot;, size = 0.6) 6.1.6 Mise en page Fonction tm_layout() La fonction tm_layout permet d’ajuster la mise en page d’une carte et différents éléments de son esthétique. Pour découvrir l’ensemble des arguments possibles tapez la commande help(tm_layout) (ou ?tm_layout) dans votre console R. Plusieurs des arguments utiles sont présentés ci-dessous. Titre, cadre et couleur du fond L’ajout d’un titre (title), la taille de ce dernier (title.size) et sa position (title.position). La présence ou l’absence d’un cadre (frame) et l’épaisseur du trait de celui-ci (frame.lw). La taille des marges extérieures au cadre: outer.margins = c(Haut,Droit,Bas,Gauche) où Haut, Droit, Bas, Gauche sont des chiffres entre 0 (pas de marge) et 1 (marge complète). La couleur du fond de la carte (bg.color) et de l’espace à l’extérieure du cadre (outer.bg.color). Voici quelques exemples de mise en page qui utilisent ces arguments. # Création d&#39;une carte générale map_Q &lt;- tm_shape(Q) + tm_fill() + tm_borders() # Différentes options de mise en page map_Q + tm_layout(title = &quot;Carte du Québec&quot;, title.size =0.8, title.position = c(&quot;right&quot;,&quot;top&quot;)) map_Q + tm_layout(frame = FALSE) map_Q + tm_layout(bg.color = &quot;aquamarine&quot;, scale = 2) map_Q + tm_layout(frame.lwd = 2, outer.margins = c(0, 0.2,0, 0.2), outer.bg.color=&quot;lavender&quot;) Légende La fonction tm_layout() permet aussi de configurer l’apparence de la légende. Certains des arguments utiles sont: La présence, ou non, d’une légende (legend.show). Par défaut la légende est affichée. L’option de placer la légende à l’extérieur du cadre de la figure (legend.outside). La position de la légende à l’intérieur (legend.position) ou à l’extérieur (legend.outside.position) du cadre. Par défaut,la légende est placée dans le coin où il y a le plus d’espace. L’option de mettre un cadre autour de la légende (legend.frame) et de définir l’épaisseur du trait (legend.frame.lwd) et la couleur de fond de la légende (legend.bg.color) La police de caractère (legend.title.fontfamily), la taille des caractères (legend.title.fontface), et la couleur (legend.title.color) du texte et du titre de la légende. Voici quelques exemples de mise en page de la légende: tm_shape(Q) + tm_polygons(col = &quot;NOM_REG&quot;) + tm_layout(legend.show = FALSE) tm_shape(Q) + tm_polygons(col = &quot;NUM_REG&quot;, title = &quot;Régions administratives&quot;, legend.is.portrait = FALSE) + tm_layout(frame = FALSE, legend.outside = TRUE, legend.outside.position = &quot;bottom&quot;, legend.outside.size = 0.15, legend.text.size = 0.75) tm_shape(Q) + tm_fill(col = &quot;NOM_REG&quot;, title = &quot;Régions administratives&quot;) + tm_layout(legend.outside = TRUE) tm_shape(Q) + tm_fill(col=&quot;NOM_REG&quot;, title = &quot;Régions administratives&quot;) + tm_layout(bg.color = &quot;black&quot;, frame = FALSE, legend.outside = TRUE, legend.outside.position = &quot;left&quot;, legend.title.fontfamily = &quot;serif&quot;, legend.title.fontface = 2, legend.title.color = &quot;lightpink&quot;, legend.text.color = &quot;white&quot;) Ajustement des couleurs De plus, la fonction tm_layout permet d’ajuster les couleurs présentes dans la carte: L’argument aes.color défini la couleur de remplissage des polygones, des frontières, du texte, etc. L’argument saturation défini le niveau de saturation des couleurs. La valeur par défaut est 1, et la valeur 0 donne une représentation en noir et blanc. Il est possible de donner des valeurs supérieures à 1 pour des couleurs très saturées. Il est aussi possible de données des valeurs négatives. L’argument sepia.intensity est un nombre entre 0 et 1 qui défini le niveau de “chaleur” des couleurs. Plus sa valeur est grande, plus les couleurs ont une teinte jaune voir brune. La valeur par défaut est 0. L’argument aes.palette permet de changer la palette de couleurs utilisées. La librarie tmap utilise les palettes de couleurs de Color Brewer. Dans le cas d’attributs catégoriques (comme le nom de régions) la palette utilisée par défaut se nomme Set3, mais il est possible de choisir d’autres palettes parmi celles-ci: Accent, Dark2, Paired, Pastel1, Pastel2, Set1, et Set2. Nous reviendrons sur le sujet des palettes un peu plus loin dans cete leçon. Voici quelques exemples de modification des couleurs: Q1 &lt;- tm_shape(Q) + tm_polygons() + tm_layout(aes.color = c(fill=&quot;lightblue&quot;,borders=&quot;darkgreen&quot;)) Q2 &lt;- tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_layout(legend.show = FALSE, aes.color = c(borders=&quot;white&quot;), saturation = 0) Q3 &lt;- tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_layout(legend.show = FALSE, sepia.intensity = 0.5) Q4 &lt;- tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_layout(legend.show = FALSE, aes.palette = list(cat = &quot;Accent&quot;)) Styles prédéfinis Fonction tm_style() La librarie tmap contient des styles prédéfinis qu’on appelle avec la fonction tm_style et qui permettent de ne pas avoir à définir individuellement des arguments de la fonction tm_layout. Voici quelques uns de ces styles prédéfinis. tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_style(&quot;classic&quot;) + tm_layout(legend.show = FALSE) tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_style(&quot;bw&quot;) + tm_layout(legend.show = FALSE) tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_style(&quot;cobalt&quot;) + tm_layout(legend.show = FALSE) tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_style(&quot;col_blind&quot;) + tm_layout(legend.show = FALSE) Vous remarquerez que le style col_blind utilise une palette de couleur permettant aux personnes daltoniennes de pouvoir différencier les polygones de couleurs différentes. 6.1.7 Écriture sur une carte Fonction tm_text() La fonction tm_text() permet d’écrire sur chaque polygone la valeur d’un de ses attributs. Par exemple, nous pouvons ajouter le numéro de la région administrative sur chaque polygone: tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_style(&quot;col_blind&quot;) + tm_layout(legend.show = FALSE, frame = FALSE)+ tm_text(&quot;NUM_REG&quot;, size = 0.6, fontface=&quot;bold&quot;) Ou encore: tm_shape(Q) + tm_polygons() + tm_layout(aes.color = c(fill=&quot;black&quot;,borders=&quot;white&quot;), bg.color = &quot;black&quot;, frame = FALSE, legend.bg.color = TRUE, legend.outside = TRUE, legend.text.size = 0.8, legend.text.color = &quot;white&quot;, legend.title.color = &quot;white&quot;) + tm_text(&quot;NUM_REG&quot;, col= &quot;NOM_REG&quot;, palette = &quot;Paired&quot;, size = 0.8, fontface=&quot;bold&quot;, legend.col.show = TRUE, title.col = &quot;Régions administratives&quot;, auto.placement=TRUE, just=&quot;right&quot;) 6.1.8 Les lignes Données sur le réseau routier du Québec Pour explorer les options d’affichage de données vectorielles de types ligne et multiligne, nous utilisons le shapefile du réseau des routes du Québec. Chargeons ces données dans notre session de travail R avec la fonction st_read(): Ro &lt;- st_read(&quot;Module6/Module6_donnees/Routes/QC_routes.shp&quot;) Reading layer `QC_routes&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module6/Module6_donnees/Routes/QC_routes.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 223 features and 2 fields Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: -822900 ymin: 118000 xmax: 526000 ymax: 983200 Projected CRS: NAD83 / Quebec Lambert Observer la structure et les attributs du shapefile Ro. Celui-ci contient 223 multilignes et 2 attributs autres que la géométrie: NoRte: le numéro de la route, ClsRte: la classe de la route. En particulier, il existe trois classes possibles de route: Ro$ClsRte &lt;- as.factor(Ro$ClsRte) levels(Ro$ClsRte) [1] &quot;Autoroute&quot; &quot;Nationale&quot; &quot;Régionale&quot; Fonction tm_lines() La bibliothèque tmap possède une fonction particulière pour illustrer des objects vectoriels de type ligne et multigne. Il s’agit de la fonction tm_lines(). Celle-ci doit être ajouter à la fonction tm_shape(L) où L est un shapefile contenant des objets de géométrie ligne ou multiligne. Illustrons les multilignes du shapefile Ro: tm_shape(Ro) + tm_lines() Pour superposer la carte des routes sur la carte du Québec, nous utilisons la propriété additive des objets tmap. tm_shape(Q) + tm_fill() + tm_shape(Ro) + tm_lines(col=&quot;brown&quot;) + tm_layout(title = &quot;Réseau routier&quot;) Notez que chaque fois qu’on ajoute un nouvel ensemble de données à cartographier en utilisant tm_shape(nouvelles_donnees), les fonctions tm_fonctions() qui suivent s’appliquent à ces nouvelles données et non aux données antérieures. Pour représenter différemment les objets de type ligne en fonction de la valeur d’un de leur attribut, nous pouvons utiliser l’argument col dans la fonction tm_lines: # créons une palette de trois couleurs pal.col&lt;-c(&quot;red&quot;,&quot;darkgoldenrod4&quot;,&quot;darkslateblue&quot;) tm_shape(Q) + tm_fill() + tm_shape(Ro) + tm_lines(col = &quot;ClsRte&quot;, palette = pal.col, title.col = &quot;Types de route&quot;) 6.1.9 Les points Coordonnées des municipalités du Québec Pour explorer les options d’affichage de données vectorielles de types point et multipoint, nous utilisons le shapefile des coordonnées géographiques de quelques municipalités du Québec. Chargeons ces données dans notre session de travail R avec la fonction st_read(): V &lt;- st_read(&quot;Module6/Module6_donnees/Villes/QC_coord_municipalites.shp&quot;) Reading layer `QC_coord_municipalites&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module6/Module6_donnees/Villes/QC_coord_municipalites.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 15 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -78.91 ymin: 45.41 xmax: -64.47 ymax: 62.41 Geodetic CRS: NAD83 Ce shapefile compte 15 objets de type point et un seul attribut (Mncplts) correspondant au nom de la municipalité qui lui est associée. La bibliothèque tmap comprend plusieurs fonctions permettant de représenter des données de type point. Familiarisons-nous d’abord avec les fonctions tm_dots() et tm_markers(). Nous verrons plus loin les fonctions tm_bubbles() et tm_symbols(). Fonction tm_dots() La fonction tm_dots() fonctionne de façon similaire aux fonctions tm_polygons() et tm_lines(). Il suffit de l’ajouté à la fonction tm_shape(P) où P est un shapefile de types point ou multipoint. # Juste les points Q1 &lt;- tm_shape(V) + tm_dots() # Les points et la carte du QC Q2 &lt;- tm_shape(Q) + tm_fill(col = &quot;blue&quot;, alpha = 0.4) + tm_shape(V) + tm_dots(col = &quot;darkblue&quot;, size = 1) # tmap_arrange(Q1,Q2) Nous pouvons également définir la couleur des points en fonction de la valeur de leur attribut. tm_shape(Q) + tm_fill() + tm_shape(V) + tm_dots(col = &quot;Mncplts&quot;, palette = &quot;Paired&quot;, size = 1) + tm_layout(frame = FALSE, legend.outside = TRUE, title = &quot;Municipalités&quot;, legend.title.color = NA, legend.text.size = 0.8) Fonction tm_markers() La fonction tm_markers() représente les points par le symbole de repère géographique: tm_shape(Q) + tm_fill() + tm_shape(V) + tm_markers(size = 0.5, text = &quot;Mncplts&quot;, text.size = 0.8, text.just = &quot;top&quot;) + tm_layout(inner.margins = c(0.1,0.2,0.1,0.2)) La fonction tm_markers() permet d’ajouter du texte facilement sur les repères et contient des arguments similaires à la fonction tm_text(). 6.1.10 Données matricielles Données d’élévation du Québec Pour explorer les options d’affichage de données matricielles, nous utilisons un raster représentant le relief du territoire québecois sous forme d’une matrice d’élévation. Chargeons ces données dans notre session de travail R avec la fonction raster(). Nous devons prélablement charger la bibliothèque raster: library(raster) E &lt;- raster(&quot;Module6/Module6_donnees/Elevation/QC_Elevation.tif&quot;) Le raster E est une matrice de 810612 cellules, et chacune de ces cellules a une résolution d’environ 2 km par 2 km. La valeur maximale d’élévation est de 1592 m. Fonction tm_raster() La fonction tm_raster() de la bibliothèque tmap permet de visualiser les rasters en assignant des couleurs différentes pour des classes de valeurs différentes. L’argument n sert à préciser le nombre approximatif de classes à utiliser. tm_shape(E) + tm_raster(title = &quot;Élévation (m)&quot;) tm_shape(E) + tm_raster(n = 10, title = &quot;Élévation (m)&quot;) Il est possible d’afficher en légende un histogramme illustrant la distribution des valeurs. Par exemple: tm_shape(E) + tm_raster(n = 10, title = &quot;Élévation (m)&quot;, legend.hist = TRUE) + tm_legend(outside = TRUE, hist.width = 4) Par défaut, la palette de couleur utilisée est la palette séquentielle YlOrBr de ColorBrewer (de jaune à brun en passant par orange). Or, nous pouvons changer la palette de couleur. Utilisons, par exemple, la fonction colorRampPalette() pour créer notre propre palette de couleur. pal.elevation = colorRampPalette( c(&quot;midnightblue&quot;,&quot;forestgreen&quot;, &quot;darkolivegreen4&quot;,&quot;burlywood&quot;, &quot;chocolate4&quot;)) tm_shape(E) + tm_raster(n = 10, title = &quot;Élévation&quot;, palette = pal.elevation(10), legend.hist = TRUE, colorNA = &quot;beige&quot; ) + tm_legend(outside = TRUE, hist.width = 3) Il existe différentes façons de former des classes de valeur à partir de la distribution. L’argument style de la fonction tm_raster() permet de choisir une méthode parmi plusieurs dont les suivantes: \"fixed\": crée des classes de valeurs selon notre propre choix. Ces classes doivent être définies dans un vecteur assigné à l’argument breaks. \"equal\": divise les valeurs en n classes. Ceci est la méthode par défaut. \"pretty\": choisi automatiquement le nombre de classes qui permet de distinguer les valeurs dans un rendu esthétique. \"quantile\": divise les valeurs en quantiles. \"jenks\": utilise l’algorithme de Jenks pour déterminer le nombre optimal de classes. Visualisons à nouveau la carte des données d’élévation en utilisant un style “fixed” et un style “quantile”: # définir la mise en page pour les deux cartes format_carte &lt;- tm_layout(frame = FALSE, legend.position = c(0.67,0.04), legend.title.size = 0.8, legend.format=c(text.align=&quot;right&quot;), legend.bg.color = &quot;white&quot;, legend.frame = &quot;black&quot;) # style fixed. Efixed &lt;- tm_shape(E) + tm_raster(title = &quot;Élévation(m)&quot;, palette = pal.elevation(10), style = &quot;fixed&quot;, breaks = c(0,100,200,300,400,500,600,700,800,900,1000,1600)) + format_carte # style quantile Equant &lt;- tm_shape(E) + tm_raster(title = &quot;Élévation(m)&quot;, palette=pal.elevation(10), style=&quot;quantile&quot;) + format_carte tmap_arrange(Efixed,Equant) 6.1.11 Carte avec symboles proportionnels Dans des cartes thématiques, il est souvent utile de représentées certains attributs par des symboles proportionnels. Les fonctions tm_symbols() et tm_bubbles() de la bibliothèque tmap sont utiles pour réaliser ce type de cartes. Fonction tm_symbols() La fonction tm_symbols() est similaire à la fonction tm_dots() mais ne s’utilise pas nécessairement avec des données vectorielles de type points. En particulier, elle permet de représenter la valeur d’attribut d’un polygone en affichant un symbole dont la taille ou la couleur est proportionnelle à cette valeur. En guise d’exemple, reprenons les données sur les régions administratives du Québec pour lesquelles nous connaissons la taille de la population. Nous pouvons illustrer les régions par un cercle dont le diamètre est proportionnel à la taille de sa population. Il s’agit d’attribuer à l’argument size, le nom de l’attribut que nous souhaitons représenter. tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;, legend.show = FALSE) + tm_style(&quot;bw&quot;) + tm_symbols(col = &quot;black&quot;, size = &quot;Pop_tot&quot;, legend.size.show = TRUE, legend.size.is.portrait = TRUE, title.size = &quot;Population&quot;) Par défaut, le symbole utilisé est un point. Le point correspond au symbole shape = 21. Nous pouvons toutefois utiliser d’autres symboles comme le carré (shape = 15), ou le repère géographique (shape = marker_icon()). Vous pouvez même importer vos propres symboles. carte_base &lt;- tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;, legend.show = FALSE) + tm_style(&quot;bw&quot;) carte_carre &lt;- carte_base + tm_symbols(shape = 15, col = &quot;red&quot;, size = &quot;Pop_tot&quot;, legend.size.show = TRUE, legend.size.is.portrait = TRUE, title.size = &quot;Population&quot;) carte_marqueur &lt;- carte_base + tm_symbols(shape = marker_icon(), border.col = NULL, size = &quot;Pop_tot&quot;, legend.size.show = TRUE, legend.size.is.portrait = TRUE, title.size = &quot;Population&quot;) tmap_arrange(carte_carre, carte_marqueur) Représenter deux légendes Lorsque nous utilisons des symboles proportionnels, nous devons souvent avoir plus d’une légende. Par exemple, dans les cartes précédentes, nous avions seulement une légende se rapportant à la taille des populations mais aucune légende pour identifier les régions. Pour ajouter deux légendes (ou plus), nous devons utiliser la fonction tm_layout() avec l’argument legend.stack qui précise si les légendes seront disposées de façon verticale ou horizontale. tm_shape(Q) + tm_polygons(col=&quot;NOM_REG&quot;, palette=&quot;Set1&quot;, border.col = &quot;darkgrey&quot;, title =&quot;Régions administratives&quot;) + tm_symbols(size = &quot;Pop_tot&quot;, border.col = &quot;grey&quot;, col=&quot;black&quot;, scale = 2, legend.size.show = TRUE, legend.size.is.portrait = FALSE, sizes.legend.labels = c(&quot;500&quot;,&quot;1000&quot;,&quot;1500&quot;,&quot;2000&quot;,&quot;2500&quot;), title.size =&quot;Population (en milliers)&quot;) + tm_layout(frame = FALSE, legend.outside = TRUE, legend.stack = &quot;vertical&quot;, legend.title.fontface = &quot;bold&quot; ) Fonction tm_bubbles() La fonction tm_bubbles() est similaire à la fonction tm_symbols() et s’utilise lorsqu’on souhaite seulement représenter des symboles sous forme de cercle/point. Cette fonction est pratique lorsque nous voulons représenter deux attributs avec un symbole: le premier attribut est représenté par la taille du cercle et le second attribut par sa couleur. Utilisons à nouveau les données sur la taille des populations des régions administratives. Par exemple, représentons chaque région par un cercle dont le diamètre est proportionnel à la taille totale de sa population (comme nous l’avons fait plus haut). De plus, colorons chaque cercle en fonction de la proportion d’enfants (individus agés entre 0 et 14 ans) dans sa population. Tout d’abord, nous devons calculer la proportion d’enfants dans chaque région. Pour le moment, nous connaissons seulement le nombre d’enfants (A0.14_T). Créons un nouvel attribut pour le shapefile Q: Q$Pop_prop_enfant &lt;- Q$Pop_0_14/Q$Pop_tot Utilisons maintenant la fonction tm_bubbles() en définissant l’argument size par l’attribut \"ATot_T\", et l’argument col par l’attribut \"Pop_prop_enfant\": tm_shape(Q) + tm_polygons(col = &quot;NUM_REG&quot;, legend.show = FALSE, palette = &quot;Greys&quot;) + tm_bubbles(size = &quot;Pop_tot&quot; , col = &quot;Pop_prop_enfant&quot;, style = &quot;quantile&quot;, scale = 2, border.col = &quot;black&quot;, border.lwd = .5, legend.size.show = TRUE, legend.size.is.portrait = FALSE, title.size =&quot;Population (en milliers)&quot;, title.col = &quot;Proportion d&#39;enfants (0-14 ans)&quot;, sizes.legend.labels = c(&quot;500&quot;,&quot;1000&quot;,&quot;1500&quot;,&quot;2000&quot;,&quot;2500&quot;))+ tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 1) L’argument style est utilisé pour définir les classes de couleurs. Ici, nous avons choisi une classification en quantile. Noter que nous pouvons définir un titre pour la légende des tailles (title.size) et un titre pour la légende des couleurs (title.col). Remarquer que cette figure nous permet d’observer que la proportion d’enfants au Nunavik est très grande malgré que la taille de la population soit petite. 6.1.12 Cartes Choroplèthes Les cartes choroplèthes sont utilisées pour représenter des données vectorielles de type polygone en assignant une couleur à chaque polygone en fonction de la valeur d’un de ces attributs. Pour créer des cartes choroplèthes, nous utilisons l’argument col de la fonction tm_polygons(). L’assignation des couleurs se fait de la même façon que pour tm_raster() et tm_bubbles() en définissant des classes de valeur d’attribut. Créons des cartes choroplèthes de la proportion d’enfants dans les régions administratives en utilisant différentes classifications de couleurs. # Par defaut, nous avons 4 classes Qdefaut &lt;- tm_shape(Q) + tm_polygons(col = &quot;Pop_prop_enfant&quot;) # style fixed. Qfixed &lt;- tm_shape(Q) + tm_polygons(col = &quot;Pop_prop_enfant&quot;, style = &quot;fixed&quot;, breaks = c(0.1, 0.14, 0.15, 0.16, 0.18, 0.3)) # style quantile Qquant = tm_shape(Q) + tm_polygons(col = &quot;Pop_prop_enfant&quot;, style = &quot;quantile&quot;) tmap_arrange(Qdefaut,Qfixed,Qquant) Legend labels were too wide. The labels have been resized to 0.6, 0.6, 0.6, 0.6, 0.6. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger. 6.1.13 Cartes à panneaux multiples Fonction tm_facets() Il est parfois utile illustrer des polygones côte-à-côte afin de faciliter la comparaison d’un de leurs attributs. On appelle les cartes des polygones individuellement représentés des panneaux. Pour créer une carte à panneaux multiples, nous utilisons d’abord la fonction tm_polygons() pour représenter chaque polygone selon la méthode de notre choix (par exemple selon une représentation choroplèthe d’un des attributs). Ensuite, nous ajoutons la fonction tm_facets() pour préciser la disposition des panneaux (arguments nrow ou ncol) ainsi que l’attribut utilisé (la facette) pour distinguer chaque panneau (argument by). Représentons à nouveau les polygones des régions administratives selon la proportion d’enfants dans leur population mais cette fois en créant une carte à panneaux multiples: tm_shape(Q) + tm_polygons(col = &quot;Pop_prop_enfant&quot;, style = &quot;quantile&quot;) + tm_facets(by = &quot;NOM_REG&quot;, nrow = 5, scale.factor = 5) + tm_layout(panel.label.height = 2, panel.label.size = 0.9, legend.show = FALSE) L’argument scale.factor détermine la mise à l’échelle du texte par rapport à la mise à l’échelle des polygones. Les polygones ont été réduits de taille pour entrer dans leur panneau, toutefois nous souhaitons que le titre apparaissant dans la partie supérieure du panneau ne soit pas réduit autant. Il est possible de modifier la police du texte, sa couleur, la couleur de fond des panneaux, le cadre des panneaux, et plus, en utilisant les arguments de la fonction tm_layout(). 6.1.14 Cartes avec encadré Il est parfois nécessaire d’accompagner une carte par une autre carte de taille moindre circonscrite dans un encadré sur ou en marge de la carte principale. Ceci est le cas, par exemple, lorsque nous souhaitons préciser la localisation de la carte principale dans une région plus grande. Bibliothèque grid Pour réaliser une carte avec un encadré, nous devons utiliser la bibliothèque grid. Commençons par installer cette bibliothèque: install.packages(&quot;grid&quot;) En guise d’exemple, considérons une section du raster d’élévation E correspondant à la région de l’Outaouais. Vous n’avez pas besoin de comprendre les opérations ci-dessous car nous les apprendrons dans les modules 7 et 8. # Isoler le polygone de l&#39;Outaouais Q_Outaouais &lt;- subset(Q, NOM_REG == &quot;Outaouais&quot;) # Découper le raster E selon l&#39;étendue de Q_Outaouais E_Outaouais &lt;- crop(E, extent(Q_Outaouais)) # Créer un mask E_Outaouais &lt;- mask(E_Outaouais, Q_Outaouais) Créons d’abord une carte des données d’élévation pour la région de l’Outaouais. Cette carte consituera notre carte principale. # Définir la carte principale carte_princ &lt;- tm_shape(E_Outaouais) + tm_raster(title = &quot;Élévation (m)&quot;, palette = pal.elevation(5)) + tm_scale_bar(position = c(&quot;left&quot;,&quot;bottom&quot;), text.size = 0.6) # Mise en page de la carte format_carte &lt;- tm_layout(frame = FALSE, legend.outside = TRUE, legend.outside.position = &quot;right&quot;, legend.title.size = 0.8, legend.bg.color = &quot;white&quot;, legend.frame = &quot;black&quot;) Créons maintenant une carte du Québec qui délimite la région de l’Outaouais par des frontières de couleur rouge. Cette carte sera l’encadré à insérer sur la carte principale. # Définir la carte encadré carte_cadre &lt;- tm_shape(Q) + tm_borders(col = &quot;black&quot;) + tm_shape(Q_Outaouais) + tm_borders(lw=2, col=&quot;red&quot;) Nous pouvons enfin combiner les deux cartes ensembles. Il s’agit d’afficher la carte principale et d’ajouter la carte encadré en utilisant la fonction print(). En particulier, nous utilisons la fonction viewport() de la bibliothèque grid qui permet de définir la position de la carte encadré sur la carte ainsi que sa taille. library(grid) carte_princ + format_carte print(carte_cadre, vp = viewport(0.72, 0.42, width = 0.4, height = 0.4)) Les chiffres (0.72,0.42) correspondent aux coordonnées (x,y) de la position de la carte encadrée sur la carte principale (où (0,0) est le coin inférieur gauche de la carte principale, et (1,1) est le coin supérieur droit). Les arguments width et height sont des nombres entre 0 et 1. Ceux-ci correspondent au facteur par lequel nous souhaitons réduire la largeur et la hauteur de la carte encadrée. Consulter ce site pour en apprendre davantage sur la cartographie avec ggplot2↩︎ Noter que le nombre de divisions créé par tmap est approximativement celui demandé car tmap crée des divisions uniformément espacées situées sur des coordonnées de valeurs entières.↩︎ "],["exercices.html", "6.2 Exercices", " 6.2 Exercices À venir! "],["manip_vec.html", "Module 7 Manipulation de données vectorielles", " Module 7 Manipulation de données vectorielles L’objectif principal de ce module est d’apprendre à manipuler des données vectorielles. À la fin de ce module vous saurez: Ajouter de nouveaux attributs à des données vectorielles, et également supprimer ou éditer des attributs. Filtrer des données vectorielles en se basant sur leurs attributs. Joindre spatialement deux ensembles de données vectorielles. Extraire un sous-ensemble de données pour l’intégrer aux attributs d’un second ensemble de données spatiales. Combiner, aggréger et simplifier des objets vectoriels. Transformer la géométrie d’objets vectoriels. Créer des zones tampons autour d’objets vectoriels. Trouver le centroid et les coordonnées d’objets vectoriels. Faire des opérations topologiques sur des objets vectoriels (union, intersection, différence) Confirmer des relations topologiques entre deux objets vectoriels. Calculer des mesures spatiales sur des objets vectoriels (distance, longueur, superficie). Vous utiliserez les bibliothèques suivantes: sf mapview units Vous apprendrez à utiliser les fonctions suivantes: subset() st_coordinates() class() merge() st_join() st_simplify() st_area() set_units() st_buffer() st_intercepts() rowSums() lengths() st_is_longlat() Vous utiliserez les données suivantes: Dans la section leçon, vous utiliserez des données vectorielles portant sur les municipalités du Québec, sur les régions administratives du Québec et sur les parcs nationaux de la Société des établissements de plein air du Québec (SÉPAQ). Dans la section exercices, vous mettrez en pratique les manipulations vues dans la leçon en utilisant les mêmes données. "],["lecon_manip_vec.html", "7.1 Leçon", " 7.1 Leçon Au module 4, vous avez appris les fonctions essentielles pour lire et visualiser des données spatiales vectorielles sous R. Le présent module vous amènera maintenant à manipuler des données vectorielles. Dans un premier temps, cette leçon vous enseignera le fonctionnement d’opérations de base sur les données vectorielles. Ces opérations comprennent deux grandes catégories: les opérations qui portent sur les attributs des données vectorielles et les opérations qui portent sur la géométrie des données vectorielles. Les opérations réalisées sur les attributs des données vectorielles sont indépendantes de la composante spatiale des données, alors que les opérations spatiales prennent en considération la géométrie des données et peuvent même la transformer. Dans un second temps, cette leçon vous guidera dans la résolution d’une problèmatique qui nécessite de manipuler des données vectorielles. Au cours des différentes étapes permettant de résoudre la problématique, vous mettrez en pratique les diverses fonctions R apprises jusqu’à maintenant. Plus précisément, nous allons explorer le territoire Québécois en se posant la question suivante: Parmi les dix plus grandes villes du Québec, quelle est celle qui dispose du plus grand nombre de parcs nationaux dans un rayon de 70 km ? 7.1.1 Télécharger les données Les données Dans cette leçon, nous allons utiliser les données vectorielles relatives aux municipalités et aux régions administratives du Québec, ainsi qu’au réseau de la Société des établissements de plein air du Québec, la SÉPAQ. Afin de faciliter le téléchargement de ces données, l’ensemble de ces couches d’informations spatiales peuvent être téléchargées en cliquant sur un seul lien: données pour le module 7. Sauvegardez le dossier compressé (zip) dans votre répertoire de travail Module7_donnees pour ce module, et dézippez-le. Le dossier comprend trois sous-dossiers et un fichier .csv: villes, parcs.gdb, regions_admin, population.csv. 7.1.2 Opérations de base 7.1.2.1 Importer et visualiser les données Commençons par charger les bibliothèques requises pour lire les données spatiales vectorielles (sf) et les visualiser (mapview). library(sf) library(mapview) Maintenant, allons lire le fichier shapefile de l’ensemble des municipalités du Québec en utilisant la fonction st_read() tel que vu dans le module 4. municipalites &lt;- st_read(&quot;Module7/Module7_donnees/villes/villes.shp&quot;) Reading layer `villes&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module7/Module7_donnees/villes/villes.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 767 features and 17 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System Le shapefile a été importé dans un objet R de classe sf (c’est-à-dire un objet importé ou généré par l’utilisation de la bibliothèque sf). Nous remarquons que la géométrie de cet object vectoriel est de type point (POINT). Plus précisément, cet objet contient 767 points (features) et 17 attributs (fields). Pour en savoir davantage sur ces attributs de nature géographique, démographique et administrative, vous pouvez télécharger et consulter la [documentation] (https://www.donneesquebec.ca/recherche/fr/dataset/base-de-donnees-geographiques-et-administratives/resource/beb4472a-0edb-4824-b67e-40e20b425326) disponible sur le site de Données Québec. Nous pouvons maintenant visuellement valider que l’importation des données a bien été réussie en utilisant la fonction mapview() : mapview(municipalites, legend = FALSE) Dans le précédent module portant sur la cartographie, nous avons décrit plusieurs fonctionnalités de la bibliothèque tmap et avons démontré sa flexibilité et à sa capacité à produire des cartes de grande qualité. Toutefois, la bibliothèque mapview demeure fort utile lorsque nous souhaitons visualiser rapidement des données. Par défaut, la fonction mapview() affiche la carte d’OpenstreeMap en arrière-pan, ce qui permet de contextualiser facilement les données. De plus, les cartes produites avec mapview() sont interactives, permettant d’accéder directement à la table d’attributs des données vectorielles représentées. Par exemple, sur la carte ci-dessus, vous n’avez qu’à cliquer sur le marqueur géographique correspondant à chaque municipalité (point) ou à chaque parc (polygone) pour obtenir la liste des attributs et leur valeur. De plus, vous pouvez choisir d’afficher l’une ou l’autre des couches en cochant la couche désirée dans la fenêtre située dans le coin supérieur gauche. 7.1.2.2 Opérations sur les attributs des données vectorielles Les opérations sur les données vectorielles peuvent être séparées en deux grandes catégories. Les opérations qui portent sur les attributs des données et les opérations qui portent sur la géométrie des données. Les opérations réalisées sur les attributs des données vectorielles sont indépendantes de la composante spatiale des données. Ce sont des fonctions générales pour manipuler des bases de données et qui s’appliquent aux data.frame des données vectorielles. La présente section s’attarde à décrire certaines de ces fonctions. Filter des attributs Une opération fréquente lorsque nous manipulons des données vectorielles est celle de filtrer les données. Par exemple, dans le shapefile municipalites que nous venons d’importer, nous pourrions vouloir sélectionner seulement certaines municipalités parmi les 767 répertoriées ou certains attributs parmi les 17. Nous pourrions aussi vouloir déterminer quelles municipalités possédent une valeur spécifique pour un attribut donné. Dans les sous-sections qui suivent, nous présenterons des opérations qui permettent de filtrer les attributs de données vectorielles. Sélectionner des attributs à partir de leur indice Les objets sf sont manipulables de la même façon qu’un data.frame (étant eux-mêmes des data.frame). Les attributs correspondent aux colonnes tandis que les entités spatiales (points, lignes ou polygones) correspondent aux lignes du data.frame. Par exemple, l’objet spatial municipalites contient 767 points correspondant chacun à une municipalité. La table d’attributs contient quant à elle 18 colonnes correspondant à chacun des attributs permettant de décrire les municipalités. Pour sélectionner un élément spatial spécifique d’un shapefile, nous pouvons simplement spécifier l’indice de la ligne qui lui est associée dans le data.frame. Par exemple : municipalites[1, ] # Pour accéder à la première ligne. Simple feature collection with 1 feature and 17 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -57.13 ymin: 51.43 xmax: -57.13 ymax: 51.43 Geodetic CRS: Geographic Coordinate System LAYER AREA PERIMETER HABIT_P. 1 Unknown Point Feature 0 0 1 HABIT_P_ID HABIT_P_ HABIT_P_I1 HAP_CO_PRE 1 1 1 417 PRE HAP_NO_IND HAP_DE_IND HAP_CO_CLA HAP_CO_TOP 1 03 63 0000 001 Lieu habité TER 236021 HAP_NM_TOP HAP_DA_TOP HAP_CO_VER HAP_DA_MOD 1 Blanc-Sablon 20010115 BDGA1M v1.1 0 INT_AFF geometry 1 2M POINT (-57.13 51.43) Nous remarquons que le nombre de features (points) est maintenant de 1 (voir la première ligne de la sortie produite par R). En effet, puisque nous avons sélectionné le premier point de l’objet spatial municipalites nous avons exclu les 766 autres points. De la même manière, pour sélectionner un attribut spécifique, nous pouvons simplement spécifier l’indice de la colonne qui lui est associée : municipalites[, 2] # Pour accéder à la deuxième colonne. Simple feature collection with 767 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System First 10 features: AREA geometry 1 0 POINT (-57.13 51.43) 2 0 POINT (-57.2 51.41) 3 0 POINT (-76.25 51.69) 4 0 POINT (-78.75 51.49) 5 0 POINT (-58.65 51.23) 6 0 POINT (-59.62 50.47) 7 0 POINT (-73.87 50.41) 8 0 POINT (-60.67 50.22) 9 0 POINT (-62.81 50.29) 10 0 POINT (-64.33 50.29) Nous remarquons également que le nombre de fields (colonnes) à diminuer à 1. Sélectionner des attributs à partir de leur nom Il est également possible de sélectionner un attribut particulier en spécifiant son nom. Les colonnes disposent toujours d’un nom unique dans un data.frame. Nous pouvons afficher le nom des colonnes en utilisant la fonction names() : names(municipalites) [1] &quot;LAYER&quot; &quot;AREA&quot; &quot;PERIMETER&quot; [4] &quot;HABIT_P.&quot; &quot;HABIT_P_ID&quot; &quot;HABIT_P_&quot; [7] &quot;HABIT_P_I1&quot; &quot;HAP_CO_PRE&quot; &quot;HAP_NO_IND&quot; [10] &quot;HAP_DE_IND&quot; &quot;HAP_CO_CLA&quot; &quot;HAP_CO_TOP&quot; [13] &quot;HAP_NM_TOP&quot; &quot;HAP_DA_TOP&quot; &quot;HAP_CO_VER&quot; [16] &quot;HAP_DA_MOD&quot; &quot;INT_AFF&quot; &quot;geometry&quot; Cette table contient 17 attributs. L’attribut nommé HAP_NM_TOP réfère au nom des municipalités. Notez que l’abréviation TOP signifie toponyme. Pour sélectionner cet attribut nous pouvons le faire simplement en utilisant son nom. Par exemple, en utilisant la syntaxe suivante : municipalites[, &quot;HAP_NM_TOP&quot;] Simple feature collection with 767 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System First 10 features: HAP_NM_TOP geometry 1 Blanc-Sablon POINT (-57.13 51.43) 2 Lourdes-de-Blanc-Sablon POINT (-57.2 51.41) 3 Nemiscau POINT (-76.25 51.69) 4 Waskaganish POINT (-78.75 51.49) 5 Saint-Augustin POINT (-58.65 51.23) 6 Chevery POINT (-59.62 50.47) 7 Mistissini POINT (-73.87 50.41) 8 La Romaine POINT (-60.67 50.22) 9 Baie-Johan-Beetz POINT (-62.81 50.29) 10 Rivière-Saint-Jean POINT (-64.33 50.29) # Ce qui revient également au même que la syntaxe suivante municipalites[, 13] Simple feature collection with 767 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System First 10 features: HAP_NM_TOP geometry 1 Blanc-Sablon POINT (-57.13 51.43) 2 Lourdes-de-Blanc-Sablon POINT (-57.2 51.41) 3 Nemiscau POINT (-76.25 51.69) 4 Waskaganish POINT (-78.75 51.49) 5 Saint-Augustin POINT (-58.65 51.23) 6 Chevery POINT (-59.62 50.47) 7 Mistissini POINT (-73.87 50.41) 8 La Romaine POINT (-60.67 50.22) 9 Baie-Johan-Beetz POINT (-62.81 50.29) 10 Rivière-Saint-Jean POINT (-64.33 50.29) # Puisque cette colonne est en treizième position. Notez que la syntaxe familière municipalites$HAP_NM_TOP retourne un vecteur listant les valeurs de l’attribut HAP_NM_TOP, mais ne conserve pas la géométrie du shapefile: head(municipalites$HAP_NM_TOP) [1] &quot;Blanc-Sablon&quot; &quot;Lourdes-de-Blanc-Sablon&quot; [3] &quot;Nemiscau&quot; &quot;Waskaganish&quot; [5] &quot;Saint-Augustin&quot; &quot;Chevery&quot; Toutefois, la syntaxte précédente conserve la géométrie du shapefile et peut ainsi être utilisée pour définir un nouvel objet spatial. Par exemple, créons un nouveau shapefile qui contient seulement le nom des municipalités et leur position géographique : villes &lt;- municipalites[,&quot;HAP_NM_TOP&quot;] villes Simple feature collection with 767 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System First 10 features: HAP_NM_TOP geometry 1 Blanc-Sablon POINT (-57.13 51.43) 2 Lourdes-de-Blanc-Sablon POINT (-57.2 51.41) 3 Nemiscau POINT (-76.25 51.69) 4 Waskaganish POINT (-78.75 51.49) 5 Saint-Augustin POINT (-58.65 51.23) 6 Chevery POINT (-59.62 50.47) 7 Mistissini POINT (-73.87 50.41) 8 La Romaine POINT (-60.67 50.22) 9 Baie-Johan-Beetz POINT (-62.81 50.29) 10 Rivière-Saint-Jean POINT (-64.33 50.29) Profitons-en pour renommer l’attribut HAP_NM_TOP afin d’avoir un intitulé de colonne plus explicite : names(villes) &lt;- c(&quot;toponyme&quot;, &quot;geometry&quot;) names(villes) [1] &quot;toponyme&quot; &quot;geometry&quot; Filtrer des valeurs d’attribut On peut vouloir sélectionner un ou plusieurs éléments spatiaux d’un shapefile qui possèdent une valeur spécifique d’attribut. Cette opération peut être réalisée en utilisant les fonctions subset() ou which(). Fonction subset() La fonction subset() n’est pas spécifique aux données spatiales, c’est une fonction générale de R qui retourne le sous-ensemble d’un vecteur, d’une matrice or d’un tableau de données qui satisfait une condition donnée. Par exemple, nous pouvons utiliser la fonction subset() pour filtrer le jeu de données villes afin d’obtenir la localisation d’une municipalité précise: la_poc &lt;- subset(villes, toponyme == &quot;La Pocatière&quot;) mapview(la_poc, legend = FALSE) Notez que l’objet retourné, ici la_poc, est de même classe que l’objet filtré, ici villes. Nous pouvons valider la classe d’un objet dans R avec la fonction class(). class(la_poc) [1] &quot;sf&quot; &quot;data.frame&quot; Fonction which() La fonction which() est aussi une fonction générale de R. Elle identifie la position des éléments de valeur TRUE dans un vecteur logique. Par exemple: #Exemple 1 which(c(TRUE, FALSE, TRUE, FALSE, TRUE)) [1] 1 3 5 #Exemple 2 which(c(1, 1, 2) == 2) [1] 3 Maintenant, utilisons la fonction which() pour isoler la ville de La Pocatière: which(villes$toponyme == &quot;La Pocatière&quot;) [1] 128 Remarquez que la fonction which() retourne l’indice de la ligne dans la table d’attributs de l’objet villes satisfaisant la condition toponyme == \"La Pocatière\". Nous pouvons ensuite consigner cet identifiant dans l’objet id_la_poc et l’utiliser pour déterminer la localisation de la ville de La Pocatière: id_la_poc &lt;- which(villes$toponyme == &quot;La Pocatière&quot;) villes[id_la_poc,] Simple feature collection with 1 feature and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -70.04 ymin: 47.37 xmax: -70.04 ymax: 47.37 Geodetic CRS: Geographic Coordinate System toponyme geometry 128 La Pocatière POINT (-70.04 47.37) Ajouter des attributs Un autre type de manipulations fréquemment utilisé est celui d’enrichir un jeu de données vectorielles en lui ajoutant des attributs. Ces nouvelles informations peuvent provenir d’une base de données non-spatiales ou d’un autre shapefile. Dans le cas de données non-spatiales, nous pouvons combiner les attributs désirés en utilisant l’opération merge() que nous définissons dans cette sous-section. Lorsque nous souhaitons ajouter des attributs provenant de données spatiales, nous devons faire une jointure spatiale en utilisant l’opération st_join(). Nous définirons st_join() dans la section suivante portant sur les opérations spatiales sur les données vectorielles. La fonction merge() La fonction merge() est une fonction générale de R qui sert à combiner deux tableaux de données différents en se servant de rangées ou de colonnes communes. Par exemple, ajoutons à chacune des municipilatés contenues dans le shapefile villes la taille de sa population. Cette information est contenue dans un fichier csv (Module7_donnees/ville/population.csv) et provient du répertoire des municipalités du Québec. Nous allons d’abord importer ce fichier CSV dans R en utilisant la fonction read.csv(). Ensuite, nous sélectionnerons les colonnes pertinentes de ce tableau, et nous ajouterons ces informations aux attributs de l’objet spatial villes. pop &lt;- read.csv(&quot;Module7/Module7_donnees/villes/population.csv&quot;,encoding=&quot;UTF-8&quot;) Notez que la précision de l’encodage assure que les accents français sont bien importés lors de la lecture du document. L’objet pop est un data.frame de 114 colonnes décrivant un ensemble d’informations propres aux municipalités du Québec allant de leur nom jusqu’à la composition de leur conseil municipal. Toutes ces informations ne sont pas pertinentes pour le présent exercice. Pour faciliter la manipulation de ce tableau, sélectionnons seulement les colonnes suivantes: munnom: Nom de la ville. msuperf: Superficie de la municipalité. mpopul: Taille de la population de la municipalité. pop &lt;- pop[, c(&quot;munnom&quot;, &quot;msuperf&quot;, &quot;mpopul&quot;)] Le nouvel objet pop ainsi défini, contient seulement 3 colonnes. Nous voulons à présent fusionner l’objet pop avec l’objet spatial villes en utilisant la fonction merge(). Cette fusion entre les deux objets villes et pop sera réalisée sur les colonnes toponyme et munnom respectivement. Ces deux colonnes contiennent le nom des municipalités et agissent donc comme dénominateur commun entre les deux jeux de données. #villes_qc &lt;- merge(x = villes_qc, y = pop, by.x=&quot;toponyme&quot;, by.y=&quot;munnom&quot;, all.x = TRUE) villes_pop &lt;- merge(x = villes, y = pop, by.x=&quot;toponyme&quot;, by.y=&quot;munnom&quot;) villes_pop Simple feature collection with 485 features and 3 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -82.93 ymin: 42.31 xmax: -56.18 ymax: 62.42 Geodetic CRS: Geographic Coordinate System First 10 features: toponyme msuperf mpopul geometry 1 Acton Vale 91.1 7733 POINT (-72.56 45.65) 2 Aguanish 680.6 238 POINT (-62.08 50.22) 3 Akulivik 82.3 678 POINT (-78.2 60.81) 4 Albanel 205.0 2232 POINT (-72.44 48.88) 5 Alma 232.6 30831 POINT (-71.65 48.54) 6 Amherst 249.5 1459 POINT (-64.21 45.83) 7 Amos 437.2 12769 POINT (-78.12 48.57) 8 Amqui 128.3 6065 POINT (-67.43 48.46) 9 Armagh 170.6 1502 POINT (-70.59 46.74) 10 Asbestos 31.8 6837 POINT (-71.93 45.77) Le nouveau shapefile villes_pop contient les mêmes attributs que villes auxquels se sont ajoutés les attributs de pop. Remarquez que villes_pop contient moins d’éléments que villes. En effet, la fonction merge() n’a retenue que les villes qui étaient contenues à la fois dans le shapefile villes et dans la base de données pop. Pour conserver l’entièreté des éléments initialement présents dans villes, il faudrait ajouter l’argument all.x = TRUE à la fonction merge(). Dans ce cas, les villes dont la population n’est pas définie dans pop se verraient attribuer une valeur NA à l’attribut mpopul. Renommons les colonnes de villes_pop pour qu’elles portent un nom plus représentatif de leur contenu. names(villes_pop) [1] &quot;toponyme&quot; &quot;msuperf&quot; &quot;mpopul&quot; &quot;geometry&quot; names(villes_pop)[2:3] &lt;- c(&quot;superficie&quot;, &quot;population&quot;) names(villes_pop) [1] &quot;toponyme&quot; &quot;superficie&quot; &quot;population&quot; &quot;geometry&quot; 7.1.2.3 Opérations spatiales sur les données vectorielles Les opérations réalisées dans la section précédente sur les attributs des données vectorielles, telles merge(), which() et subset(), sont indépendantes de la composante spatiale des données. Si nous changions la géométrie des objets spatiaux décrits par les données vectorielles (par exemple en changeant les coordonnées des villes), ces opérations produiraient les mêmes résultats. Ce sont des fonctions générales pour manipuler des bases de données et qui s’appliquent aux data.frame des données vectorielles. Dans la présente section, nous verrons plutôt des opérations qui dépendent de la composante spatiale des données vectorielles. Ces opérations prennent en considération la géométrie des données et certaines peuvent aussi la transformer. Jointure spatiale Une opération de jointure permet de lier entre eux des éléments spatiaux sur la base d’une valeur d’attribut commune. La fonction st_join() La fonction st_join() de la bibliothèque sf permet de joindre à un shapefile de l’information provenant d’une autre couche spatiale. Cette opération constitue une jointure spatiale. Par exemple, importons le shapefile des régions administratives du Québec, disponible dans le dossier Module7_données, et réalisons une jointure entre cette couche et la couche villes. regions &lt;- st_read(&quot;Module7/Module7_donnees/regions_admin/regions_admin.shp&quot;) Reading layer `regions_admin&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module7/Module7_donnees/regions_admin/regions_admin.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 21 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System # on observe le contenu de ce shaphefile regions Simple feature collection with 21 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: Rgns_Ad 1 Côte-Nord 2 Côte-Nord 3 Côte-Nord 4 Saguenay - Lac-Saint-Jean 5 Gaspésie - Îles-de-la-Madeleine 6 Bas-Saint-Laurent 7 Abitibi-Témiscamingue 8 Mauricie 9 Capitale-Nationale 10 Outaouais geometry 1 POLYGON ((-66.69 55, -66.64... 2 POLYGON ((-66.26 55, -66.25... 3 POLYGON ((-67.22 55, -67 55... 4 POLYGON ((-72.07 47.95, -72... 5 POLYGON ((-67.15 49.19, -67... 6 POLYGON ((-67.15 49.19, -66... 7 POLYGON ((-75.52 47.85, -75... 8 POLYGON ((-74.47 48.95, -74... 9 POLYGON ((-72.07 47.95, -72... 10 POLYGON ((-75.52 47.85, -75... # on le visualise mapview(regions) Notez que les éléments de regions sont des polygones. Ces polygones possèdent un seul attribut, \"Rgns_Ad\", correspondant au nom des régions administratives que ceux-ci délimitent. Nous allons maintenant faire une jointure spatiale entre villes et regions afin d’associer à chaque municipalité sa région administrative d’attache. villes_reg = st_join(villes, regions[ ,&quot;Rgns_Ad&quot;]) villes_reg Simple feature collection with 767 features and 2 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System First 10 features: toponyme Rgns_Ad 1 Blanc-Sablon Côte-Nord 2 Lourdes-de-Blanc-Sablon Côte-Nord 3 Nemiscau Nord-du-Québec 4 Waskaganish Nord-du-Québec 5 Saint-Augustin Côte-Nord 6 Chevery Côte-Nord 7 Mistissini Nord-du-Québec 8 La Romaine Côte-Nord 9 Baie-Johan-Beetz Côte-Nord 10 Rivière-Saint-Jean Côte-Nord geometry 1 POINT (-57.13 51.43) 2 POINT (-57.2 51.41) 3 POINT (-76.25 51.69) 4 POINT (-78.75 51.49) 5 POINT (-58.65 51.23) 6 POINT (-59.62 50.47) 7 POINT (-73.87 50.41) 8 POINT (-60.67 50.22) 9 POINT (-62.81 50.29) 10 POINT (-64.33 50.29) Remarquez que l’objet villes_reg est identique à l’objet villes mais contient un attribut supplémentaire: la colonne Rgns_Ad. Il est important de préciser que la fonction st_join() nécessite que les deux couches spatiales à joindre utilisent le même système de coordonnées de référence (SCR). Contrairement à la fonction merge() vue plus haut, la fonction st_join() est bien une opération spatiale. En effet, st_join(x,y) détermine s’il y a une intersection spatiale entre chaque élément de l’objet de gauche (x = villes) et l’un ou l’autre des éléments de l’objet de droite (y = regions). Une intersection entre deux éléments spatiaux se produit lorsqu’ils partagent une même portion de l’espace. Ainsi, il y a une intersection entre le point associé à la ville de Shawinigan et le polygone associé à la région de la Mauricie. Par ailleurs, il n’y a pas d’intersection entre le point associé à la ville de Sherbrooke et le polygone de la Mauricie. Lorsque st_join(x,y) identifie la présence d’une intersection entre deux éléments, elle assigne à l’élément de gauche la valeur de l’attribut (ici \"Rgns_Ad\") de l’élément de droite. Lorsqu’il n’y a pas d’intersection entre deux éléments, la fonction assigne une valeur d’attribut NA à l’élément de gauche. Par exemple, les données villes contiennent des municipalités qui ne sont pas situées au Québec. On retrouve entre autres la ville d’Albany dans l’état de New York aux États-Unis. Ainsi aucune région n’a pu être associée à ces villes. villes_reg[692,] Simple feature collection with 1 feature and 2 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -73.77 ymin: 42.66 xmax: -73.77 ymax: 42.66 Geodetic CRS: Geographic Coordinate System toponyme Rgns_Ad geometry 692 Albany &lt;NA&gt; POINT (-73.77 42.66) Si nous souhaitons que la fonction st_join(x,y) conserve seulement les éléments de x qui intersectent un ou l’autre des éléments de y, nous devons ajouter l’argument left = FALSE : villes_reg &lt;- st_join(villes, regions[ ,&quot;Rgns_Ad&quot;], left = FALSE) Visualisons le nouveau shapefile que nous venons de créer. Ce dernier contient seulement les municipalités à l’intérieur du territoire québécois. mapview(villes_reg, legend = FALSE) Notez que lorsque vous cliquez sur les points de la carte, la valeur de l’attribut “Rngs_Ad” est maintenant également donnée. Vous pouvez ainsi différencier visuellement les municipalités selon leur région administrative d’attache. mapview(villes_reg, zcol = &quot;Rgns_Ad&quot;, legend = FALSE) Que se produit-il si nous inversons les arguments villes et regions dans la fonction st-join()  ? Dans ce cas, la jointure spatiale associe à chaque région les villes qui sont situées (c’est-à-dire intersectent) son territoire. Observons le résultat d’une telle jointure : reg_villes &lt;- st_join(regions, villes[,&quot;toponyme&quot;], left = FALSE) reg_villes Simple feature collection with 620 features and 2 fields Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -57.11 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: Rgns_Ad toponyme 3 Côte-Nord Kawawachikamach 3.1 Côte-Nord Matimekosh 3.2 Côte-Nord Schefferville 4 Saguenay - Lac-Saint-Jean Girardville 4.1 Saguenay - Lac-Saint-Jean Albanel 4.2 Saguenay - Lac-Saint-Jean Mistassini 4.3 Saguenay - Lac-Saint-Jean Dolbeau 4.4 Saguenay - Lac-Saint-Jean Normandin 4.5 Saguenay - Lac-Saint-Jean Sainte-Monique 4.6 Saguenay - Lac-Saint-Jean La Doré geometry 3 POLYGON ((-67.22 55, -67 55... 3.1 POLYGON ((-67.22 55, -67 55... 3.2 POLYGON ((-67.22 55, -67 55... 4 POLYGON ((-72.07 47.95, -72... 4.1 POLYGON ((-72.07 47.95, -72... 4.2 POLYGON ((-72.07 47.95, -72... 4.3 POLYGON ((-72.07 47.95, -72... 4.4 POLYGON ((-72.07 47.95, -72... 4.5 POLYGON ((-72.07 47.95, -72... 4.6 POLYGON ((-72.07 47.95, -72... Le shapefile reg_villes est constitué des polygones de regions. Puisque plusieurs municipalités intersectent chaque région, le polygone d’une région donnée est dupliqué pour chacun des points. C’est-à-dire qu’une nouvelle ligne est ajoutée pour chacune des intersections identifiées. Remarquez que nous pouvons aussi utiliser la fonction join_st() en vue de créer un filtre spatial, par exemple avec la fonction subset()  : villes_CN&lt;- subset(villes_reg, Rgns_Ad==&quot;Côte-Nord&quot;) mapview(villes_CN, legend = FALSE) Cette opération nous a permis de filtrer les municipalités du Québec pour retenir seulement celles situées dans la région administrative de la Côte-Nord. Opérations géométriques Les opérations géométriques sur les données vectorielles sont des opérations qui peuvent changer la géométrie des données ou qui peuvent créer, à partir de celles-ci, des nouveaux objets vectoriels de géométrie différente. La fonction aggregate() La fonction aggregate() de la bibliothèque sf permet d’agréger (c’est-à-dire de grouper) des éléments spatiaux d’une même couche de données vectorielles. Afin de démontrer comment opère la fonction aggregate() considérons d’abord l’objet villes_reg_pop. Ce dernier est formé par la jointure spatiale entre villes_pop, le shapefile associant à chaque municipalité la taille de sa population, et regions : villes_reg_pop &lt;- st_join(villes_pop, regions[ ,&quot;Rgns_Ad&quot;], left = FALSE) villes_reg_pop Simple feature collection with 477 features and 4 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -79.5 ymin: 45.05 xmax: -57.13 ymax: 62.42 Geodetic CRS: Geographic Coordinate System First 10 features: toponyme superficie population 1 Acton Vale 91.1 7733 2 Aguanish 680.6 238 3 Akulivik 82.3 678 4 Albanel 205.0 2232 5 Alma 232.6 30831 7 Amos 437.2 12769 8 Amqui 128.3 6065 9 Armagh 170.6 1502 10 Asbestos 31.8 6837 11 Aupaluk 32.7 224 Rgns_Ad geometry 1 Montérégie POINT (-72.56 45.65) 2 Côte-Nord POINT (-62.08 50.22) 3 Nord-du-Québec POINT (-78.2 60.81) 4 Saguenay - Lac-Saint-Jean POINT (-72.44 48.88) 5 Saguenay - Lac-Saint-Jean POINT (-71.65 48.54) 7 Abitibi-Témiscamingue POINT (-78.12 48.57) 8 Bas-Saint-Laurent POINT (-67.43 48.46) 9 Chaudière-Appalaches POINT (-70.59 46.74) 10 Estrie POINT (-71.93 45.77) 11 Nord-du-Québec POINT (-69.61 59.3) L’objet villes_reg_pop associe à chaque municipalité la taille de sa population ainsi que sa région administrative. En agrégeant ensemble les villes d’une même région, il nous est possible de déterminer la taille de la population de cette région. C’est ce que nous allons faire en utilisant la fonction aggregate() : reg_pop&lt;-aggregate(villes_reg_pop[&quot;population&quot;], by = list(villes_reg_pop$Rgns_Ad), FUN = sum, na.rm = TRUE) reg_pop Simple feature collection with 17 features and 2 fields Attribute-geometry relationship: 0 constant, 1 aggregate, 1 identity Geometry type: GEOMETRY Dimension: XY Bounding box: xmin: -79.5 ymin: 45.05 xmax: -57.13 ymax: 62.42 Geodetic CRS: Geographic Coordinate System First 10 features: Group.1 population 1 Abitibi-Témiscamingue 125833 2 Bas-Saint-Laurent 143428 3 Capitale-Nationale 684340 4 Centre-du-Québec 201807 5 Chaudière-Appalaches 372758 6 Côte-Nord 72674 7 Estrie 251011 8 Gaspésie - Îles-de-la-Madeleine 62017 9 Lanaudière 409733 10 Laurentides 388382 geometry 1 MULTIPOINT ((-79.5 48.87), ... 2 MULTIPOINT ((-70.04 47.37),... 3 MULTIPOINT ((-72.27 46.76),... 4 MULTIPOINT ((-72.82 46.06),... 5 MULTIPOINT ((-72 46.57), (-... 6 MULTIPOINT ((-69.8 48.24), ... 7 MULTIPOINT ((-72.31 45.49),... 8 MULTIPOINT ((-66.69 49.1), ... 9 MULTIPOINT ((-73.92 46.68),... 10 MULTIPOINT ((-75.62 46.09),... De façon générale, la fonction aggregate(x, by, FUN) comprend trois arguments: x est l’objet spatial que l’on souhaite agréger, by défini la condition utilisée pour regrouper les éléments de x, FUN défini la fonction selon laquelle l’attribut d’un groupement est calculé à partir des attributs des éléments agrégés. Dans notre exemple, nous avons regroupé les points de l’objet spatial villes_reg_pop[\"population\"] qui possèdent la même valeur d’attribut \"Rgns_Ad\". Les points ainsi regroupés forment une géométrie multipoint (MULTIPOINT). Chaque groupe de points est identifié par le nom de sa région administrative (Abitibi-Témiscamingue, Bas-Saint-Laurent, etc.). L’attribut d’un groupe est calculé en faisant la somme (FUN = sum) des attributs des points qui le constituent. L’argument additionnel na.rm = TRUE précise que lors du calcul de la somme, les éléments dont l’attribut \"population\" prend la valeur NA doivent être ignorés. En effet, la population de quelques municipalités n’est pas définie dans cette base de données. Notez qu’une autre fonction aurait pu être utilisée, par exemple la moyenne, le maximum, le minimum, etc. La condition by peut prendre différentes forment. Elle peut être définie par une liste de longueur égale au nombre d’éléments dans x (c’est-à-dire le même nombre de rangées). C’est de cette façon que nous l’avons définie plus haut (la liste est de longueur égale aux nombres de points dans villes_reg_pop). De plus, by peut prendre la forme d’un objet spatial dont la géométrie est utilisée pour grouper les éléments de x. Dans ce cas, la géométrie du nouvel objet créé par la fonction aggregate() est la même que l’objet by. Donnons un exemple illustrant cette situation. Agrégeons maintenant les municipalités de l’objet villes_pop[\"population\"] en utilisant directement l’objet regions constitué de polygones  : reg_pop2 &lt;-aggregate(villes_pop[&quot;population&quot;], by = regions, FUN = sum, na.rm = TRUE) reg_pop2 Simple feature collection with 21 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: population geometry 1 NA POLYGON ((-66.69 55, -66.64... 2 NA POLYGON ((-66.26 55, -66.25... 3 157 POLYGON ((-67.22 55, -67 55... 4 91339 POLYGON ((-72.07 47.95, -72... 5 62017 POLYGON ((-67.15 49.19, -67... 6 143428 POLYGON ((-67.15 49.19, -66... 7 125833 POLYGON ((-75.52 47.85, -75... 8 275487 POLYGON ((-74.47 48.95, -74... 9 684340 POLYGON ((-72.07 47.95, -72... 10 311130 POLYGON ((-75.52 47.85, -75... Observez que les groupements sont maintenant des polygones, et non des multipoints. Par ailleurs le calcul de l’attribut \"population\" est le même. Une visualisation du nouvel objet reg_pop2 permet d’illustrer les régions selon la taille de leur population : mapview(reg_pop2) Donnons un dernier exemple de l’utilisation de la fonction aggregate() en considérant le shapefile régions regions Simple feature collection with 21 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: Rgns_Ad 1 Côte-Nord 2 Côte-Nord 3 Côte-Nord 4 Saguenay - Lac-Saint-Jean 5 Gaspésie - Îles-de-la-Madeleine 6 Bas-Saint-Laurent 7 Abitibi-Témiscamingue 8 Mauricie 9 Capitale-Nationale 10 Outaouais geometry 1 POLYGON ((-66.69 55, -66.64... 2 POLYGON ((-66.26 55, -66.25... 3 POLYGON ((-67.22 55, -67 55... 4 POLYGON ((-72.07 47.95, -72... 5 POLYGON ((-67.15 49.19, -67... 6 POLYGON ((-67.15 49.19, -66... 7 POLYGON ((-75.52 47.85, -75... 8 POLYGON ((-74.47 48.95, -74... 9 POLYGON ((-72.07 47.95, -72... 10 POLYGON ((-75.52 47.85, -75... Remarquez que certaines régions, comme la Côte-Nord, sont représentées par plusieurs polygones. C’est pour cette raison que ce shapefile contient 21 éléments spatiaux alors qu’il y a 17 régions administratives au Québec. Utilisons la fonction aggregate() pour agréger en un seul multipolygone les polygones qui portent la même valeur d’attribut \"Rgns_Ad\" : regions_agg &lt;-aggregate(regions, by=list(regions$Rgns_Ad), unique) regions_agg Simple feature collection with 17 features and 2 fields Attribute-geometry relationship: 0 constant, 1 aggregate, 1 identity Geometry type: GEOMETRY Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: Group.1 1 Abitibi-Témiscamingue 2 Bas-Saint-Laurent 3 Capitale-Nationale 4 Centre-du-Québec 5 Chaudière-Appalaches 6 Côte-Nord 7 Estrie 8 Gaspésie - Îles-de-la-Madeleine 9 Lanaudière 10 Laurentides Rgns_Ad 1 Abitibi-Témiscamingue 2 Bas-Saint-Laurent 3 Capitale-Nationale 4 Centre-du-Québec 5 Chaudière-Appalaches 6 Côte-Nord 7 Estrie 8 Gaspésie - Îles-de-la-Madeleine 9 Lanaudière 10 Laurentides geometry 1 POLYGON ((-75.52 47.85, -75... 2 POLYGON ((-67.15 49.19, -66... 3 POLYGON ((-72.07 47.95, -72... 4 POLYGON ((-72.08 46.57, -72... 5 POLYGON ((-70.2 47.41, -70.... 6 MULTIPOLYGON (((-67.41 54.9... 7 POLYGON ((-71.46 45.82, -71... 8 POLYGON ((-67.15 49.19, -67... 9 POLYGON ((-74.89 47.76, -74... 10 POLYGON ((-75.52 47.76, -75... Cette fois nous avons utilisé la fonction unique pour agréger les attributs qui sont de classe caractère. Remarquez que la Côte-Nord est maintenant représentée par un multipolygone (MULTIPOLYGON) et que le nouveau shapefile regions_agg contient 17 éléments, un pour chacune des régions administratives. Retirons la première colonne superflue de ce nouveau shapefile et utilisons-le dans les futurs exemples pour désigner les régions administratives. regions &lt;- regions_agg[-1] #pour retirer la première ligne La fonction st_simplify() Il est parfois utile de simplifier les objets vectoriels de types ligne ou polygone afin de produire des cartes à des échelles plus petites. La simplification permet de réduire l’utilisation de la mémoire, du disque, et de la bande passante. La fonction st_simplify() de la bibliothèque sf permet de simplifier des objets vectoriels de types ligne ou polygone en réduisant le nombre de points que ceux-ci comprennent. Souvenez-vous qu’une ligne est constituée d’une succession de points et qu’un polygone est constitué d’un ensemble de lignes. Cette fonction est basée sur l’algorithme de Douglas-Peucker. Décrire le fonctionnement de cet algorithme dépasse l’objectif de ce cours. Grosso modo, l’algorithme fait appel à un seuil de distance (le paramètre dTolerance) qu’il utilise pour transformer en ligne droite toute courbe qui dévie d’une ligne droite par une quantité moindre que ce seuil. Cette distance réflète en quelque sorte la résolution que nous souhaitons atteindre avec l’objet simplifié. Le seuil de tolérance étant une distance, nous l’exprimons en mètres. Nous devons alors nous assurer que l’objet spatial à simplifier est dans un système de coordonnées métriques. En guise d’exemple, simplifions le shapefile des régions administratives du Québec (??): regions_nad &lt;- st_transform(regions, crs = 32198) regions_simple_10 &lt;- st_simplify(regions_nad, dTolerance = 10000) #10000m regions_simple_40 &lt;- st_simplify(regions_nad, dTolerance = 40000) #40000m Remarquez que nous avons d’abord transformé l’objet spatial regions dans le système de coordonnées de référence NAD83, dont le EPSG correspond à 32198, puisque l’unité de ce système est le mètre. La fonction st_combine() La fonction st_combine() de la bibliothèque sf sert à combiner des géométries afin d’en former une seule. Cette opération peut être utile lorsque nous souhaitons considérer plusieurs géométries comme formant un même objet spatial. Reading layer `regn_tours_s250k_20160125&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module7/data/regions_touristiques/Shapefile/regn_tours_s250k_20160125.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 21 features and 4 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -79.77 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: WGS 84 Considérons le shapefile GIM contenant deux géométries: le polygone délimitant la Gaspésie et un polygone délimitant les Îles-de-la-Madeleine. GIM Simple feature collection with 2 features and 2 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -63 ymin: 46.84 xmax: -60.4 ymax: 48.67 Geodetic CRS: WGS 84 Id Nom_reg 1 1 Îles-de-la-Madeleine 2 2 Gaspésie geometry 1 MULTIPOLYGON (((-61 48.67, ... 2 MULTIPOLYGON (((-64.95 47.9... Maintenant, combinons ces deux polygones pour former une géométrie unique qui correspondra à la région administrative de la Gaspésie - Îles-de-la-Madeleine GIM_combine &lt;- st_combine(GIM) GIM_combine Geometry set for 1 feature Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -68.52 ymin: 46.84 xmax: -60.4 ymax: 49.72 Geodetic CRS: WGS 84 MULTIPOLYGON (((-61 48.67, -60.75 48.67, -60.5 ... Le nouvel objet GIM_combine est effectivement formé d’une seule géométrie. Notez cependant que la fonction st_combine() ne fusionne pas les frontières à l’intérieur du nouveau polygone formé (??). Pour unir deux polygones, il faut plutôt utiliser la fonction st_union() que nous définirons plus bas dans cette leçon. La fonction st_cast() La fonction st_cast() sert à convertir la géométrie d’un objet spatial donné vers une autre géométrie. Cette fonction comprend deux arguments : st_cast(x, to). Le premier argument, x, correspond à l’objet vectoriel dont on souhaite modifier la géométrie, alors que le second argument, to, correspond à la géométrie que l’on souhaite lui attribuer. Donnons un exemple. Utilisons d’abord le shapefile regions pour isoler le polygone de la région administrative de la Mauricie grâce à la fonction subset() : Mauricie &lt;- subset(regions,Rgns_Ad==&quot;Mauricie&quot;) Mauricie Simple feature collection with 1 feature and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: POLYGON Dimension: XY Bounding box: xmin: -75.52 ymin: 46.15 xmax: -71.89 ymax: 49 Geodetic CRS: GCS_Geographic_Coordinate_System Rgns_Ad geometry 12 Mauricie POLYGON ((-74.47 48.95, -74... Nous observons que l’objet Mauricie est bel et bien de type polygone. Maintenant utilisons la fonction st_cast() pour transformer la géométrie de cet objet en type multiligne et multipoint  : Mauricie_lines &lt;- st_cast(Mauricie, to = &quot;MULTILINESTRING&quot;) Mauricie_lines Simple feature collection with 1 feature and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: -75.52 ymin: 46.15 xmax: -71.89 ymax: 49 Geodetic CRS: GCS_Geographic_Coordinate_System Rgns_Ad geometry 12 Mauricie MULTILINESTRING ((-74.47 48... Mauricie_pts&lt;-st_cast(Mauricie, to = &quot;MULTIPOINT&quot;) Mauricie_pts Simple feature collection with 1 feature and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: MULTIPOINT Dimension: XY Bounding box: xmin: -75.52 ymin: 46.15 xmax: -71.89 ymax: 49 Geodetic CRS: GCS_Geographic_Coordinate_System Rgns_Ad geometry 12 Mauricie MULTIPOINT ((-74.47 48.95),... Nous observons que les deux nouveaux objets vectoriels ont bel et bien la géométrie souhaitée (??). Dans cet exemple, nous avons en quelque sorte “décomposé” la géométrie d’un polygone en lignes puis en points. Or, la fonction st_cast() peut également servir à “consolider” des géométries. En guise d’exemple, considérons l’objet villes_NQ_combo créé en isolant du shapefile villes_reg les villes situées dans la région administrative du Nord-du-Québec et en les combinant par l’utilisation de la fonction st_combine() : villes_NQ &lt;- subset(villes_reg, Rgns_Ad == &quot;Nord-du-Québec&quot;) villes_NQ_combo &lt;- st_combine(villes_NQ) villes_NQ_combo Geometry set for 1 feature Geometry type: MULTIPOINT Dimension: XY Bounding box: xmin: -79.29 ymin: 49.05 xmax: -65.95 ymax: 62.42 Geodetic CRS: Geographic Coordinate System MULTIPOINT ((-76.25 51.69), (-78.75 51.49), (-7... Cet objet possède une géométrie multipoint où chaque point correspond à une municipalité du Nord-du-Québec. Utilisons maintenant la fonction st_cast() pour transformer la géométrie de cet objet en ligne et en polygone  : villes_NQ_lines&lt;-st_cast(villes_NQ_combo, to = &quot;LINESTRING&quot;) villes_NQ_lines Geometry set for 1 feature Geometry type: LINESTRING Dimension: XY Bounding box: xmin: -79.29 ymin: 49.05 xmax: -65.95 ymax: 62.42 Geodetic CRS: Geographic Coordinate System LINESTRING (-76.25 51.69, -78.75 51.49, -73.87 ... villes_NQ_pol&lt;-st_cast(villes_NQ_combo, to = &quot;POLYGON&quot;) villes_NQ_pol Geometry set for 1 feature Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.29 ymin: 49.05 xmax: -65.95 ymax: 62.42 Geodetic CRS: Geographic Coordinate System POLYGON ((-76.25 51.69, -78.75 51.49, -73.87 50... L’objet villes_NQ_lines correspond effectivement à un ensemble de lignes et l’objet villes_NQ_lines à un ensemble de polygones formés en reliant les points ensembles. La fonction st_buffer() Une zone tampon (appelée buffer en anglais) est un polygone dont les frontières sont définies par une distance donnée autour d’un objet vectoriel. Une zone tampon peut être créée autour de tout objet vectoriel, que ce soit des points, des lignes ou des polygones. La création de zones tampons est généralement réalisée pour répondre à des questions de nature géographique. Par exemple, combien de garderies se situent à une distance de 2 km de ma maison ? Ou encore, combien de stations services se situent à moins de 500 m de la route menant de Chelsey à Cantley en Outaouais ? La fonction st_buffer() de la bibliothèque sf permet de créer des zones tampons. Cette fonction comprend obligatoirement deux arguments. Le premier correspond à l’objet vectoriel autour du quel nous souhaitons construire une zone tampon, et le deuxième argument défini la distance sur laquelle la zone tampon s’étendra autour de l’objet vectoriel. Comme pour la fonction st_simplify(), l’objet vectoriel auquel nous appliquons la fonction st_buffer() doit être exprimé dans un SCR d’unité de mesure métrique. Construisons des zones tampons autour de la ville de La Pocatière, que nous avons isolée plus haut, en considérant deux distances différentes (7.1): la_poc_nad &lt;- st_transform(la_poc, crs = 32198) la_poc_tampon10 &lt;- st_buffer(la_poc_nad, dist = 10e3) la_poc_tampon50 &lt;- st_buffer(la_poc_nad, dist = 50e3) Notez que l’expression e3 correspond au chiffre 1000 (c’est-à-dire 10 exposent 3). Figure 7.1: Deux zones tampons de 10 km (en bleu) et de 50 km (en vert) autour de la ville de La Pocatière Maintenant, construisons des zones tampons autour des régions administratives de l’Abitibi-Témiscamingue et du Saguenay - Lac-Saint-Jean (7.2). Utilisons d’abord la fonction subset() pour isoler les polygones correspondants à ces régions à partir du shapefile regions_nad dont l’unité de mesure du SCR est le mètre. # Isoler les polygones des deux régions Abitibi &lt;- subset(regions_nad, Rgns_Ad == &quot;Abitibi-Témiscamingue&quot;) SagStJean &lt;- subset(regions_nad, Rgns_Ad == &quot;Saguenay - Lac-Saint-Jean&quot;) # Calculer une zone tampon pour chacun des polygones Abitibi_tampon20 &lt;- st_buffer(Abitibi, dist = 20e3) #20 km SagStJean_tampon50 &lt;- st_buffer(SagStJean, dist = 70e3) #70 km Figure 7.2: Une zone tampon de 20 km autour de la région administrative de l’Abitibi-Témicamingue et une zone tampon de 70 km autour du Saguenay - Lac-Saint-Jean. Notez que la zone tampon d’un polygone inclue le polygone d’origine. C’est-à-dire que ce n’est pas simplement une bordure autour du polygone. La fonction st_centroid Le centroïde d’un polygone en cartographie correspond approximativement au centre géométrique d’un polygone36. Ces coordonnées servent parfois à définir la localisation du polygone. La fonction st_centroid() de la bibliothèque sf permet de calculer le centroïde de polygones. Déterminons le centroïde des polygones de l’Abitibi et du Saguenay - Lac-Saint-Jean (7.3). Notez que la fonction st_centroid() nécessite également que le polygone soit défini selon un SCR dont l’unité de mesure est le mètre. centre_Abitibi &lt;- st_centroid(Abitibi) centre_Abitibi Simple feature collection with 1 feature and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: POINT Dimension: XY Bounding box: xmin: -689600 ymin: 483300 xmax: -689600 ymax: 483300 Projected CRS: NAD83 / Quebec Lambert Rgns_Ad geometry 1 Abitibi-Témiscamingue POINT (-689572 483277) centre_SagStJean &lt;- st_centroid(SagStJean) centre_SagStJean Simple feature collection with 1 feature and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: POINT Dimension: XY Bounding box: xmin: -233200 ymin: 645400 xmax: -233200 ymax: 645400 Projected CRS: NAD83 / Quebec Lambert Rgns_Ad geometry 17 Saguenay - Lac-Saint-Jean POINT (-233243 645360) La fonction st_centroid() retourne un objet vectoriel de type point qui conserve les attributs du polygone. Figure 7.3: Les centroïdes (en rouge) des régions de l’Abitibi-Témicamingue (en bleu) et du Saguenay - Lac-Saint-Jean (vert) calculés avec la fonction st_centroid(). La fonction st_coordinates La fonction st_coordinates() permet de connaître les coordonnées d’un objet vectoriel. Trouvons, par exemple, les coordonnées de la ville de La Pocatière que nous avons isolée plus haut  : st_coordinates(la_poc) X Y 1 -70.04 47.37 Dans le cas présent, les coordonnées sont exprimées en degrés. Le X correspond à la longitude et le Y, à la latitude. En effet, le SCR de la_poc utilise des longitudes-latitudes. Ceci peut-être confirmé en utilisant la fonction st_is_longlat()  : st_is_longlat(la_poc) [1] TRUE D’autre part, l’objet la_poc_nad, que nous avons obtenu en transformant la_poc dans le SCR NAD83 utilise plutôt des mètres. Ainsi  : st_is_longlat(la_poc_nad) [1] FALSE Conséquemment, les coordonnées identifiées par la fonction st_coordinates() sont en mètres  : st_coordinates(la_poc_nad) X Y 1 -116039 375793 Notez que cette fonction peut être utilisée sur tout objet de type vectoriel (ligne, multiligne, polygone, etc.). La sortie correspondra alors à un tableau donnant les coordonnées de chaque point consituant l’objet. Opérations topologiques entre deux couches Les opérations topologiques décrivent les relations spatiales entre des objets37. Ces opérations sont équivalentes aux opérations ensemblistes en mathématiques, telles l’union ou l’intersection, mais s’appliquent cette fois à des objets définis par une géométrie. La bibliothèque sf contient plusieurs opérateurs topologiques; par exemple: st_union(), st_intersection(), st_difference() et st_sym_difference(). Ces opérateurs forment un nouvel objet spatial à partir des deux objets spatiaux intérroger. Par exemple, la géométrie de l’objet z formé par l’opération z &lt;- st_union(x,y) est constituée de la géométrie de x et de celle de y sans toutefois qu’il y ait de chevauchement. Pour illustrer les opérations topologiques entre deux objets vectoriels considérons les polygones A et B créés en définissant des zones tampons à partir des polygones de l’Abitibi-Témiscamingue et du Saguenay - Lac-Saint-Jean respectivement. A &lt;- st_buffer(Abitibi, dist = 80e3) B &lt;- st_buffer(SagStJean, dist = 100e3) Calculons maintenant des opérations topologiques sur ces polygones  : union_AB &lt;- st_union(A,B) inter_AB &lt;- st_intersection(A,B) diff_AB &lt;- st_difference(A,B) diff_BA &lt;- st_difference(B,A) sym_diff_AB &lt;- st_sym_difference(A,B) Observons les géométries produites par ces opérations (figure ??)  : Opérations topologiques de confirmation Les opérations topologiques de confirmation sont des fonctions qui permettent de vérifier si deux objets spatiaux satisfont à une relation topologique donnée. Ces opérations ne créent pas un nouvel objet spatial, elles retournent plutôt une valeur binaire qui confirme si oui ou non la relation existe entre les deux objets interrogés. La bibliothèque sf contient plusieurs opérateurs topologiques de confirmation; par exemple: st_intersects(), st_disjoint(), st_crosses(), st_overlaps(), st_touches(), st_within() et st_contains(). La fonction st_intersects La fonction st_intersects() vérifie si deux objets spatiaux X et Y occupent un espace commun. La fonction confirmera qu’il y a bel et bien une intersection entre les deux objets si leurs intérieurs ou leurs frontières se recoupent. X et Y peuvent avoir n’importe quelle géométrie (point, multipoint, ligne, multiligne, polygone, multipolygone) (figure 7.4). Figure 7.4: Combinaisons de géométries satisfaisant à la condition d’intersection. Récupérer sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Pour bien comprendre comment opère st_intersects() considérons le polygone A utilisé précédemment ainsi que l’objet spatial points constitués de cinq points de couleur différente. points Simple feature collection with 5 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -685800 ymin: 476800 xmax: -685800 ymax: 476800 Projected CRS: NAD83 / Quebec Lambert geometry couleur 1 POINT (-685765 476835) Bleu 2 POINT (-224449 667962) Rouge 3 POINT (-480113 560159) Violet 4 POINT (-395847 597020) Jaune 5 POINT (-902947 480553) Vert Figure 7.5: Exemples illustrant la fonction st_intersects(). Utilisons a fonction st_intersects() pour déterminer quels points intersectent le polygone A : st_intersects(points, A) Sparse geometry binary predicate list of length 5, where the predicate was `intersects&#39; 1: 1 2: (empty) 3: 1 4: (empty) 5: 1 La sortie est exprimée sous forme d’une liste contenant 5 paires éléments; une paire pour chacun des points interrogés. Le premier élément d’une paire (c’est-dire,le chiffre avant le deux-points) correspond à l’indice du point. Le second élément prend la valeur 1 si le point intersecte le polygone A, et la valeur empty si le point ne recoupe pas le polygone A. Il est aussi possible d’ajouter l’argument sparse = FALSE afin que la sortie s’exprime sous une forme matricielle d’éléments logiques. st_intersects(points, A, sparse = FALSE) [,1] [1,] TRUE [2,] FALSE [3,] TRUE [4,] FALSE [5,] TRUE La forme logique est particulièrement utile lorsque nous voulons filtrer les géométries qui satisfont à la condition d’intersection. Par exemple, cette commande retourne seulement les points qui intersectent le polygone A : points[st_intersects(points, A, sparse = FALSE),] Simple feature collection with 3 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -902900 ymin: 476800 xmax: -480100 ymax: 560200 Projected CRS: NAD83 / Quebec Lambert geometry couleur 1 POINT (-685765 476835) Bleu 3 POINT (-480113 560159) Violet 5 POINT (-902947 480553) Vert Que se passent-ils si nous inversons les arguments de la fonction st_intersects() ? st_intersects(A, points) Sparse geometry binary predicate list of length 1, where the predicate was `intersects&#39; 1: 1, 3, 5 Dans ce cas, la fonction retourne une liste d’une seule combinaison éléments associée au polygone interrogé. Cette fois, les éléments à droite du deux-points correspondent aux indices des points qui satisfont à la condition d’intersection. La fonction st_disjoint La fonction st_disjoint() vérifie la condition inverse de la fonction st_intersects(), c’est-à-dire l’absence d’intersection entre deux objets X et Y (figure 7.6). Figure 7.6: Combinaisons de géométries disjointes. Image récupérée sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Par exemple, la fonction st_disjoint() permet de confirmer que les points jaune et rouge sont disjoints du polygone A (Figure 7.5) : st_disjoint(A, points) Sparse geometry binary predicate list of length 1, where the predicate was `disjoint&#39; 1: 2, 4 # ou encore points$couleur[st_disjoint(A, points,sparse = FALSE)] [1] &quot;Rouge&quot; &quot;Jaune&quot; La fonction st_crosses La fonction st_crosses() vérifie si deux objets spatiaux X et Y se croisent. Cette fonction est donc similaire à la fonction st_intersects() mais elle contient des conditions supplémentaires: l’intersection entre les deux géométries inclue une partie mais pas l’entièreté de leurs intérieurs, la dimension géométrique de l’intersection doit être inférieure à la dimension maximale des deux géométries, l’intersection ne peut être égale à l’une ou l’autre des géométries. La figure 7.7 illustre différentes combinaisons de géométries qui satisfont à la condition st_crosses. Figure 7.7: Combinaisons de géométries qui se croisent. Image récupérée sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Donnons quelques exemples pour démontrer en quoi la fonction st_crosses() diffère de la fonction st_intersects(). Pour ce faire, considérons les géométries illustrées à la figure 7.8. Figure 7.8: Exemples illustrant la fonction st_crosses(). Bien que toutes ces géométries s’intersectent, elles ne se croisent pas toutes. Vérifions d’abord la condition d’intersection  : st_intersects(A,trait_bleu) Sparse geometry binary predicate list of length 1, where the predicate was `intersects&#39; 1: 1 st_intersects(A,trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `intersects&#39; 1: 1 st_intersects(A,B) Sparse geometry binary predicate list of length 1, where the predicate was `intersects&#39; 1: 1 Puis, la condition de croisement  : st_crosses(A,trait_bleu) Sparse geometry binary predicate list of length 1, where the predicate was `crosses&#39; 1: (empty) st_crosses(A,trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `crosses&#39; 1: 1 st_crosses(A,B) Sparse geometry binary predicate list of length 1, where the predicate was `crosses&#39; 1: (empty) Le trait bleu ne croise pas le polygone A car l’intersection entre ces deux géométries est égale au trait bleu. De plus, les polygones A et B ne se croisent pas non plus car leur intersection forme un polygone. Un polygone a une dimension géométrique de 2, tout comme les polygones A et B. Ainsi, seul le trait mauve croise le polygone A. En effet, une partie seulement de sa géométrie intersecte le polygone A, le reste étant situé à l’extérieur du polygone. La fonction st_overlaps La fonction st_overlaps() vérifie si l’intersection entre deux géométries de même dimension possède aussi la même dimension. De plus, cette intersection ne peut être égale à une des deux géométries interrogées. La figure 7.9 illustre différentes combinaisons de géométries qui satisfont à la condition de superposition. Figure 7.9: Combinaisons de géométries qui se superposent. Image récupérée sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Considérons les polygones A, B, ainsi que celui de l’Abitibi-Témiscamingue illustrés à la figure 7.10. Figure 7.10: Exemples illustrant la fonction st_overlaps(). Les polygones A et B satisfont la condition de superposition car leur intersection est aussi un polygone. Par ailleurs le polygone A et celui de l’Abitibi ne satisfont pas à la condition de superposition car l’intersection est identique au polygone de l’Abitibi-Témiscamingue. st_overlaps(A,B) Sparse geometry binary predicate list of length 1, where the predicate was `overlaps&#39; 1: 1 st_overlaps(Abitibi,A) Sparse geometry binary predicate list of length 1, where the predicate was `overlaps&#39; 1: (empty) La fonction st_touches La fonction st_touches() vérifie si deux objets X et Y ont au moins un point en commun sans toutefois que leurs interieurs s’intersectent. La figure 7.11 illustre différentes combinaisons de géométries qui se touchent. Figure 7.11: Combinaisons de géométries qui se touchent. Image récupérée sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Considérons par exemple les objets spatiaux illustrés à la figure ??  : La fonction st_touches() nous permet de vérifier que le polygone B, en rouge, touche au trait mauve et que le polygone A, en bleu, touche au point vert. Par ailleurs, la fonction confirme aussi que le polygone A ne touche pas au point bleu car ce sont leurs intérieurs qui s’intersectent. La même situation s’observe pour les polygones A et B qui partagent plus que leurs frontières. Cependant les polygones de l’Abitibi-Témiscamingue, en vert, et de la Mauricie, en jaune, s’intersectent seulement le long de leurs frontières et ainsi se touchent. st_touches(B, trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `touches&#39; 1: 1 st_touches(A, point_vert) Sparse geometry binary predicate list of length 1, where the predicate was `touches&#39; 1: 1 st_touches(A, point_bleu) Sparse geometry binary predicate list of length 1, where the predicate was `touches&#39; 1: (empty) st_touches(A,B) Sparse geometry binary predicate list of length 1, where the predicate was `touches&#39; 1: (empty) st_touches(Abitibi,Mauricie) Sparse geometry binary predicate list of length 1, where the predicate was `touches&#39; 1: 1 Les fonctions st_within et st_contains La fonction st_within(X,Y) vérifie si l’objet X est entièrement à l’intérieur de l’objet Y. À l’opposé, la fonction st_contains(X,Y) vérifie si l’objet X contient entièrement l’objet Y. L’ordre des arguments est donc important dans l’utilisation de ces deux fonctions. La figure 7.12 illustre différentes combinaisons de géométries qui sont contenues dans une autre géométrie. Figure 7.12: Combinaisons de géométries qui contiennent ou sont contenues dans une autre géométrie. Image récupérée sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Pour illustrer ces fonctions, considérons les objets spatiaux illustrés à la figure 7.13  : Figure 7.13: Exemples illustrant les fonctions st_contains() et st_within(). La fonction st_contains() nous permet de vérifier que le polygone A, en bleu, contient le point bleu et le trait bleu. Par contre, le polygone A ne contient pas le trait mauve puisque ce dernier n’est pas entièrement à l’intérieur de A. De plus, le contour rose du polygone B contient entièrement le trait mauve. st_contains(A, point_bleu) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: 1 st_contains(A, trait_bleu) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: 1 st_contains(A, trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: (empty) st_contains(contour_rose, trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: 1 La fonction st_contains() comporte une subtilité qui peut être trompeuse. La condition st_contains(X,Y) est satisfaite, c’est-à-dire, l’object X contient l’objet Y, si et seulement si aucun points de Y se trouve à l’extérieur de X, et qu’au moins un point de Y se trouve à l’intérieur de X38. En particulier, ceci signifie qu’un polygone ne contient jamais sa frontière. Ainsi, dans l’illustration de la figure 7.13, le polygone B, en rouge, ne contient pas le contour rose. Le polygone B ne contient pas non plus le trait mauve. Cependant, il contient le trait vert car ce dernier comporte des points à l’intérieur du polygone B. st_contains(B, contour_rose) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: (empty) st_contains(B, trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: (empty) st_contains(B, trait_vert) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: 1 La fonction st_contains() vérifie exactement la condition inverse de la fonction st_within() : st_within(point_bleu, A) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: 1 st_within(trait_bleu, A) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: 1 st_within(trait_mauve, A) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: (empty) st_within(trait_mauve, contour_rose) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: 1 st_within(contour_rose, B) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: (empty) st_within(trait_mauve, B) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: (empty) st_within(trait_vert, B) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: 1 Terminons cette sous-section par une remarque importante: La fonction st_join(), vue plus, qui permet de faire une jointure spatiale entre deux objets vectoriels s’appuie, par défaut, sur la fonction de confirmation st_intersects(). En effet, la fonction st_join(x,y) identifie la présence d’une intersection entre les éléments de x et de y puis assigne les attributs de y aux éléments de x qui satisfont cette condition d’intersection. Par aileurs, il est possible d’utiliser la fonction st_join() en utilisant d’autres opérations topologiques de confirmation que celle par défaut. En effet, il est possible de définir un troisième argument, join, pour préciser une autre opération comme st_contains, st_touches, st_overlaps etc. Donnons un exemple. Pour chaque régions administratives du Québec, déterminons les régions qui lui sont adjacentes. Il s’agit ici d’utiliser la fonction st_join() avec la condition st_touches : st_join(regions, regions, join = st_touches) Simple feature collection with 76 features and 2 fields Geometry type: GEOMETRY Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: Rgns_Ad.x 1 Abitibi-Témiscamingue 1.1 Abitibi-Témiscamingue 1.2 Abitibi-Témiscamingue 2 Bas-Saint-Laurent 2.1 Bas-Saint-Laurent 2.2 Bas-Saint-Laurent 2.3 Bas-Saint-Laurent 3 Capitale-Nationale 3.1 Capitale-Nationale 3.2 Capitale-Nationale Rgns_Ad.y 1 Mauricie 1.1 Nord-du-Québec 1.2 Outaouais 2 Capitale-Nationale 2.1 Chaudière-Appalaches 2.2 Côte-Nord 2.3 Gaspésie - Îles-de-la-Madeleine 3 Bas-Saint-Laurent 3.1 Centre-du-Québec 3.2 Chaudière-Appalaches geometry 1 POLYGON ((-75.52 47.85, -75... 1.1 POLYGON ((-75.52 47.85, -75... 1.2 POLYGON ((-75.52 47.85, -75... 2 POLYGON ((-67.15 49.19, -66... 2.1 POLYGON ((-67.15 49.19, -66... 2.2 POLYGON ((-67.15 49.19, -66... 2.3 POLYGON ((-67.15 49.19, -66... 3 POLYGON ((-72.07 47.95, -72... 3.1 POLYGON ((-72.07 47.95, -72... 3.2 POLYGON ((-72.07 47.95, -72... Cette fonction nous retourne un objet spatial composé de deux attributs. L’attribut de gauche, Rgns_Ad.x donne le nom de chaque polygone des régions administratives de regions alors que l’attribut de droite, Rgns_Ad.y, assigne à chacun de ces polygones, le nom d’une des régions administrives qui lui est voisine. Puisque chaque polygone possède plus d’une région voisine, leur nom et leur géométrie sont répétées pour chaque région voisine. Opérations de mesure Plusieurs fonctions de la bibliothèque sf permettent de calculer des mesures spatiales comme la distance, la superficie, ou la longueur. La fonction st_distance() La fonction st_distance() retourne la distance euclidienne entre deux objets spatiaux. Par exemple, nous pouvons utiliser cette fonction pour calculer la distance entre deux points. Calculons la distance qui sépare la ville de La Pocatière, dont nous avons isolé les coordonnées plus haut, et la ville de Rimouski. # Isoler le point correspondant aux coordonnées de la ville # de Rimouski à partir du shapefile des villes du Québec rimouski &lt;- subset(villes, toponyme == &quot;Rimouski&quot;) # Transformer rimouski dans le même SCR d&#39;unité métrique que la_poc rimouski_nad &lt;- st_transform(rimouski, crs = 32198) # Calculer la distance distance_lapoc_rimou &lt;- st_distance(la_poc_nad, rimouski_nad) distance_lapoc_rimou Units: [m] [,1] [1,] 164694 La distance calculée est de 164693 m, soit environ as.integer(round(distance_lapoc_rimou[1]/1000)) km. Notez que nous avons calculé la distance géométrique et non la distance que l’odomètre d’une voiture calculerait en voyageant sur l’autoroute entre La Pocatière et Rimouski. Observez que la fonction st_distance() retourne aussi l’unité de mesure, ici des mètres. En effet, l’objet retourné par cette fonction est de classe units : class(distance_lapoc_rimou) [1] &quot;units&quot; Nous pouvons également utiliser la fonction st_distance() pour calculer la distance entre plusieurs points. Par exemple, considérons le shapefile villes et calculons la distance qui sépare La Pocatière de chacune des villes du Québec. # Transformer le SRC de villes villes_nad &lt;- st_transform(villes, crs = 32198) # Calculer les distances distance_la_poc_villes &lt;- st_distance(villes_nad, la_poc_nad) # Assigner le nom des villes rownames(distance_la_poc_villes) &lt;- villes$toponyme colnames(distance_la_poc_villes) &lt;- &quot;La Pocatière&quot; # Les premières entrées head(distance_la_poc_villes) Units: [m] La Pocatière Blanc-Sablon 1032719 Lourdes-de-Blanc-Sablon 1027494 Nemiscau 654358 Waskaganish 775654 Saint-Augustin 926883 Chevery 833225 Ou encore, calculons la distance qui sépare chacune des villes du Québec  : distance_villes_villes &lt;- st_distance(villes_nad, villes_nad) colnames(distance_villes_villes) &lt;- villes$toponyme rownames(distance_villes_villes) &lt;- villes$toponyme quelques_villes &lt;- c(49, 154, 314, 549, 639) distance_villes_villes[quelques_villes, quelques_villes] Units: [m] Rouyn-Noranda Québec Gatineau Gaspé Rouyn-Noranda 0 607593 399903 1069375 Québec 607593 0 373067 549266 Gatineau 399903 373067 0 921441 Gaspé 1069375 549266 921441 0 Montréal 514725 231996 163439 778264 Montréal Rouyn-Noranda 514725 Québec 231996 Gatineau 163439 Gaspé 778264 Montréal 0 Cette fois, la fonction st_distance() retourne une matrice pour laquelle chaque entrée correspond à la distance entre deux villes. Cette matrice est bien sûr symétrique et sa diagonale est nulle. Nous pouvons aussi utiliser la fonction st_distance()pour calculer la distance entre un point et un polygone. Par exemple, calculons la distance entre le point correspondant au centre du polygone de l’Abitibi-Témiscamingue et le polygone du Saguenay - Lac-Saint-Jean (voir la figure 7.3). st_distance(centre_Abitibi, SagStJean) Units: [m] [,1] [1,] 268327 Notez que pour calculer la distance entre un polygone et un point, ce dernier doit être situé à l’extérieur du polygone, sans quoi cette fonction retourne la valeur zéro  : st_distance(centre_Abitibi, Abitibi) Units: [m] [,1] [1,] 0 La distance entre deux polygones se calcule de façon similaire. st_distance(Abitibi, SagStJean, by_element = TRUE) 76459 [m] Cette mesure correspond à la plus petite distance séparant les deux polygones. La fonction st_area() La fonction st_area() calcule la superficie d’un polygone. Calculons par exemple la superficie des polygones illustrés à la figure 7.13) : st_area(A) 1.74e+11 [m^2] st_area(B) 2.863e+11 [m^2] st_area(inter_AB) 1.642e+10 [m^2] Remarquez que les unités, ici des mètres carrés, sont fournies. L’objet retourné par la fonction st_area() est aussi de classe units : class(st_area(A)) [1] &quot;units&quot; La superficie d’objets spatiaux de dimension inférieure à deux est bien nulle : st_area(point_bleu) 0 [m^2] st_area(trait_bleu) 0 [m^2] La fonction st_length() La fonction st_length() calcule la longueur d’un objet spatial unidimensionnel (LINESTRING, MULTILINESTRING). st_length(trait_bleu) 227718 [m] st_length(trait_mauve) 361759 [m] st_length(contour_rose) 2095138 [m] Comme pour les fonctions st_distance() et st_area(), la fonction st_length() retourne un objet de classe units. La fonction calcule une longueur nulle pour les polygones ou les points : st_length(A) 0 [m] st_length(point_bleu) 0 [m] La fonction set_units Il peut être pratique de changer les unités de mesure avec lesquelles nous travaillons. Par exemple, utiliser les mètres carrés lorsque nous traitons de larges étendues peut être encombrant. La fonction set_units de la bibliothèque units permet de transformer les unités de mesure d’un objet ou d’en assigner à un objet sans unités. Par exemple, pour les unités de longueur : library(units) udunits database from /usr/share/xml/udunits/udunits2.xml L_m &lt;- st_length(trait_bleu) L_km &lt;- set_units(L_m,km) L_miles &lt;- set_units(L_m, miles) L_m 227718 [m] L_km 227.7 [km] L_miles 141.5 [miles] Et, pour les unités d’aire : A_m2 &lt;- st_area(A) A_km2 &lt;- set_units(A_m2, km2) A_ha &lt;- set_units(A_m2, ha) # 1 hectare (ha) mesure 100 m x 100 m A_m2 1.74e+11 [m^2] A_km2 174004 [km2] A_ha 17400384 [ha] 7.1.3 Problématique à résoudre Maintenant que nous avons appris les opérations de base pour manipuler les données vectorielles, nous sommes en mesure de résoudre la problématique énoncée au début de cette leçon : Parmi les dix plus grandes villes du Québec, quelle est celle qui dispose du plus grand nombre de parcs nationaux dans un rayon de 70 km ? Les étapes de la démarche de résolution sont les suivantes: Obtenir la taille de la population de chacune des municipalités. Filtrer ces municipalités pour retenir les 10 municipalités ayant la taille de population la plus importante. Lire la géodatabase du réseau de la SÉPAQ. Tracer une zone tampon de 70 km de rayon autour de chacune des dix plus grandes villes. Pour chaque zone, compter le nombre de parcs présent dans la zone tampon de 70 km. Déterminer la ville qui compte le plus grand nombre de parcs dans la zone tampon qui lui est associée. Commençons! 1. Taille des populations pour chaque municipalité Nous devons obtenir la taille de la population de chacune des municipalités québécoises. Nous avons déjà réalisé cette opération lorsque nous avons appris à utiliser la fonction merge(). En effet, nous avons associé à chaque municipalité contenue dans le shapefile villes la taille de sa population telle que donnée dans le dataframe pop. Nous avons utilisé la fonction merge() sur les colonnes toponyme et munnom qui agissent comme dénominateur commun des deux jeux de données. Voici un rappel de l’opération exécutée : villes_pop &lt;- merge(x = villes, y = pop, by.x=&quot;toponyme&quot;, by.y=&quot;munnom&quot;) names(villes_pop)[2:3] &lt;- c(&quot;superficie&quot;, &quot;population&quot;) # Nous avions aussi changer le nom des colonnes! head(villes_pop) Simple feature collection with 6 features and 3 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -78.2 ymin: 45.65 xmax: -62.08 ymax: 60.81 Geodetic CRS: Geographic Coordinate System toponyme superficie population 1 Acton Vale 91.1 7733 2 Aguanish 680.6 238 3 Akulivik 82.3 678 4 Albanel 205.0 2232 5 Alma 232.6 30831 6 Amherst 249.5 1459 geometry 1 POINT (-72.56 45.65) 2 POINT (-62.08 50.22) 3 POINT (-78.2 60.81) 4 POINT (-72.44 48.88) 5 POINT (-71.65 48.54) 6 POINT (-64.21 45.83) 2. Dix municipalités les plus grandes Nous devons filtrer l’objet villes_pop et sélectionner les 10 municipalités de plus grande population. Tout d’abord, il s’agit d’ordonner l’attribut population contenu dans l’objet villes_pop. Pour ce faire, nous allons utiliser la fonction order(): villes_pop &lt;- villes_pop[order(villes_pop$population, decreasing = TRUE), ] L’objet villes_pop est maintenant ordonné de manière décroissante en fonction de la taille de la population des municipalités. Ainsi, les 10 premières lignes de cet objet correspondent aux 10 municipalités les plus grandes du Québec. On peut donc assigner les 10 premières lignes à un nouvelle objet intitulé top10_villes: top10_villes &lt;- villes_pop[1:10, ] top10_villes Simple feature collection with 10 features and 3 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -75.64 ymin: 45.31 xmax: -71.18 ymax: 46.81 Geodetic CRS: Geographic Coordinate System toponyme superficie population 204 Montréal 431.7 1801546 240 Québec 485.2 546958 166 Laval 266.8 439754 94 Gatineau 380.6 286755 175 Longueuil 122.6 249338 442 Sherbrooke 366.0 169136 174 Lévis 498.3 147440 456 Trois-Rivières 334.2 138134 449 Terrebonne 158.5 117664 336 Saint-Jean-sur-Richelieu 233.7 98036 geometry 204 POINT (-73.56 45.51) 240 POINT (-71.21 46.81) 166 POINT (-73.75 45.55) 94 POINT (-75.64 45.48) 175 POINT (-73.52 45.54) 442 POINT (-71.89 45.4) 174 POINT (-71.18 46.8) 456 POINT (-72.54 46.34) 449 POINT (-73.63 45.69) 336 POINT (-73.25 45.31) Visualisons ce nouvel objet avec la fonction mapview(). mapview(top10_villes, zcol= &quot;population&quot;) 3. Géodatabase du réseau de la SÉPAQ La troisième étape consiste à charger la couche d’informations spatiales contenant les différentes aires récréatives du Québec. Cette information se trouve à l’intérieur de la géodatabase parcs.gdb disponible dans le répertoire Module7_donnees que vous avez téléchargé au début de la leçon. Comme vu dans le module 4, les géodatabase permettent de contenir plusieurs couches vectorielles. Nous devons donc lire la géodatabase et explorer les différentes couches afin de déterminer celle qui correspond aux aires récréatives. st_layers(&quot;Module7/Module7_donnees/parcs.gdb&quot;) Driver: OpenFileGDB Available layers: layer_name geometry_type features fields 1 Terafc_s Multi Polygon 5 18 2 Terpnq_s Multi Polygon 27 18 3 Terfer_s Multi Polygon 1 18 4 Terpla_s Multi Polygon 27 18 5 Terpma_s Multi Polygon 1 18 6 Terpnc_s Multi Polygon 4 18 7 Terrec_s Multi Polygon 72 18 8 Terref_s Multi Polygon 21 18 9 Terrfa_s Multi Polygon 9 18 10 Terrnf_s Multi Polygon 8 18 11 Terrom_s Multi Polygon 28 18 12 Tersfo_s Multi Polygon 1 18 13 Tertec_s Multi Polygon 1 18 14 Terzec_s Multi Polygon 86 18 15 Terepa_s Multi Polygon 1 18 16 Terpde_s Multi Polygon 189 18 17 Terpre_s Multi Polygon 17 18 Nous pouvons remarquer que les intitulés des différentes couches ne sont pas bien définis. Il faut donc prendre le temps de regarder la documentation accessible sur le site de données ouvertes Québec. Ne vous inquiétez pas, je l’ai fait pour vous! En s’intéressant à la structure de données et à la nomenclature utilisée et décrite, nous pouvons déterminer que la couche terpnq_s correspond aux territoires des parc nationaux du Québec. Nous pouvons donc faire la lecture de la géodatabase avec la fonction st_read() en précisant cette couche à l’aide de l’argument layer. parcs_nationaux &lt;- st_read(&quot;Module7/Module7_donnees/parcs.gdb&quot;, layer = &quot;terpnq_s&quot;) Reading layer `terpnq_s&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module7/Module7_donnees/parcs.gdb&#39; using driver `OpenFileGDB&#39; Simple feature collection with 27 features and 18 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -79.39 ymin: 45.29 xmax: -62.41 ymax: 61.45 Geodetic CRS: NAD83 Visualisons les polygones de parcs_nationaux. mapview(parcs_nationaux, zcol = &quot;TRQ_NM_TER&quot;, legend = FALSE) Notez que l’attribut “TRQ_NM_TER” de l’objet parcs_nationaux correspond au nom de chaque parc national. parcs_nationaux$TRQ_NM_TER [1] &quot;Parc national des Pingualuit&quot; [2] &quot;Parc national Kuururjuaq&quot; [3] &quot;Parc national Ulittaniujalik&quot; [4] &quot;Parc national Tursujuq&quot; [5] &quot;Parc national d&#39;Anticosti&quot; [6] &quot;Parc national de la Gaspésie&quot; [7] &quot;Parc national de la Pointe-Taillon&quot; [8] &quot;Parc national des Monts-Valin&quot; [9] &quot;Parc national d&#39;Aiguebelle&quot; [10] &quot;Parc national de l&#39;Île-Bonaventure-et-du-Rocher-Percé&quot; [11] &quot;Parc national du Fjord-du-Saguenay&quot; [12] &quot;Parc national du Bic&quot; [13] &quot;Parc national de Miguasha&quot; [14] &quot;Parc national des Hautes-Gorges-de-la-Rivière-Malbaie&quot; [15] &quot;Parc national du Lac-Témiscouata&quot; [16] &quot;Parc national des Grands-Jardins&quot; [17] &quot;Parc national de la Jacques-Cartier&quot; [18] &quot;Parc national d&#39;Opémican&quot; [19] &quot;Parc national du Mont-Tremblant&quot; [20] &quot;Parc national de Frontenac&quot; [21] &quot;Parc national des Îles-de-Boucherville&quot; [22] &quot;Parc national de Plaisance&quot; [23] &quot;Parc national du Mont-Saint-Bruno&quot; [24] &quot;Parc national d&#39;Oka&quot; [25] &quot;Parc national du Mont-Mégantic&quot; [26] &quot;Parc national de la Yamaska&quot; [27] &quot;Parc national du Mont-Orford&quot; 4. Zones tampons autour des plus grandes municipalités Nous traçons maintenant une zone tampon (POLYGON) de 70 km de rayon autour de chaque municipalité (POINT) du shapefile top10_villes. Pour se faire, nous allons utiliser la fonction st_buffer(). Avant de réaliser cette opération, nous devons vérifier que le système de coordonnées de référence de l’objet spatial top10_villes est défini en unité métrique. En effet, la distance de 70 km pourrait être interprétée comme étant 70 degrés si l’unité de la projection était en degré. Attention, cette erreur est très courante! Lorsque l’on veut calculer des distances euclidiennes, il faut toujours s’assurer que l’unité du système de projection est en mètre et non en degré. st_crs(top10_villes)$proj4string [1] &quot;+proj=longlat +ellps=GRS80 +no_defs&quot; +proj=longlat atteste que la projection est en degré. Nous allons donc reprojeter l’objet top10_villes dans le système de coordonnées de référence NAD83 qui est métrique et dont le EPSG est 32198. NAD83 correspond au système de coordonnées Conique conforme de Lambert. top10_villes_lcc &lt;- st_transform(top10_villes, crs = 32198) # On valide que les unités sont métriques (+units=m) st_crs(top10_villes_lcc)$proj4string [1] &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Traçons à présent les zones tampon (buffer) autour des municipalités à l’aide de la fonction st_buffer() comme expliqué précédemment, et visualisons le résultat de cette opération top10_villes_buffer &lt;- st_buffer(top10_villes_lcc, dist = 70e3) # 70 kms en mètres = 70e3 mapview(top10_villes_buffer, zcol = &quot;toponyme&quot;, legend = FALSE) Rappelons que le premier argument de la fonction st_buffer() correspond à l’objet spatial à partir duquel nous créons les zones tampons, et le second argument correspond à la longueur du rayon des zones tampon en mètres (70 km = 70e3 m). 5. Nombre de parcs dans chaque zone tampon Nous allons utiliser la fonction st_intersects() pour déterminer quels parcs de l’objet parcs_nationaux se trouvent, partiellement ou entièrement, à l’intérieur de chacune des zones tampons de l’objet top10_villes_buffer. Avant de réaliser cette opération spatiale, nous devons nous assurer que les deux objets spatiaux (top10_villes_buffer et parcs_nationaux) utilisent le même système de coordonnées de référence. st_crs(top10_villes_buffer) == st_crs(parcs_nationaux) [1] FALSE Puisque la réponse est négative, transformons le SCR de l’objet parcs_nationaux. parcs_nationaux_lcc = st_transform(parcs_nationaux, crs = st_crs(top10_villes_buffer)) Nous pouvons maintenant utiliser la fonction st_intersects(): st_intersects(x = top10_villes_buffer, y = parcs_nationaux_lcc, sparse = FALSE) [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [1,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [2,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [3,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [4,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [5,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [6,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [7,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [8,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [9,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [10,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] [1,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [2,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [3,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [4,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [5,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [6,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [7,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [8,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [9,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [10,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [1,] FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE [2,] TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [3,] FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE [4,] FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE [5,] FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE [6,] FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE [7,] TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [8,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [9,] FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE [10,] FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE [,25] [,26] [,27] [1,] FALSE FALSE FALSE [2,] FALSE FALSE FALSE [3,] FALSE FALSE FALSE [4,] FALSE FALSE FALSE [5,] FALSE FALSE FALSE [6,] TRUE TRUE TRUE [7,] FALSE FALSE FALSE [8,] FALSE FALSE FALSE [9,] FALSE FALSE FALSE [10,] FALSE TRUE FALSE La fonction st_intersects avec l’argument sparse = FALSE retourne une matrice avec en ligne les zones tampons des 10 plus grandes villes (argument x ci-dessus) et en colonne, les 27 parcs nationaux du Québec (argument y ci-dessus). Pour chacune des combinaisons, la valeur boléenne renvoyée (TRUE ou FALSE) spécifie si les deux polygones se chevauchent (partiellement ou non). L’une des propriétés intéressante des valeurs boléennes (TRUE ou FALSE), renvoyées par la fonction st_intersects, est que la valeur TRUE peut être interprétée par R comme une valeur de 1 et FALSE comme une valeur de 0. Il est donc possible de réaliser des opérations mathématiques sur des valeurs boléennes. Par exemple, nous pouvons effectuer une sommation sur les lignes (zones tampons de chaque grande municipalité) afin de déterminer combien de parcs nationaux se trouvent à l’intérieur des zones tampons (c-à-d combien d’éléments ont la valeur TRUE). rowSums(st_intersects(x = top10_villes_buffer, y = parcs_nationaux_lcc, sparse = FALSE)) [1] 3 1 3 1 3 4 1 0 3 4 Consignons à présent ces valeurs dans une nouvelle colonne de la table d’attributs de l’objet top10_villes. top10_villes$nbr_parcs &lt;- rowSums(st_intersects(x = top10_villes_buffer, y = parcs_nationaux_lcc, sparse = FALSE)) top10_villes Simple feature collection with 10 features and 4 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -75.64 ymin: 45.31 xmax: -71.18 ymax: 46.81 Geodetic CRS: Geographic Coordinate System toponyme superficie population 204 Montréal 431.7 1801546 240 Québec 485.2 546958 166 Laval 266.8 439754 94 Gatineau 380.6 286755 175 Longueuil 122.6 249338 442 Sherbrooke 366.0 169136 174 Lévis 498.3 147440 456 Trois-Rivières 334.2 138134 449 Terrebonne 158.5 117664 336 Saint-Jean-sur-Richelieu 233.7 98036 geometry nbr_parcs 204 POINT (-73.56 45.51) 3 240 POINT (-71.21 46.81) 1 166 POINT (-73.75 45.55) 3 94 POINT (-75.64 45.48) 1 175 POINT (-73.52 45.54) 3 442 POINT (-71.89 45.4) 4 174 POINT (-71.18 46.8) 1 456 POINT (-72.54 46.34) 0 449 POINT (-73.63 45.69) 3 336 POINT (-73.25 45.31) 4 7. Ville qui compte le plus grand nombre de parcs Pour répondre à la question posée, ordonnons la table d’attributs de l’objet top10_villes en se basant sur la nouvelle colonne nbr_parcs. top10_villes &lt;- top10_villes[order(top10_villes$nbr_parcs, decreasing = TRUE), ] top10_villes Simple feature collection with 10 features and 4 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -75.64 ymin: 45.31 xmax: -71.18 ymax: 46.81 Geodetic CRS: Geographic Coordinate System toponyme superficie population 442 Sherbrooke 366.0 169136 336 Saint-Jean-sur-Richelieu 233.7 98036 204 Montréal 431.7 1801546 166 Laval 266.8 439754 175 Longueuil 122.6 249338 449 Terrebonne 158.5 117664 240 Québec 485.2 546958 94 Gatineau 380.6 286755 174 Lévis 498.3 147440 456 Trois-Rivières 334.2 138134 geometry nbr_parcs 442 POINT (-71.89 45.4) 4 336 POINT (-73.25 45.31) 4 204 POINT (-73.56 45.51) 3 166 POINT (-73.75 45.55) 3 175 POINT (-73.52 45.54) 3 449 POINT (-73.63 45.69) 3 240 POINT (-71.21 46.81) 1 94 POINT (-75.64 45.48) 1 174 POINT (-71.18 46.8) 1 456 POINT (-72.54 46.34) 0 Nous constatons que Sherbrooke et Saint-Jean-sur-Richelieu disposent toutes deux du plus grand nombre (4) de parcs nationaux dans un rayon de 70 km! Le centre géométrique d’une forme planaire est la moyenne des positions de tous les points constituants la forme. Vous pouvez trouver des informations supplémentaires sur le centroïde [ici]^(http://wiki.gis.com/wiki/index.php/Centroid).↩︎ https://geocompr.robinlovelace.net/spatial-operations.html#topological-relations↩︎ http://lin-ear-th-inking.blogspot.com/2007/06/subtleties-of-ogc-covers-spatial.html↩︎ "],["ex_map_vec.html", "7.2 Exercices", " 7.2 Exercices Dans cette section, vous mettrez en pratique certains concepts vus dans la section leçon de ce module. Bien que la réponse à chaque question soit disponible, il est très important de tenter d’y répondre par vous même! Question 1 a) Construire un polygone de la forme d’un quadrilatère dont les sommets correspondent aux municipalités suivantes: Blanc-Sablon, Gaspé, Ivujivik et Chisasibi. Réponse Utiliser la fonction subset() pour filtrer le shapefile municipalites et isoler ces quatres villes. Selection &lt;- subset(villes, (toponyme == &quot;Blanc-Sablon&quot;) | (toponyme == &quot;Gaspé&quot;) | (toponyme == &quot;Ivujivik&quot;) | (toponyme == &quot;Chisasibi&quot;)) Selection Simple feature collection with 4 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -78.9 ymin: 48.83 xmax: -57.13 ymax: 62.42 Geodetic CRS: Geographic Coordinate System toponyme geometry 1 Blanc-Sablon POINT (-57.13 51.43) 549 Gaspé POINT (-64.48 48.83) 710 Chisasibi POINT (-78.9 53.78) 718 Ivujivik POINT (-77.91 62.42) Le symbole | signifie et. Combiner ces quatres villes (points) en un seul objet spatial (multipoints) en utilisant la fonction st_combine() : Combo_Selection &lt;- st_combine(Selection) Combo_Selection Geometry set for 1 feature Geometry type: MULTIPOINT Dimension: XY Bounding box: xmin: -78.9 ymin: 48.83 xmax: -57.13 ymax: 62.42 Geodetic CRS: Geographic Coordinate System MULTIPOINT ((-57.13 51.43), (-64.48 48.83), (-7... Transformer cet objet multipoints en polygone en utilisant la fonction st_cast() : Poly_Selection &lt;- st_cast(Combo_Selection, to = &quot;POLYGON&quot;) Poly_Selection Geometry set for 1 feature Geometry type: POLYGON Dimension: XY Bounding box: xmin: -78.9 ymin: 48.83 xmax: -57.13 ymax: 62.42 Geodetic CRS: Geographic Coordinate System POLYGON ((-57.13 51.43, -64.48 48.83, -78.9 53.... Confirmer votre réponse en visualisant le polygone formé : mapview(Poly_Selection) b) Quelle est la superficie, en km, de ce polygone? Réponse S’assurer d’abord que le polygone est représenté dans une projection métrique : st_crs(Poly_Selection)$proj4string [1] &quot;+proj=longlat +ellps=GRS80 +no_defs&quot; +proj=longlat atteste que la projection est en degré. Reprojeter l’objet dans le SCR NAD83 dont le EPSG est 32198 : Poly_Selection_nad83 &lt;- st_transform(Poly_Selection, crs = 32198) st_crs(Poly_Selection_nad83)$proj4string [1] &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Les unités sont à présent en mètres. Calculer la superficie du polygone en utilisant la fonction st_area() et convertisser les unités en \\(km^2\\) en utilisant la fonction set_units() : Aire &lt;- st_area(Poly_Selection_nad83) Aire_km2 &lt;- set_units(Aire, km2) Aire_km2 1020565 [km2] Question 2 a) Combien de villes se trouvent dans une zone tampon de 20 km autour de la frontière séparant les régions administratives des Laurentides et de Lanaudière. Réponse Utiliser la fonction subset() pour filtrer le shapefile regions et isoler les polygones correspondants aux Laurentides et à Lanaudière. regions_nad &lt;- st_transform(regions, crs = 32198) #utiliser une projection métrique Laurentides &lt;- subset(regions_nad, Rgns_Ad == &quot;Laurentides&quot;) Lanaudiere &lt;- subset(regions_nad, Rgns_Ad == &quot;Lanaudière&quot;) Trouver la frontière entre les deux régions en utilisant la fonction st_intersection() : Frontiere &lt;- st_intersection(Laurentides, Lanaudiere) mapview(Frontiere) La visualisation permet de valider votre calcul. Créer maintenant une zone tampon de 50 km autour de la frontière en utilisant la fonction st_buffer : Frontiere_tampon &lt;- st_buffer(Frontiere, dist = 20e3) mapview(Frontiere_tampon) Utiliser à nouveau la fonction st_intersection() pour trouver les municipalités à l’intérieur de la zone tampon. Il s’agit, en effet, de trouver l’intersection entre les shapeliles villes et Frontiere_tampon. villes_nad &lt;- st_transform(villes, crs = 32198) #utiliser une projection métrique Villes_Frontiere_tampon &lt;- st_intersection(villes_nad, Frontiere_tampon) mapview(Villes_Frontiere_tampon) Utiliser la fonction nrow() pour trouver le nombre de villes dans la zone tampon. nrow(Villes_Frontiere_tampon) [1] 28 b) Calculer la taille de la population qui habite cette zone tampon. Réponse Utiliser la fonction merge() pour combiner le tableau pop listant la taille des populations municipales à l’objet Villes_Frontiere_tampon défini plus haut. Villes_Frontiere_tampon_pop &lt;- merge(x = Villes_Frontiere_tampon, y = pop, by.x = &quot;toponyme&quot;, by.y = &quot;munnom&quot; ) head(Villes_Frontiere_tampon_pop) Simple feature collection with 6 features and 5 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -421200 ymin: 187600 xmax: -396100 ymax: 246500 Projected CRS: NAD83 / Quebec Lambert toponyme Rgns_Ad Rgns_Ad.1 msuperf mpopul 1 Blainville Laurentides Lanaudière 55.4 60838 2 Boisbriand Laurentides Lanaudière 29.5 26899 3 Chertsey Laurentides Lanaudière 302.1 4816 4 Deux-Montagnes Laurentides Lanaudière 7.3 17998 5 Laval Laurentides Lanaudière 266.8 439754 6 Mascouche Laurentides Lanaudière 107.6 49466 geometry 1 POINT (-419531 202664) 2 POINT (-415976 194824) 3 POINT (-416660 246456) 4 POINT (-421211 187607) 5 POINT (-409628 187891) 6 POINT (-396135 208723) Utiliser la fonction sum() pour calculer la population totale comprise dans la zone tampon. sum(Villes_Frontiere_tampon_pop$mpopul) [1] 977256 Une autre façon d’obtenir le même résultat est d’utiliser la fonction aggregate() : villes_nad_pop &lt;- merge(x = villes_nad, y = pop, by.x = &quot;toponyme&quot;, by.y = &quot;munnom&quot; ) aggregate(villes_nad_pop[&quot;mpopul&quot;], by = Frontiere_tampon, FUN = sum) Simple feature collection with 1 feature and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: -496800 ymin: 180900 xmax: -386800 ymax: 459700 Projected CRS: NAD83 / Quebec Lambert mpopul geometry 10 977256 POLYGON ((-489069 423212, -... Question 3 Trouver les régions administratives traversées par la ligne reliant la ville de Sherbrooke à celle de Fermont. Réponse Utiliser la fonction subset() pour isoler les points du shapefile villes_nad correspondants aux villes de Sherbrooke et de Fermont. Sherb_Fermont &lt;- subset(villes_nad, (toponyme == &quot;Sherbrooke&quot;) | (toponyme == &quot;Fermont&quot;)) mapview(Sherb_Fermont) Utiliser la fonction st_combine() pour combiner ces deux points en une seule géométrie multipoint. Sherb_Fermont_points &lt;- st_combine(Sherb_Fermont) Utiliser la fonction st_cast() pour transformer la géométrie multipoint en ligne. Sherb_Fermont_ligne &lt;- st_cast(Sherb_Fermont_points, to = &quot;LINESTRING&quot;) mapview(Sherb_Fermont_ligne) Utiliser maintenant la fonction st_crosses pour déterminer les régions administratives traversées par cette ligne. regions_nad[st_crosses(regions_nad, Sherb_Fermont_ligne, sparse = FALSE ),] Simple feature collection with 6 features and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: GEOMETRY Dimension: XY Bounding box: xmin: -434800 ymin: 117900 xmax: 787400 ymax: 1229000 Projected CRS: NAD83 / Quebec Lambert Rgns_Ad 3 Capitale-Nationale 4 Centre-du-Québec 5 Chaudière-Appalaches 6 Côte-Nord 7 Estrie 17 Saguenay - Lac-Saint-Jean geometry 3 POLYGON ((-265892 445785, -... 4 POLYGON ((-274244 292963, -... 5 POLYGON ((-127822 380938, -... 6 MULTIPOLYGON (((69033 12183... 7 POLYGON ((-230167 207127, -... 17 POLYGON ((-265892 445785, -... Utiliser la fonction mapview() pour valider visuellement votre réponse. regions_traversees &lt;- regions_nad[st_crosses(regions_nad, Sherb_Fermont_ligne, sparse = FALSE ),] mapview(regions_traversees) + mapview(Sherb_Fermont_ligne) Question 4 La problématique résolue à la fin de la leçon, nous a permis de déterminer que 4 parcs de la SÉPAQ se trouvent dans un rayon de 70 km de la municipalité de Saint-Jean-sur-Richelieu. Quelle est la superficie totale couverte par ces parcs à l’intérieur de ce rayon ? Réponse À partir de l’objet spatial top10_villes_buffer créé plus tôt, isoler la zone tampon autour de la municipalité de Saint-Jean-sur-Richelieu en utilisant la fonction subset(). SJSR_tampon &lt;- subset(top10_villes_buffer, toponyme == &quot;Saint-Jean-sur-Richelieu&quot;) Utiliser la fonction st_intersection pour trouver les parcs du shapefile parcs_nationaux_lcc qui intersectent cette zone tampon. Parcs_SJSR_tampon &lt;- st_intersection(parcs_nationaux_lcc, SJSR_tampon) mapview(Parcs_SJSR_tampon) + mapview(SJSR_tampon, col.regions = &quot;red&quot;, alpha.regions = 0.2) Utiliser la fonction st_area() pour déterminer la superficie de chacun des parcs. Aire_Parcs_SJSR_tampon &lt;- st_area(Parcs_SJSR_tampon) Aire_Parcs_SJSR_tampon Units: [m^2] [1] 8030419 8860076 22905154 13477000 Utiliser la fonction sum() pour déterminer la superficie totale, puis la fonction set_units() pour transformer les mètres carrés en hectares. AireTot_Parcs_SJSR_tampon &lt;- sum(Aire_Parcs_SJSR_tampon) AireTot_Parcs_SJSR_tampon &lt;- set_units(AireTot_Parcs_SJSR_tampon, ha) AireTot_Parcs_SJSR_tampon 5327 [ha] "],["manip_mat.html", "Module 8 Manipulation de données matricielles", " Module 8 Manipulation de données matricielles Cette leçon porte sur la manipulation des données spatiales matricielles. À la fin de ce module vous saurez: Attribuer des catégories aux valeurs des cellules d’un raster. Filtrer des cellules d’un raster selon leur valeur. Filtrer des cellules d’un raster selon leurs coordonnées. Découper un raster en utilisant un rectangle de délimitation. Découper un raster en utilisant un objet vectoriel. Combiner des rasters pour en former un seul. Déterminer les coordonnées d’une cellule à partir de son indice. Déterminer l’objet spatial le plus proche d’un autre. Vous utiliserez les bibliothèques suivantes: mapview raster sf elevatr Vous apprendrez à utiliser les fonctions suivantes: reclassify() crop() mask() extract() st_sfc(), st_as_sf() st_nearest_feature() xyFromCell() cumsum() get_elev_raster() De plus, vous utiliserez aussi des fonctions vues dans les modules précédents: nrow(), ncol() et ncell() summary() unique() subset() which(), which.max() max() as.data.frame(), data.frame() extent() plot() crs(), st_crs() st_polygon() st_intersects() Vous utiliserez les données suivantes: Dans la section Leçon ainsi que dans la section Exercices, vous utiliserez des données matricielles d’élévation pour le Québec, des données vectorielles des sentiers de randonnées de la SÉPAQ, ainsi que les limites de quatre parcs nationaux identifiés au module 7. "],["lecon_mat_mani.html", "8.1 Leçon", " 8.1 Leçon Au module 5, vous avez appris les fonctions essentielles pour lire et visualiser des données spatiales matricielles sous R. Le présent module vous amènera maintenant à manipuler conjointement des données matricielles et vectorielles. Dans un premier temps, cette leçon vous enseignera le fonctionnement d’opérations de base sur les données matricielles. Dans un second temps, cette leçon vous guidera dans la résolution d’une problèmatique qui nécessite de manipuler des données matricielles. Au cours des différentes étapes permettant de résoudre la problématique, vous mettrez en pratique les diverses fonctions R apprises jusqu’à maintenant. Plus précisément, nous allons pousser plus loin la problématique étudiée au module 7 en répondant aux deux questions suivantes: Parmi les quatre parcs nationaux de la région de Sherbrooke, lequel dispose du plus haut sommet? Quelle est le profil topographique du sentier se rendant au plus proche de ce sommet? 8.1.1 Télécharger les données Les données Dans cette leçon, nous allons utiliser le modèle d’élévation numérique aussi appelé Digital Elevation Model (DEM). Cette couche d’information spatiale est produite par le gouvernement du Canada (accessible sur ce portail). Cette couche est une matrice de données (raster) contenant des valeurs d’élévation en mètres. Nous allons également nous servir de la base de données vectorielles des sentiers de randonnées de la SÉPAQ (source), ainsi que celle des parcs nationaux de la région de Sherbrooke identifiés au module 7. Afin de faciliter le téléchargement de ces données, l’ensemble de ces couches d’informations spatiales peuvent être téléchargée en cliquant sur un seul lien: données pour le module 8. Une fois téléchargé, le dossier compressé (zip) doit être dézippé dans votre répertoire de travail. Le dossier Module8_donnees comprend deux sous-dossiers et un fichier: parcs_sherbrooke DEM.tif sentiers_sepaq 8.1.2 Opération de bases Dans cette section, nous allons nous familiariser avec les opérations fréquemment utilisées sur les données matricielles. 8.1.2.1 Importer et visualiser les données Dans allons d’abord importer les différentes couches d’informations spatiales dans l’environnement R. Nous commençons par charger les bibliothèques requises pour importer les données spatiales vectorielles (sf), pour importer les données spatiales matricielles (raster) et pour visualiser ces données (mapview). library(sf) library(raster) library(mapview) Ensuite, nous utilisons la fonction st_read() pour importer le shapefile parcs_sherbrooke qui contient les quatre parcs se situant dans un rayon de 70 km de la municipalité de Sherbrooke (voir la problématique du module 7). parcs &lt;- st_read(&quot;Module8/Module8_donnees/parcs_sherbrooke/parcs_sherbrooke.shp&quot;) Reading layer `parcs_sherbrooke&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module8/Module8_donnees/parcs_sherbrooke/parcs_sherbrooke.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 4 features and 18 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -323500 ymin: 151800 xmax: -201900 ymax: 226200 Projected CRS: NAD83 / Quebec Lambert Enfin, nous importons la couche d’élévation DEM pour la région d’intérêt en utilisant la fonction raster(). dem &lt;- raster(&quot;Module8/Module8_donnees/DEM.tif&quot;) Nous visualisons ensuite les deux objets spatiaux afin de valider l’importation en utilisant la fonction mapview(). mapview(dem) + mapview(parcs, zcol = &quot;TRQ_NM_&quot;) Notez que l’attribut TRQ_NM_ correspond aux noms des parcs nationaux. 8.1.2.2 Filtrer les cellules d’un raster Une des opérations les plus fréquentes sur les raster est celle de filtrer les cellules (ou pixels). Ceci peut être fait dans le but de sélectionner des cellules possédant une valeur d’attribut particulière. Par exemple, à partir d’une couche matricielle des différentes classes d’utilisation du sol pour une région donnée, nous pourrions vouloir sélectionner les pixels de la classe “Eaux” ou encore ceux de la classe “Terres humides”. Filtrer les cellules peut également être fait dans le but de sélectionner des cellules sur la base de leur localisation spatiale. Par exemple, nous pourrions vouloir choisir les cellules d’un raster qui sont à l’intérieur des limites administratives d’une municipalité. Dans les sous-sections qui suivent, nous présenterons des fonctions qui permettent de réaliser ces deux types d’opération de filtrage de données matricielles. Filtrer en utilisant la valeur des cellules Fonction which() Au module 5, nous avons vu comment accéder et manipuler les données de raster en utilisant, entre autres, les fonctions summary() et getValues(). Il est ainsi possible d’avoir une idée de la distribution des valeurs du raster dem en utilisant la ligne de commande suivante : summary(getValues(dem)) Min. 1st Qu. Median Mean 3rd Qu. Max. 30 211 303 314 410 1174 NA&#39;s 3839 Nous pouvons apercevoir que certaines cellules du raster dem contiennent des valeurs négatives. Notez que ces valeurs ne sont pas aberrantes et signifient simplement que ces pixels se retrouvent en dessous du niveau de la mer. Pour la suite de la leçon (et à titre d’exemple), nous allons exclure ces valeurs négatives. En d’autres termes, nous allons appliquer un filtre sur les cellules du raster, filtre qui ne laissera passer que les valeurs positives. Plus précisément, nous allons utiliser la fonction which() pour filter les données du raster dem. Rappelons que la fonction which() identifie la position des éléments de valeur TRUE dans un vecteur logique (voir le module 7 pour un rappel). Utilisons donc cette fonction pour trouver les cellules qui ont des valeurs d’élévation négatives. ind &lt;- which(getValues(dem) &lt; 0) ind integer(0) La ligne de commande ci-dessus retourne les indices des cellules qui satisfont la condition demandée (c’est-à-dire avoir une valeur négative). Pour savoir combien de cellules possèdent une valeur d’élévation négative, nous pouvons tout simplement compter le nombre d’éléments contenus dans le vecteur retourné par la fonction which(). Si les cellules identifiées étaient nombreuses ou si nous avions besoin de conserver ce nombre en mémoire pour l’utiliser dans la suite de notre analyse, nous pourrions obtenir ce compte en utilisant la fonction générale length() qui retourne la taille d’un vecteur: nombre &lt;- length(ind) nombre [1] 0 Notons qu’il est aussi possible d’accéder aux valeurs de ces cellules en utilisant les indices ind identifiés: getValues(dem)[ind] numeric(0) Nous observons que les valeurs sont belles et bien négatives! Pour filtrer ces cellules aux valeurs négatives, c’est-à-dire exclure ces valeurs de notre analyse, nous allons remplacer leur valeur par le terme NA. Rappelons que NA signifie non applicable. dem[ind] &lt;- NA Voyons maintenant comment cette modification aux valeurs de certaines cellules altère les statistiques générales sur les valeurs du raster dem : summary(getValues(dem)) Min. 1st Qu. Median Mean 3rd Qu. Max. 30 211 303 314 410 1174 NA&#39;s 3839 L’élévation minimale est maintenant de 2 et le nombre de NA a augmenté de 0. Ceci confirme que notre filtre a bien été appliqué. La fonction which() peut aussi être utilisée pour filtrer des données selon des expressions logiques plus complexes. Nous pouvons, par exemple, remplacer getValues(dem) &lt; 0 par getValues(dem) &lt; 0 | getValues(dem) &gt; 1000 pour exclure également les cellules avec des valeurs plus grandes que 1000 m. De plus, il est aussi possible de changer les valeurs des cellules identifiées en d’autres valeurs que NA. Fonction reclassify La fonction reclassify() de la bibliothèque raster permet également de filtrer des données matricielles et de leur assigner de nouvelles valeurs. Démontrons son utilisation par un cas simple. Nous allons catégoriser le niveau d’élévation, c’est-à-dire les valeurs du raster dem, en trois catégories: catégorie 1: classe d’élévation faible allant de 0 à 250 m, catégorie 2: classe d’élévation modérée allant de 251 à 500 m, catégorie 3: classe d’élévation forte allant de 501 à 1200 m. Avant de pouvoir utiliser la fonction reclassify() il est nécessaire de construire une matrice indiquant les bornes limites des différentes classes. nouvelles_classes &lt;- matrix(c(0, 250, 1, 250, 500, 2, 500, 1200, 3), nrow = 3, ncol = 3, byrow = TRUE) colnames(nouvelles_classes) &lt;- c(&quot;Limite_min&quot;, &quot;Limite_max&quot;, &quot;nouvelles_classes&quot;) nouvelles_classes Limite_min Limite_max nouvelles_classes [1,] 0 250 1 [2,] 250 500 2 [3,] 500 1200 3 Cette matrice est utilisée comme argument de la fonction reclassify() afin d’assigner les nouvelles classes aux valeurs du raster dem. nouvelles_classes_dem &lt;- reclassify(dem, nouvelles_classes, rigth = FALSE) Notez que l’utilisation par défaut de la fonction reclassify() inclue la borne supérieure mais pas la borne inférieure de l’intervalle de reclassification (]limite_lim, limite_max]). L’ajout de l’argument rigth = FALSE vient spécifier que nous souhaitons le contraire, c’est-à-dire l’inclusion de la borne inférieure mais pas de la borne supérieure ([limite_lim, limite_max[). Ainsi, nous avons précisé que les valeurs inclues dans la nouvelle classe 1 vont de 0 à 249 m plutôt que de 1 à 250 m. Visualisons la nouvelle classification du domaine de valeurs du raster d’élévation dem à l’aide de la fonction mapview(): mapview(nouvelles_classes_dem) Notez que nous pouvons aussi utiliser NA pour exclure certaines cellules: nouvelles_classes2 &lt;- matrix(c(0, 250, NA, 250, 500, 2, 500, 1200, 3), nrow = 3, ncol = 3, byrow = TRUE) mapview(reclassify(dem, nouvelles_classes2)) Filtrer en utilisant les coordonnées spatiales des cellules Une des opérations les plus fréquentes sur les raster est de filtrer les cellules en fonction de leurs coordonnées spatiales. Dans cette section nous allons apprendre à utiliser les fonctions crop() et mask() pour réaliser ces manipulations. Fonction crop() La fonction crop() vous permet de rogner un raster, autrement dit d’utiliser un rectangle pour filter les cellules selon qu’elles soient ou non à l’intérieur de ce dernier. Pour utiliser la fonction crop(), nous avons besoin de deux objets. Le premier objet est le raster à rogner et le second objet est le rectangle avec lequel le raster sera rogné. Ce rectangle est un objet de classe Extent (étendue en français). Un tel objet peut être créé en utilisant les coordonnées de ses coins inférieur-gauche (xmin, ymin) et supérieur-droit (xmax, ymax): ext &lt;- extent(c(-72, -71.5, 45.2, 45.8)) ext class : Extent xmin : -72 xmax : -71.5 ymin : 45.2 ymax : 45.8 Avec la fonction plot(), nous pouvons visualiser la partie du raster qui sera rognée. Notez que la fonction mapview() ne peut pas être utilisée pour visualiser des objets de classe Extent. plot(dem) plot(ext, add = TRUE) Il est très important de relever que de manière implicite les valeurs des coordonnées utilisées dans extent() sont exprimées dans le SCR de notre raster dem. Utilisons maintenant la fonction crop() dont le premier argument est le raster à rogner et le second argument est l’objet de classe Extent. dem_cr &lt;- crop(dem, ext) La sortie est un raster (que nous appelons dem_cr) qui est recadré selon ext. Les cellules qui ne sont pas dans ce rectangle sont exclues. mapview(dem_cr) La fonction crop() accepte en second argument, non seulement les objets de classe Extent, mais aussi tout objet à partir duquel un objet de classe Extent peut être extrait. Ceci signifie que le second argument peut aussi comprendre les objets spatiaux de classe RasterLayer et de classe sf. En guise d’exemple, nous allons maintenant rogner le raster dem en utilisant les limites du premier parc de la SÉPAQ identifié dans les données vectorielles parcs. Il est en effet possible d’extraire un objet de classe Extent à partir de ces données. Vérifions-le en utilisant la fonction extent(): extent(parcs[1,]) class : Extent xmin : -215252 xmax : -201928 ymin : 195972 ymax : 226160 Avant d’utiliser la fonction crop() nous avons besoin de re-projeter le raster dem dans le SCR des données vectorielles parcs (notez que nous pourrions aussi faire l’inverse). L’opération qui suit utilise de façon implicite l’étendue spatiale de parcs[1, ] pour rogner dem_lcc. dem_lcc &lt;- projectRaster(dem, crs = crs(parcs)) dem_cr_p &lt;- crop(dem_lcc, parcs[1, ]) mapview(dem_cr_p) Fonction mask() La fonction mask() permet de découper un raster avec un polygone de n’importe quelle forme et non uniquement selon un rectangle. Pour illustrer cette fonction nous allons d’abord créer un polygone avec la fonction st_as_sf() de la bibliothèque sf (voir le module 4) : # `mat` est une matrice 7x2 des coordonnées du polygone. mat &lt;- matrix(c( -72.5, 45.8, -72, 45.5, -72.5, 45.2, -71.5, 45.4, -71.7, 45.6, -71.5, 45.7, -72.5, 45.8), ncol = 2, byrow = TRUE) # nous transformons mat en un data frame puis en un objet de class `sf` pol &lt;- st_as_sf( data.frame( var = 1, geom = st_sfc(st_polygon(x = list(mat))) ), crs = st_crs(dem) ) Notons que nous avons utilisé le même SCR que dem. Regardons ce à quoi ressemble le polygone que nous venons de créer. mapview(dem)+mapview(pol) La fonction mask() permet de sélectionner uniquement les cellules du raster dem qui sont à l’intérieur du polygone pol (passé en second argument): dem_ma &lt;- mask(dem, pol) mapview(dem_ma) La fonction mask() est dotée d’un argument inverse qui, s’il prend la valeur TRUE, permet de sélectionner toutes les cellules d’un raster qui sont à l’extérieur du polygone fourni: dem_ma_inv &lt;- mask(dem, pol, inverse = TRUE) mapview(dem_ma_inv) La fonction mask() permet ainsi de filtrer les données matricielles de façon plus complexe qu’avec la fonction which(). En effet, les valeurs du raster dem_ma correspondent aux valeurs du sous-ensemble des cellules de dem qui sont à l’intérieur du polygone pol de forme complexe. Nous avons donc filtré spatialement les données de dem et nous avons assigné ce raster à la variable dem_ma que nous pouvons alors utiliser comme tout autre raster. summary(getValues(dem_ma)) Min. 1st Qu. Median Mean 3rd Qu. Max. 100 221 259 270 304 839 NA&#39;s 38445 Terminons cette section sur les opérations de filtre par trois remarques importantes: L’étendue du raster retourné par la fonction crop() sera différente de celle du raster initial (sauf si l’étendue initiale est utilisée pour rogner). À l’inverse, la fonction mask() préserve l’étendue spatiale. Vous pouvez en faire la vérification: extent(dem) class : Extent xmin : -72.72 xmax : -70.85 ymin : 45 ymax : 46.06 extent(dem_cr) class : Extent xmin : -72 xmax : -71.5 ymin : 45.2 ymax : 45.8 extent(dem_ma) class : Extent xmin : -72.72 xmax : -70.85 ymin : 45 ymax : 46.06 Le temps de calcul pour réaliser l’opération crop() est souvent très rapide, ce qui n’est pas le cas de l’opération mask() quand le polygone est complexe. Il est parfois possible d’avoir des gains d’efficacité en faisant appel à crop() avant d’utiliser mask(). Dans la situation où seules les valeurs des cellules filtrées nous intéresse, il est possible d’utiliser la fonction extract() plutôt que la fonction mask(). La fonction extract() de la bibliothèque raster retourne une liste pour laquelle chaque élément donne les valeurs des cellules extraites pour chaque couche du raster. Par exemple, le raster dem possède une seule couche, ainsi la liste retournée par la fonction extract() ne possède qu’un seul élément. Toutefois, cet élément est un vecteur de taille 6075 listant la valeur de chacune des cellules extraites. [1] 6075 Min. 1st Qu. Median Mean 3rd Qu. Max. 100 221 259 270 304 839 dem_ex &lt;- extract(dem, pol) length(dem_ex[[1]]) summary(dem_ex[[1]]) 8.1.2.3 Combiner des rasters Une opération qui peut s’avérer utile est celle de combiner des rasters, c’est-à-dire former un seul raster à partir de deux rasters ou plus. Par exemple, une telle opération pourrait être nécessaire si, pour une problématique donnée, nous devions combiner des rasters d’élévation de chaque région administrative du Québec pour obtenir un seul raster couvrant l’entièreté de la province. Fonction merge() La fonction merge() de la bibliothèque raster permet de combiner deux rasters ou plus. Cette fonction s’utilise différemment de la fonction générale merge() vue au module 7 pour combiner des data frame. En guise d’exemple, combinons les rasters dem_ma et dem_ma_inv créés plus haut en applicant la fonction mask() au raster dem : dem_merge &lt;- merge(dem_ma, dem_ma_inv) Notez que pour combiner des rasters avec la fonction merge() ceux-ci doivent avoir la même résolution et posséder le même système de coordonnées de référence (SCR). Il est possible que deux rasters que l’on souhaite combiner couvrent certaines régions communes. C’est-à-dire que certains pixels se superposent. Si la valeur des pixels se superposant diffère, la fonction merge() choisira la valeur que prend le pixel dans le raster donné en premier argument. Par exemple, créons un raster qui soit identique à dem_cr mais pour lequel tous les pixels ont une altitude 100 m plus grande : #Ajoutons 100m à tous les pixels de dem_cr dem_cr_plus &lt;- dem_cr + 100 Ensuite, combinons dem_cr_plus à dem_ma avec la fonction merge(). Le raster combiné prendra des valeurs différentes sur les pixels qui se superposent selon l’ordre des arguments : dem_merge_ordre1 &lt;- merge(dem_cr_plus, dem_ma) dem_merge_ordre2 &lt;- merge(dem_ma, dem_cr_plus) Fonction mosaic() La fonction mosaic() de la bibliothèque raster est similaire à merge() mais offre plus de flexibilité pour définir la valeur des pixels qui se chevauchent. En particulier, elle possède un troisième argument servant à préciser la fonction avec laquelle la valeur des pixels redondants est calculée. Par exemple, la fonction pourrait choisir la valeur la plus grande, la valeur la plus petite, ou encore la moyenne des valeurs. La fonction pourrait aussi être définie par l’usager et prendre une forme plus spécifique. dem_mosaic_min &lt;- mosaic(dem_cr_plus, dem_ma, fun = min) dem_mosaic_max &lt;- mosaic(dem_cr_plus, dem_ma, fun = max) dem_mosaic_mean &lt;- mosaic(dem_cr_plus, dem_ma, fun = mean) La fonction mosaic() requière également que les rasters utilisés possèdent la même résolution et le même SCR. Il existe des bibliothèques spécialisés qui offrent des fonctions plus avancées pour le traitement des pixels aux frontières des rasters qui se chevauchent (par exemple les bibliothèques landsat et satellite). L’utilisation de ces méthodes dépassent toutefois les objectifs de ce cours. 8.1.3 Problématique à résoudre Maintenant que nous avons appris les opérations de base pour manipuler les données matricielles, nous sommes en mesure de résoudre la problématique énoncée au début de cette leçon. Résolution de la question 1 Rappelons la première question : Parmi les quatre parcs nationaux de la région de Sherbrooke, lequel dispose du plus haut sommet? Les étapes de la démarche de résolution sont les suivantes: S’assurer que le raster d’élévation dem et les données vectorielles parcs sont dans le même SCR. Utiliser la fonction mask() pour extraire les cellules de dem qui sont dans les parcs nationaux considérés, Déterminer la valeur maximale d’élévation dans ce sous-ensemble de cellules extraites, Trouver les coordonnées spatiales associées à ce point de valeur d’élévation maximale. Déterminer dans quel parc se trouve les coordonnées spatiales du sommet le plus haut. Commençons! 1. Vérication des SRC Commençons par vérifier si les systèmes de coordonnées de référence (SCR) de dem et de parcs sont identiques: st_crs(dem) == st_crs(parcs) [1] FALSE Puisque les SCR diffèrent, nous allons re-projeter le raster dem en utilisant le SCR de parcs en utilisant la fonction projectRaster(). Nous avons déjà réalisé cette opération à la section précédente et nous reprenons donc ci-dessous la ligne de commande vue plus haut : dem_lcc &lt;- projectRaster(dem, crs = crs(parcs)) Pour les prochaines manipulations, nous utiliserons donc dem_lcc et parcs. 2. Filtrer le raster dem Nous cherchons ensuite à filtrer les cellules du raster d’élévation dem pour extraire celles situées à l’intérieur des limites de l’un ou de l’autre des quatre parcs nationaux considérés. Le shapefile parcs contient justement les polygones déliminant les quatre parcs. Nous pouvons donc appliquer la fonction mask() au raster dem en utilisant directement le shapefile parcs en second argument. dem_parcs &lt;- mask(dem_lcc, parcs) mapview(dem_parcs) Le raster dem_parcs obtenus par l’opération mask() possède la même étendue que le raster original dem_lcc mais ses valeurs diffèrent. Les cellules de dem_parcs prennent la valeur NA partout sauf à l’intérieur des quatre parcs nationaux où elles prennent alors la même valeur que la cellule correspondante dans dem_lcc. 3. Trouver l’élévation maximale Nous pouvons maintenant trouver la valeur d’élévation la plus élevée en utilisant la fonction getValues() suivi de la fonction max(). vmax &lt;- max(getValues(dem_parcs), na.rm = TRUE) vmax [1] 1083 Nous avons ainsi obtenu l’élévation maximale de ces parcs qui est de 1083 m. Nous cherchons alors les coordonnées spatiales associées à cette valeur. Nous pouvons faire appel à la fonction which() pour trouver l’indice de la cellule (ou les indices des cellules, si il y en a plusieurs) en question. ind_max &lt;- which(getValues(dem_parcs) == max(getValues(dem_parcs), na.rm = TRUE)) ind_max [1] 31561 Notons qu’il existe une fonction pour identifier le maximum, which.max(), qui réalise la même opération mais requière une syntaxe un peu plus simple. which.max(getValues(dem_parcs)) [1] 31561 4. Déterminer les coordonnées du plus haut sommet Pour déterminer les coordonnées de la cellule identifiée nous utilisons l’indice ind_max et la fonction as.data.frame() avec xy = TRUE et centroid = TRUE comme vu au module 5 : df_max &lt;- as.data.frame(dem_parcs[ind_max, drop = FALSE], xy = TRUE, centroid = TRUE, na.rm = TRUE) df_max x y layer 1 -207329 165880 1083 Deux remarques méritent d’être mentionnées concernant cette opération : L’argument drop = FALSE permet d’éviter que R ne convertisse dem_parcs[ind_max, ] en un vecteur, c’est important car nous voulons conserver sa forme matricielle. na.rm = TRUE permet d’ignorer toutes les valeurs masquées, comme nous l’avons dans d’autres fonctions (e.g. mean()). v. Déterminer le parc possédant le point d’élévation maximale Une fois isolées, les coordonnées x et y du pixel d’élévation maximale peuvent être utilisées pour créer un objet spatial de classe sf contenant le centroïde de ce pixel grâce à la fonction st_as_sf(). Nous nous servirons par la suite de ce point pour visualiser sa position et déterminer dans quel parc national il est situé. sf_point_max &lt;- st_as_sf(df_max, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_parcs)) sf_point_max Simple feature collection with 1 feature and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -207300 ymin: 165900 xmax: -207300 ymax: 165900 Projected CRS: NAD83 / Quebec Lambert layer geometry 1 1083 POINT (-207329 165880) Remarquez que nous avons attribué à ce point le même SRC que celui du raster dem_parcs(). En superposant, avec mapview(), les trois couches d’informations spatiales que nous venons de manipuler, nous pouvons repérer le parc dans lequel se trouve ce point d’élévation maximale. map_point &lt;- mapview(dem_parcs) + mapview(parcs, alpha = 0.01) + mapview(sf_point_max, col.regions = &quot;red&quot;) map_point@map Figure 8.1: En cliquant sur le polygone du parc contenant le point rouge (point d’élévation maximal), il est possible de constater que le point se retrouve dans le Parc national du Mont-Mégantic Nous constatons que ce point est situé dans le Parc national du Mont-Mégantic. Au lieu de déduire sa localisation de manière visuelle, nous allons à présent réaliser une opération topologique pour isoler le polygone du parc abritant ce plus haut sommet. Pour ce faire, nous utilisons la fonction st_intersects() étudiée au module 7. Rappelons que cette fonction retourne la valeur TRUE lorsque deux objets vectoriels se recoupent et FALSE autrement. st_intersects(parcs, sf_point_max, sparse = FALSE) [,1] [1,] FALSE [2,] TRUE [3,] FALSE [4,] FALSE Nous utilisons ensuite ce vecteur logique pour identifier le parc auquel ce sommet appartient. Notez que le nom des parcs est donné par l’attribut TRQ_NM_. parcs[st_intersects(parcs, sf_point_max, sparse = FALSE), ]$TRQ_NM_ [1] &quot;Parc national du Mont-Mégantic&quot; Cette opération peut être écrite plus simplement sous la forme: parcs[sf_point_max, ]$TRQ_NM_ [1] &quot;Parc national du Mont-Mégantic&quot; Cette dernière manipulation nous permet de répondre à notre première question: parmi les quatre parcs nationaux sélectionnés, c’est le Parc national du Mont-Mégantic qui a le plus haut sommet, sommet qui culmine à 1083 m d’altitude! Résolution de la question 2 Nous allons maintenant répondre à la deuxième question de notre problématique: Quelle est le profil topographique du sentier se rendant au plus proche de ce sommet? Nous allons nous placer dans la situation suivante : nous désirons faire une randonnée pédestre jusqu’au sommet que nous venons d’identifier (à tout le moins, le plus proche possible de ce sommet). Afin de nous faire une idée précise de l’effort physique que nous devrons fournir lors de cette randonnée, nous allons réaliser un profil topographique du sentier se rendant au plus proche de ce sommet. La figure 8.2 donne un exemple de profil topographique pour le sentier de la grande traversée dans le Parc national de la Gaspésie. Figure 8.2: Exemple de profil topographique: le sentier international des Appalaches taille réelle Voici les étapes que nous allons suivre en vue de répondre à la question posée: Créer un shapefile du Parc national du Mont-Mégantic, parc_megantic, à partir de parcs. Importer les données des sentiers estivaux de la SEPAQ et des données d’élévation plus précises. S’assurer que les nouveaux objets importés et parc_megantic ont le même SCR. Isoler les sentiers estivaux du Parc national du Mont-Mégantic. Trouver le chemin le plus proche du sommet identifié à la question 1. Extraire les cellules d’élévation de dem_lcc sur ce sentier. Réaliser un profile d’élévation. Commençons! 1. Créer un shapefile du Parc national du Mont-Mégantic Puisque le profil topographique que nous désirons créer se situe à l’intérieur du Parc national du Mont-Mégantic, isolons le polygone constituant ce parc à partir du shapefile parcs regroupant les quatre parcs. Rappelons que le Parc national du Mont-Mégantic est celui qui possède le plus haut sommet. En nous basant sur les commandes réalisées plus haut, nous pouvons définir le shapefile parc_megantic de la façon suivante: parc_megantic &lt;- parcs[st_intersects(parcs, sf_point_max, sparse = FALSE), ] # Ou plus simplement: # parc_megantic &lt;- parcs[sf_point_max, ] 2. Importer les données Maintenant importons les données vectorielles pour tous les sentiers de la SEPAQ. Ce shapefile se trouve dans le dossier Module8_donnees que vous avez téléchargé au début de la leçon : sentiers &lt;- st_read(&quot;Module8/Module8_donnees/sentiers_sepaq/Sentier_ete_l.shp&quot;) Reading layer `Sentier_ete_l&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module8/Module8_donnees/sentiers_sepaq/Sentier_ete_l.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 3606 features and 22 fields Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: -822400 ymin: 150300 xmax: 437600 ymax: 689800 Projected CRS: NAD83 / Quebec Lambert mapview(sentiers) Notre objectif est de savoir comment l’élévation varie le long du sentier qui conduit le plus près possible du plus haut sommet. Ainsi, en plus des données sur la localisation des sentiers, nous avons besoin des données d’élévation. Or, au lieu d’utiliser le raster dem_lcc dont la résolution spatiale est de 521 par 741 m2, nous allons nous procurer une autre couche d’élévation de résolution plus fine afin d’obtenir un profil topologique plus précis. Pour ce faire, nous utiliserons la fonction get_elev_raster() de la bibliothèque elevatr. Cette fonction permet d’accéder aux données d’élévation disponibles sur le service d’infonuagique d’Amazon (AWS) et cela à différents niveaux de résolution. La fonction get_elev_raster() requière deux arguments. Le premier argument spécifie la localisation des données recherchées. Dans notre cas, la localisation est définie le polygone parc_megantic. Le deuxième argument spécifie le niveau de résolution des données recherchées, c’est-à-dire le zoom, une valeur allant de z = 1 à z = 14. # install.packages(&quot;elevatr&quot;) # install.packages(&quot;progress&quot;) #Installer aussi! library(elevatr) elv_megantic &lt;- get_elev_raster(parc_megantic, z = 13) Nous avons ainsi obtenu le raster d’élévation elv_megantic pour le Parc national du Mont-Mégantic. La résolution spatiale de cette couche est plus fine que celle de la couche dem_lcc : res(elv_megantic) [1] 3.353 3.353 Ce qui correspond à environ 3.4 par 3.4 m2. 3. Vérication des SRC Vérifions ensuite que les SCR utilisés pour répondre à la question 2 sont tous identiques en utilisant la fonction st_crs() : st_crs(sentiers) == st_crs(parc_megantic) [1] TRUE st_crs(elv_megantic) == st_crs(parc_megantic) [1] TRUE Puisque c’est le cas, aucune transformation de SRC n’est nécessaire et nous pouvons poursuivre la résolution de notre problème. 4. Isoler les sentiers estivaux du Parc national du Mont-Mégantic À présent, nous allons isoler les sentiers du parc du Mont-Mégantic qui se trouvent dans sentiers. Commençons par inspecter la table des attributs : head(sentiers) Simple feature collection with 6 features and 22 fields Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: 391200 ymin: 610200 xmax: 437600 ymax: 645500 Projected CRS: NAD83 / Quebec Lambert No_etab Code_etab No_reseau Code_res Reseau 1 15 PAN 2 PQ Parc national 2 15 PAN 2 PQ Parc national 3 15 PAN 2 PQ Parc national 4 15 PAN 2 PQ Parc national 5 15 PAN 2 PQ Parc national 6 15 PAN 2 PQ Parc national Nom_etab Maj Source Usager Etat 1 Anticosti 2011-02 n/a Pédestre Existant 2 Anticosti 2011-02 n/a Pédestre Existant 3 Anticosti 2011-02 n/a Pédestre Existant 4 Anticosti 2011-02 n/a Pédestre Existant 5 Anticosti 2011-02 n/a Pédestre Existant 6 Anticosti 2011-02 n/a Pédestre Existant Toponyme1 Toponyme2 Toponyme3 1 Le Canyon-de-la-Chicotte &lt;NA&gt; &lt;NA&gt; 2 Lac-Baie-de-la-Tour &lt;NA&gt; &lt;NA&gt; 3 Les Télégraphes &lt;NA&gt; &lt;NA&gt; 4 Le Garde-Feu &lt;NA&gt; &lt;NA&gt; 5 La Grotte-à-la-Patate &lt;NA&gt; &lt;NA&gt; 6 Observation-la-Mer &lt;NA&gt; &lt;NA&gt; Toponyme4 Niv_diff Secteur Usager_2 Toponyme5 1 &lt;NA&gt; Intermédiaire &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 2 &lt;NA&gt; Intermédiaire &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3 &lt;NA&gt; Intermédiaire &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 4 &lt;NA&gt; Facile &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 5 &lt;NA&gt; Intermédiaire &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 6 &lt;NA&gt; Facile &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; Toponyme6 Usager_3 Usager_4 Shape_Leng 1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 6647.8 2 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 601.4 3 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3051.5 4 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 2499.2 5 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1548.7 6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1973.8 geometry 1 MULTILINESTRING ((393116 61... 2 MULTILINESTRING ((435372 63... 3 MULTILINESTRING ((436291 63... 4 MULTILINESTRING ((396510 61... 5 MULTILINESTRING ((398004 64... 6 MULTILINESTRING ((409244 64... La colonne Nom_etab contient le non des parcs que nous pouvons lister rapidement avec la fonction unique() qui enlève les doublons. unique(sentiers$Nom_etab) [1] &quot;Anticosti&quot; [2] &quot;Duchesnay&quot; [3] &quot;Lac-Simon&quot; [4] &quot;Aiguebelle&quot; [5] &quot;Bic&quot; [6] &quot;Île-Bonaventure-et-Rocher-Percé&quot; [7] &quot;Îles-de-Boucherville&quot; [8] &quot;Frontenac&quot; [9] &quot;Gaspésie&quot; [10] &quot;Grands-Jardins&quot; [11] &quot;Hautes-Gorges-de-la-Rivière-Malbaie&quot; [12] &quot;Jacques-Cartier&quot; [13] &quot;Miguasha&quot; [14] &quot;Mont-Mégantic&quot; [15] &quot;Mont-Orford&quot; [16] &quot;Mont-Tremblant&quot; [17] &quot;Mont-Saint-Bruno&quot; [18] &quot;Monts-Valin&quot; [19] &quot;Oka&quot; [20] &quot;Plaisance&quot; [21] &quot;Pointe-Taillon&quot; [22] &quot;Fjord-du-Saguenay&quot; [23] &quot;Lac-Témiscouata&quot; [24] &quot;Yamaska&quot; [25] &quot;Saguenay-Saint-Laurent&quot; [26] &quot;Opémican&quot; [27] &quot;Ashuapmushuan&quot; [28] &quot;Chic-Chocs&quot; [29] &quot;Laurentides&quot; [30] &quot;La Vérendrye, Secteur Outaouais&quot; [31] &quot;La Vérendrye, Secteur Abitibi&quot; [32] &quot;Mastigouche&quot; [33] &quot;Matane&quot; [34] &quot;Auberge de Montagne des Chic-Chocs&quot; [35] &quot;Papineau-Labelle&quot; [36] &quot;Port-Daniel&quot; [37] &quot;Portneuf&quot; [38] &quot;Rouge-Matawin&quot; [39] &quot;Port-Cartier-Sept-Îles&quot; [40] &quot;Saint-Maurice&quot; Nous observons que le Parc national du Mont-Mégantic est identifié par le nom “Mont-Mégantic”. Pour isoler ses sentiers nous pouvons procéder de deux façons. La première façon consiste à utiliser la fonction subset() (vue au module 7) pour filtrer le shapefile sentiers et sélectionner seulement les sentiers pour lesquels l’attribut Nom_etab prend la valeur “Mont-Mégantic”: sentiers_megantic &lt;- subset(sentiers, Nom_etab == &quot;Mont-Mégantic&quot;) La deuxième façon est d’utiliser un filtre spatial avec les limites du Parc national du Mont-Mégantic contenues dans parc_megantic : sentiers_megantic &lt;- sentiers[parc_megantic, ] mapview(sentiers_megantic) Nous avons ainsi obtenu, quelle que soit la méthode choisie, un objet vectoriel, sentiers_megantic, qui contient les sentiers du Parc national du Mont-Mégantic. 5. Trouver le sentier le plus proche du sommet le plus haut Nous allons maintenant utiliser la fonction st_nearest_feature() de la bibliothèque sf pour déterminer quel sentier (LINES) se trouve le plus proche du sommet (POINT). Notez qu’en anglais “near” signifie proche et “feature” signifie éléments ou plus précisément une entité spatiale (aussi appelée une géométrie) dans le présent contexte. La fonction st_nearest_feature(x,y) comprend deux arguments x et y et retourne l’indice de l’entité spatiale dans y qui est le plus près de l’entité x. id_nearest &lt;- st_nearest_feature(sf_point_max, sentiers_megantic) id_nearest [1] 6 Nous pouvons ainsi trouver le sentier recherché à partir de l’indice que nous venons d’identifier. sentier_top &lt;- sentiers_megantic[id_nearest, ] sentier_top Simple feature collection with 1 feature and 22 fields Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: -207500 ymin: 165100 xmax: -206500 ymax: 166000 Projected CRS: NAD83 / Quebec Lambert No_etab Code_etab No_reseau Code_res 1251 12 MME 2 PQ Reseau Nom_etab Maj Source 1251 Parc national Mont-Mégantic 2010-08 GPS Usager Etat Toponyme1 1251 Pédestre Existant Sentier du Mont-Mégantic Toponyme2 Toponyme3 Toponyme4 Niv_diff 1251 Les Trois-Sommets &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; Secteur Usager_2 Toponyme5 1251 Secteur de l&#39;Observatoire &lt;NA&gt; &lt;NA&gt; Toponyme6 Usager_3 Usager_4 Shape_Leng 1251 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1456 geometry 1251 MULTILINESTRING ((-207526 1... Observez que la géométrie de cette entité spatiale est une multiligne (MULTILINESTRING). Notons que nous aurions pu faire la même opération directement sur l’objet sentiers, c’est-à-dire par la commande suivante: sentiers[st_nearest_feature(sf_point_max, sentiers),] Regardons où ce sentier se situe par rapport aux autres sentiers du parc : mapview(sentiers_megantic) + mapview(sentier_top, color=&quot;red&quot;) Nous observons que ce sentier n’est en fait qu’une petite portion du parcours qu’un.e randonneur.se devra faire pour se rendre le plus près possible du plus haut sommet. Or, nous voulons le sentier complet à parcourir depuis le pied de la montagne. L’attribut Toponyme1 nous donne justement le nom du sentier (Sentier du Mont-Mégantic) auquel appartient la section sentier_top que nous venons d’identifier. Revenons maintenant au shapefile sentiers_megantic pour y extraire toutes les autres portions du sentier nommé “Sentier du Mont-Mégantic” qui ensemble formeront la randonnée complète. Pour ce faire nous utilisons la fonction subset() : rando_sections &lt;- subset(sentiers_megantic, Toponyme1 == &quot;Sentier du Mont-Mégantic&quot;) Visualisons ensuite ces différentes portions en les colorant selon un identifiant id : rando_sections$id &lt;- 1:5 mapview(rando_sections, zcol = &quot;id&quot;) Changeons l’ordre des portions afin qu’elles suivent l’ordre selon lequel elles seront parcourues à partir du sommet jusqu’au pied de la montagne (c’est-à-dire de 1 à 5 plutôt que 5,1,2,3,4) : rando_sections &lt;- rando_sections[c(5, 1:4),] rando_sections$id &lt;-1:5 mapview(rando_sections, zcol = &quot;id&quot;) Combinons maintenant ces cinq portions en une seule entité spatiale (MULTILINESTRING) en utilisant la fonction st_combine() de la bibliothèque sftelle que vue au module 7 : rando &lt;- st_combine(rando_sections) rando Geometry set for 1 feature Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: -207700 ymin: 163500 xmax: -206200 ymax: 166100 Projected CRS: NAD83 / Quebec Lambert MULTILINESTRING ((-207664 166072, -207663 16607... Observez que nous avons effectivement une seule entité spatiale. 6. Extraire les cellules d’élévation le long du sentier Pour faire le profil topographique du sentier rando, nous devons extraire des données d’élévation du parc (elv_megantic) celles qui se trouvent le long du sentier. Pour ce faire nous allons utiliser la fonction extract() de la bibliothèque raster comme suit. topo_elv &lt;- extract(elv_megantic, st_as_sf(rando), along = TRUE, cellnumbers = TRUE) Notons que cette opération peut prendre plusieurs secondes pour être complétée par votre ordinateur. Trois remarques méritent d’être mentionnées concernant cette opération : Nous avons besoin de convertir rando qui est de classe sfc en objet de classe sf pour l’utiliser avec extract(), ce que nous faisons avec st_as_sf(). along = TRUE permet d’obtenir les cellules ordonnées le long des lignes de rando_sections. cellnumbers = TRUE nous permet d’avoir les indices des cellules extraites. Comme vu un peu plus haut, la fonction extract() retourne une liste. Ainsi, topo_elv est un objet de classe list, mais cette fois le premier élément est une matrice avec deux colonnes: la première colonne contient les identifiants des cellules, et la seconde, les valeurs d’élévation (précédemment, le résultat de extract() était simplement un vecteur avec des valeurs d’élévation). Nous pouvons confirmer ces propos par les commandes suivantes : class(topo_elv) #topo_elv est un objet de classe &quot;list&quot; [1] &quot;list&quot; length(topo_elv) #cette liste comprend une seule entrée [1] 1 dim(topo_elv[[1]]) #La première entrée de la liste est une matrice de 876 lignes et de 2 colonnes. [1] 1603 2 Attribuons des noms à chacune des colonnes de la matrice contenue dans la première entrée de la liste topo_elv  colnames(topo_elv[[1]]) &lt;- c(&quot;cellule_id&quot;, &quot;elevation&quot;) head(topo_elv[[1]]) cellule_id elevation v 3971831 1099 3971831 1099 3975080 1099 3975081 1099 3978330 1099 3981579 1099 Nous avons donc toutes les valeurs d’élévation le long du sentier. 7. Obtenir le profil topographique Rappelons qu’un profil topographique est une représentation graphique du relief qui affiche l’élévation à chaque point le long d’un sentier (voir la figure 8.2). L’abscisse d’un tel graphique (c’est-à-dire l’axe des x) correspond à la distance parcourue depuis le début de la randonnée (par exemple de 0 à 100 km) et l’ordonnée (c’est-à-dire l’axe des y) correspond à l’élévation. Maintenant que nous avons l’élévation pour chaque point le long du sentier (topo_elv), nous devons déterminer la distance parcourue depuis le début du trajet jusqu’à chaque point le long de ce sentier. Tout d’abord, nous devons calculer la distance parcourue entre chaque paires de points qui se suivent le long du sentier. Pour ce faire, nous utiliserons la fonction st_distance() vue au module 7. Or, cette fonction ne peut être utilisée que sur un objet spatial, et comme nous venons de le constater topo_elv est un objet de classe list. Nous devons donc transformer topo_elv en objet spatial avec la fonction st_as_sf(). De plus, un objet spatial doit être défini par des coordonnées spatiales. Pour l’instant, les cellules formant le sentier dans topo_elv sont identifiées par leur indice et non par leurs coordonnées. Une étape préliminaire est donc nécessaire pour retrouver les coordonnées spatiales correspondant à chaque indice. Cela est possible grâce à la fonction xyFromCell() de la bibliothèque raster qui retourne les coordonnées spatiales associées à chaque indice dans le raster à partir duquel nous avons extrait topo_elv, c’est-à-dire elv_megantic. df_pts &lt;- as.data.frame(xyFromCell(elv_megantic, topo_elv[[1]][, 1])) head(df_pts) x y 1 -207662 166072 2 -207662 166072 3 -207662 166069 4 -207659 166069 5 -207659 166066 6 -207659 166062 Nous avons mis les coordonnées spatiales dans le tableau df_pts de type data.frame. Notez que l’argument topo_elv[[1]][, 1] correspond aux indices des cellules (c’est la première colonne de la première entrée de la liste topo_elv). Nous pouvons ensuite utiliser la fonction st_as_sf() pour transformer df_pts en objet de classe sf : topo_pts &lt;- st_as_sf(df_pts, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(sentiers_megantic) ) Remarquez que nous avons également attribué un SCR au nouvel objet spatial topo_pts. Nous pouvons finalement utiliser la fonction st_distance() pour calculer les distances entre points successifs de topo_pts. La fonction st_distance(x,y) nécessite obligatoirement deux objets spatiaux (x et y) en argument. Elle calcule alors la distance entre chaque paire d’éléments de x et de y, qu’elle retourne sous forme de matrice. Par exemple, l’opération suivante calcule la distance entre toutes les paires de points compris dans topo_pts : dist_tout &lt;- st_distance(topo_pts,topo_pts) dist_tout[1:5,1:5] Units: [m] [,1] [,2] [,3] [,4] [,5] [1,] 0.000 0.000 3.353 4.742 7.498 [2,] 0.000 0.000 3.353 4.742 7.498 [3,] 3.353 3.353 0.000 3.353 4.742 [4,] 4.742 4.742 3.353 0.000 3.353 [5,] 7.498 7.498 4.742 3.353 0.000 L’élément dist_tout[1,1] est la distance entre le premier point de topo_pts et lui-même (donc zéro), l’élément dist_tout[1,2] est la distance entre le premier et le deuxième points de topo_pts (auss zéro car ces deux points sont probablement très rapprochés), dist_tout[1,3] entre le premier et le troisième points de topo_pts, et ainsi de suite pour tous les points de topo_pts. La fonction st_distance() s’utilise aussi avec l’argument by_element = TRUE. Dans ce cas, la fonction retourne un vecteur dont le premier élément correspond à la distance entre le premier élément de x et le premier élément de y; le deuxième élément, à la distance entre le deuxième élément de x et le deuxième élément de y, et ainsi de suite. Par exemple, l’opération suivante : dist0 &lt;- st_distance(topo_pts,topo_pts,by_element = TRUE) dist0[1:5] Units: [m] [1] 0 0 0 0 0 retourne un vecteur nul puisque chaque élément correspond à la distance entre un point et lui-même. Pour répondre à notre question, nous devons calculer la distance entre des points successifs de topo_pts (c’est-à-dire la distance entre le premier et le deuxième point, entre le deuxième et le troisième point, entre le troisième et le quatrième point, etc.). Il s’agit de calculer la distance pour des paires de points formés entre topo_pts et une version de topo_pts qui est décalée d’un élément. Nous utilisons donc la fonction st_distance() avec comme premier argument topo_pts sans le premier point, et comme deuxième argument topo_pts aussi mais cette fois sans le dernier point: dist_pts &lt;- st_distance(topo_pts[-1, ], topo_pts[-nrow(topo_pts),], by_element = TRUE) Nous pouvons maintenant calculer la distance parcourue à chaque point le long du sentier depuis le début de la randonnée. Pour ce faire nous utilisons la fonction cumsum() qui calcule la somme cumulée des distances entre chaque point : dist_parcourue &lt;- cumsum(dist_pts) Nous pouvons finalement visualiser l’élévation (la deuxième colonne de topo_elv[[1]][, 2]) en fonction de la somme cumulée des distances, dist_parcourue. Remarquons que le vecteur dist_parcourue comprend un élément de moins que le vecteur topo_elv[[1]][, 2]. Ceci s’explique par le fait que dist_pts, à partir duquel nous calculons dist_parcourue, mesure la distance entre les points (c’est à dire des intervalles). Par conséquent, nous ajoutons la distance initiale de 0 m au vecteur des distances parcourues. plot(c(0, dist_parcourue), topo_elv[[1]][, 2], main = &quot;Profil topographique du Sentier du Mont-Mégantic&quot;, xlab = &quot;Distance depuis le sommet (en mètre)&quot;, ylab = &quot;Altitude (en mètre)&quot;, type = &quot;l&quot;, # pour utiliser une ligne lwd = 2 # augmente le trait de la ligne ) Et voilà qui complète la réalisation du profil topographique du sentier menant le plus près du sommet le plus haut. "],["ex_mat_manip.html", "8.2 Exercices", " 8.2 Exercices Dans cette section, vous mettrez en pratique certains concepts vus dans la section leçon de ce module. Bien que la réponse à chaque question soit disponible, il est très important de tenter d’y répondre par vous même! Question 1 Identifier le point d’élévation maximale sur une carte du parc du Mont-Orford. Réponse Isoler le polygone du parc du Mont-Orford du shapefile parcs en utilisant la fonction subset: parc_orford &lt;- subset(parcs, TRQ_NM_== &quot;Parc national du Mont-Orford&quot;) Filtrer le raster dem_lcc pour ne retenir que les cellules situées à l’intérieure du polygone délimitant les limites du parc du Mont-Orford dem_orford &lt;- mask(dem_lcc, parc_orford) mapview(dem_orford) Déterminer l’indice de la cellule ou des cellules d’élévation maximale en utilisant les fonctions getValues() et which.max(). imax_orford&lt;-which.max(getValues(dem_orford)) Trouver les coordonnées correspondant à cet indice en utilisant la fonction xyFromCell. coordmax_orford &lt;- xyFromCell(dem_orford,imax_orford) coordmax_orford x y [1,] -293815 154024 Transformer ces coordonnées en une donnée vectorielle de type POINT en utilisant la fonction st_as_sf(). #Créer d&#39;abord un data.frame à partir de coordmax_orford coordmax_orford_df &lt;- as.data.frame(coordmax_orford) #ou simplement data.frame(coordmax_orford) #Créer un point pt_max_orford &lt;- st_as_sf(coordmax_orford_df, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_orford)) #attribuer le même SCR Visualiser la carte du parc du Mont-Orford ainsi que le point d’élévalion maximale. mapview(dem_orford) + mapview(pt_max_orford, col.regions=&quot;red&quot;) Question 2 Reclassifier le raster dem_orford selon quatre classes correspondant aux valeurs comprises entre le zéro et le \\(1^{er}\\) quantile, le \\(1^{er}\\) et le \\(2^{ième}\\), le \\(2^{ième}\\) et \\(3^{ième}\\), et le \\(3^{ième}\\) et \\(4^{ième}\\). Réponse Trouver d’abord les quantiles des valeurs d’élévation dans le parc du Mont-Orford. quantile_orford &lt;- quantile(getValues(dem_orford), na.rm = TRUE) quantile_orford 0% 25% 50% 75% 100% 270.1 338.6 394.2 536.6 816.6 q_25 &lt;- as.numeric(quantile_orford[&quot;25%&quot;]) # as.numeric pour conserver seulement les chiffres q_50 &lt;- as.numeric(quantile_orford[&quot;50%&quot;]) q_75 &lt;- as.numeric(quantile_orford[&quot;75%&quot;]) q_100 &lt;- as.numeric(quantile_orford[&quot;100%&quot;]) En se servant de ces valeurs, construire une matrice qui détermine la nouvelle classification. classes_orford &lt;- matrix(c(0, q_25, 1, #1ere classe q_25, q_50, 2, #2e classe q_50, q_75, 3, #3e classe q_75, q_100, 4), #4e classe nrow = 4, ncol = 3, byrow = TRUE) # donner des titres aux colonnes de cette matrice colnames(classes_orford) &lt;- c(&quot;Limite_min&quot;, &quot;Limite_max&quot;, &quot;Classement_quantile&quot;) Utiliser la fonction reclassify() pour assigner les nouvelles classes au raster dem_orford. dem_orford_quantile &lt;- reclassify(dem_orford, classes_orford, rigth = FALSE) Confirmer visuellement la reclassification en utilisant la fonction mapview() mapview(dem_orford_quantile) Noter que nous aurions pu vouloir attribuer une nouvelle classification de type catégorique au raster dem_orford. Par exemple, Categorie_elevation &lt;- c(&quot;Faible&quot;, &quot;Intermediare&quot;, &quot;Forte&quot;, &quot;Très forte&quot;) # Ou encore Categorie_quantile &lt;- c(&quot;[0%, 25%[&quot;, &quot;[25%, 50%[&quot;, &quot;[50%, 75%[&quot;, &quot;[75%, 100%]&quot;) Dans ce cas, il faut ajouter ces catégories au raster dem_orford en utilisant la fonction levels(). levels(dem_orford_quantile) &lt;- data.frame(ID=1:4, quantile = Categorie_quantile) dem_orford_quantile class : RasterLayer dimensions : 178, 304, 54112 (nrow, ncol, ncell) resolution : 521, 741 (x, y) extent : -336797, -178413, 110676, 242574 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs source : memory names : DEM values : 1, 4 (min, max) attributes : ID quantile 1 [0%, 25%[ 2 [25%, 50%[ 3 [50%, 75%[ 4 [75%, 100%] La classification est maintenant traitée comme une variable catégorique. mapview(dem_orford_quantile) Question 3 À partir du raster dem_lcc, créer un seul raster composé de zones tampons circulaires, de 10 km de rayon, autour des points d’élévation maximale de chaque parc national de la région de Sherbrooke. Réponse Répéter les étapes de la Question 1 pour créer un shapefile correspondant au point d’élévation maximale de chaque parc. Pour le Parc du Mont-Orford: # Isoler les limites du parc parc_orford &lt;- subset(parcs, TRQ_NM_== &quot;Parc national du Mont-Orford&quot;) # Trouver dem à l&#39;intérieur du parc dem_orford &lt;- mask(dem_lcc, parc_orford) # Trouver l&#39;indice de la cellule d&#39;élévation maximale imax_orford&lt;-which.max(getValues(dem_orford)) # Trouver les coordonnées de cette cellule coordmax_orford &lt;- xyFromCell(dem_orford,imax_orford) # Transformer en data.frame coordmax_orford_df &lt;- as.data.frame(coordmax_orford) # Transformer en point pt_max_orford &lt;- st_as_sf(coordmax_orford_df, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_orford)) #attribuer le même SCR Pour le Parc national du Mont-Mégantic: parc_megantic &lt;- subset(parcs, TRQ_NM_== &quot;Parc national du Mont-Mégantic&quot;) dem_megantic &lt;- mask(dem_lcc, parc_megantic) imax_megantic &lt;- which.max(getValues(dem_megantic)) coordmax_megantic &lt;- xyFromCell(dem_megantic,imax_megantic) coordmax_megantic_df &lt;- as.data.frame(coordmax_megantic) pt_max_megantic &lt;- st_as_sf(coordmax_megantic_df, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_orford)) Pour le Parc national de la Yamaska: parc_yamaska &lt;- subset(parcs, TRQ_NM_== &quot;Parc national de la Yamaska&quot;) dem_yamaska &lt;- mask(dem_lcc, parc_yamaska) imax_yamaska &lt;- which.max(getValues(dem_yamaska)) coordmax_yamaska &lt;- xyFromCell(dem_yamaska,imax_yamaska) coordmax_yamaska_df &lt;- as.data.frame(coordmax_yamaska) pt_max_yamaska &lt;- st_as_sf(coordmax_yamaska_df, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_orford)) Pour le Parc national de Frontenac: parc_frontenac &lt;- subset(parcs, TRQ_NM_== &quot;Parc national de Frontenac&quot;) dem_frontenac &lt;- mask(dem_lcc, parc_frontenac) imax_frontenac &lt;- which.max(getValues(dem_frontenac)) coordmax_frontenac &lt;- xyFromCell(dem_frontenac,imax_frontenac) coordmax_frontenac_df &lt;- as.data.frame(coordmax_frontenac) pt_max_frontenac &lt;- st_as_sf(coordmax_frontenac_df, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_orford)) Confirmer vos calculs en visualisant les points trouvés. mapview(pt_max_orford, col.regions = &quot;red&quot;) + mapview(pt_max_megantic, col.regions = &quot;blue&quot;) + mapview(pt_max_yamaska, col.regions = &quot;green&quot;) + mapview(pt_max_frontenac, col.regions = &quot;yellow&quot;) m &lt;- mapview(pt_max_orford, col.regions = &quot;red&quot;) + mapview(pt_max_megantic, col.regions = &quot;blue&quot;) + mapview(pt_max_yamaska, col.regions = &quot;green&quot;) + mapview(pt_max_frontenac, col.regions = &quot;yellow&quot;) m@map Calculer une zone tampon de 10 km de rayon autour de chaque point en utilisant la fonction st_buffer(). tampon_orford &lt;- st_buffer(pt_max_orford, dist = 10e3) #nous savons que le CRS est d&#39;unité métrique tampon_megantic &lt;- st_buffer(pt_max_megantic, dist = 10e3) tampon_yamaska &lt;- st_buffer(pt_max_yamaska, dist = 10e3) tampon_frontenac &lt;- st_buffer(pt_max_frontenac, dist = 10e3) Filtrer le raster dem_lcc pour ne retenir que les cellules comprises à l’intérieur des zones tampons grâce à la fonction mask(). dem_tampon_orford &lt;- mask(dem_lcc, tampon_orford) dem_tampon_megantic &lt;- mask(dem_lcc, tampon_megantic) dem_tampon_yasmaka &lt;- mask(dem_lcc, tampon_yamaska) dem_tampon_frontenac &lt;- mask(dem_lcc, tampon_frontenac) Combiner les quatre raster en un seul en utilisant la fonction merge() dem_tampon_max &lt;- merge(dem_tampon_orford, merge(dem_tampon_megantic, merge(dem_tampon_yasmaka, dem_tampon_frontenac))) Noter que la fonction merge() s’utilise sur deux rasters à la fois. Il faut donc l’appliquer successivement pour combiner quatre rasters. Visualiser le raster final contenant les quatre zones tampons: mapview(dem_tampon_max) "],["spatiotemp.html", "Module 9 Données spatiotemporelles", " Module 9 Données spatiotemporelles Manipuler le temps (les dates, les heures, les secondes, etc.) représente une compétence indispensable en science des données. Les données spatiales peuvent elles aussi être indexées sur le temps, c’est-à-dire se faire attribuer un indice de classification (une «coordonnée») temporelle. On parle alors de données spatio-temporelles qui sont donc des données doublement indexées : indexées sur le temps et indexées sur l’espace. L’objectif principal de ce module est justement de manipuler ce type de données, des séries de vecteurs temporellement ordonnées, et cela pour différentes échelles temporelles. À la fin de ce module vous saurez: Manipuler le temps et les dates. Créer des animations simples qui montre l’évolution de données spatialisées dans le temps. Utiliser les objets de classe rasterStack. Écrire des fonctions simples et les utiliser pour structurer vos codes d’analyse R. Vous utiliserez les bibliothèques suivantes: mapview raster sf lubridate animation Vous apprendrez à utiliser les fonctions suivantes: hist() sort(), table() st_length() stopifnot st_cast() stack() calc() getZ(), setZ() as_date_time(), ym(), hour(), minute(), second() saveGIF() Et vous apprendrez aussi à créer vos propres fonctions avec function(). Vous utiliserez les données suivantes: Dans la section Leçon, vous utiliserez des données vectorielles de trajets de vélo dans la ville de Montréal ainsi que des données matricielles de températures et de précipitations dans le Parc national du Mont-Mégantic. Dans la section Exercices, vous mettrez en pratique les manipulations vues dans la leçon en utilisant les mêmes données. "],["lecon_spatiotemp.html", "9.1 Leçon", " 9.1 Leçon Cette leçon est divisée en deux parties. Dans la première partie, vous apprendrez à manipuler des données spatiotemporelles de type vectoriel, et dans la seconde partie, des données spatiotemporelles de type matriciel. Chacune des parties est structurée autour d’une problématique à résoudre. Dans la première partie, vous analyser un jeu de données de 400 trajets de cyclistes à Montréal. Cette analyse vous amènera à manipuler des objets vectoriels à des échelles de temps fines (de l’ordre de quelques heures). Dans la seconde partie, vous étudierez l’évolution des températures et des précipitations dans la région du Parc national du Mont-Mégantic de 2007 à 2016. Vous manipulerez alors des données climatiques mensuelles sous forme d’une série de rasters. 9.1.1 Télécharger les données Les données Les données vectorielles et matricielles utilisées dans ce module peuvent être téléchargées en cliquant sur un seul lien: données pour le module 9. Sauvegardez le dossier compressé (zip) dans votre répertoire de travail Module9_donnees pour ce module, et dézippez-le. Le dossier comprend quatre fichiers: maxt.nc mint.nc pcp.nc trip400.geojson. 9.1.2 Données spatiotemporelles vectorielles Dans cette première partie, nous allons manipuler le temps et l’espace dans un ensemble de données vectorielles. Plus précisément, nous utiliserons un ensemble de données comptabilisant 400 trajets en vélo dans la ville de Montréal, et répondrons aux questions suivantes : Quel trajet présente la vitesse moyenne la plus élevée? Quelle est la période de l’année préférée des cyclistes du jeu de données? Nous finirons cette partie avec un exercice de visualisation du trajet le plus long, que nous animerons. 9.1.2.1 Importer les données Le site de la ville de Montréal et le site Données Québec, mettent à disposition un jeu de données incluant près de 5000 trajets individuels à vélo. Ces trajets ont été obtenus avec l’application “Mon RésoVélo” qui enregistre les positions de cyclistes à intervalle régulier. Les données de trajets brutes ont ensuite été traitées avant d’être rendues disponibles en ligne sous licence creative common (CC-BY). Les trajets ont notamment été anonymisés - reportez-vous au lien précédent pour plus d’informations relatives au traitement de ces données. Ce jeu de données de 500 trajets est contenu dans un fichier zippé d’extension GeoJSON trip5000.json que nous avons préalablement téléchargé. Ces données étant un peu volumineuses (&gt;150MB), nous avons seulement conservé les 400 premiers trajets. Aussi, nous avons enlevé la colonne liste_segments_jsonb qui permet d’identifier les pistes cyclables et les portions du réseau routier emprunter par les cyclistes. Nous avons fait ce pré-traitement en utilisant des manipulations vues dans les modules précédents et que nous décrivons ci-dessous : library(sf) tmp &lt;- st_read(&quot;trip5000.json&quot;) st_write(tmp[1:400, names(tmp) != &quot;liste_segments_jsonb&quot;], &quot;trip400.geojson&quot;) Nous pouvons maintenant utiliser la fonction st_read() de la bibliothèque sf pour lire le fichier simplifié trip400.geojson disponible dans le répertoire Module9_donnees : library(sf) trajets &lt;- st_read(&quot;Module9/Module9_donnees/trip400.geojson&quot;) Reading layer `trip400&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module9/Module9_donnees/trip400.geojson&#39; using driver `GeoJSON&#39; Simple feature collection with 400 features and 7 fields Geometry type: LINESTRING Dimension: XY Bounding box: xmin: -73.84 ymin: 45.43 xmax: -73.4 ymax: 45.7 Geodetic CRS: WGS 84 L’objet trajets est de classe sf et contient un ensemble de 400 lignes décrivant les trajets à vélo et pour lesquels nous avons les informations suivantes : names(trajets) [1] &quot;stop&quot; &quot;id_origine&quot; &quot;start&quot; &quot;length&quot; [5] &quot;purpose&quot; &quot;n_coord&quot; &quot;id&quot; &quot;geometry&quot; Afin de résoudre notre problématique, nous utiliserons les colonnes suivantes: start : date et heure associées au début du trajet, stop : date et heure associées à la fin du trajet, length: longueur du trajet en mètres. 9.1.2.2 Vitesse moyenne des trajets Commençons par résoudre la première question: Quel trajet présente la vitesse moyenne la plus élevée? Nous avons importé 400 trajets à vélo et nous cherchons celui qui présente la vitesse moyenne la plus élevée. Pour calculer une vitesse pour un trajet en particulier, nous devons diviser sa longueur par le temps de parcours. Nous avons donc besoin de trouver d’abord la distance des trajets. Dans la table des attributs de trajets, il y a une colonne length qui nous donne cette distance. Par exemple, nous pouvons obtenir la longueur des 10 premiers trajets : trajets$length[1:10] [1] 3163 1066 5619 3115 5376 1153 11845 8033 [9] 21146 8315 Notons qu’en l’absence de cette colonne length, nous pourrions estimer ces distances en utilisant la fonction st_length() vue au module 7 et qui calcule la longueur de chaque ligne de trajets. len &lt;- st_length(trajets) len[1:10] Units: [m] [1] 3157 1065 5614 3110 5367 1152 11828 8021 [9] 21126 8303 Comment nous assurer que les distances répertoriées dans la colonne length sont identiques à celles calculées avec la fonction st_length()? Un moyen simple de le vérifier est de visualiser une distance en fonction de l’autre. # Tracer une distance en x, et l&#39;autre en y plot(trajets$length, st_length(trajets), xlab = &quot;distance - colonne &#39;length&#39; (m)&quot;, # ylab = &quot;distance - fonction &#39;st_length()&#39; (m)&quot;, pch = 19) # la forme des points est un cercle plein # Tracer une ligne droite de pente 1 passant par l&#39;origine. # La fonction abline(a,b) permet de créer facilement une ligne en spécifiant # le point d&#39;interception sur l&#39;axe des y (paramètre a) et la pente (paramètre b) abline(a = 0, b = 1, lty = 2) # lty = 2 donne une ligne discontinue Nous voyons ainsi rapidement que tous les points sont sur la ligne 1:1. Ceci nous permet de conclure que les valeurs sont identiques ou très proches - car nous n’avons pas fait de tests formels, et ils se pourraient donc qu’il y ait de minimes différences entre les deux distances. Nous devons ensuite quantifier la durée des trajets pour obtenir les vitesses moyennes. Pour cela, nous avons besoin des colonnes start et stop de l’objet trajets qui donnent la date et l’heure associées au début et à la fin de chaque trajet. Par exemple, pour les 20 premiers trajets ces colonnes nous donnent : trajets$start[1:10] [1] &quot;2013-06-25 17:21:21 EDT&quot; [2] &quot;2013-07-25 15:37:42 EDT&quot; [3] &quot;2013-07-25 15:19:15 EDT&quot; [4] &quot;2013-06-25 17:21:20 EDT&quot; [5] &quot;2013-06-26 13:46:01 EDT&quot; [6] &quot;2013-07-02 13:21:56 EDT&quot; [7] &quot;2013-07-02 13:05:48 EDT&quot; [8] &quot;2013-07-25 17:45:52 EDT&quot; [9] &quot;2013-07-30 10:38:23 EDT&quot; [10] &quot;2013-07-30 10:19:08 EDT&quot; trajets$stop[1:10] [1] &quot;2013-06-25 17:34:16 EDT&quot; [2] &quot;2013-07-25 15:40:06 EDT&quot; [3] &quot;2013-07-25 15:43:12 EDT&quot; [4] &quot;2013-06-25 17:34:16 EDT&quot; [5] &quot;2013-06-26 14:00:05 EDT&quot; [6] &quot;2013-07-02 13:25:26 EDT&quot; [7] &quot;2013-07-02 13:45:14 EDT&quot; [8] &quot;2013-07-25 18:21:40 EDT&quot; [9] &quot;2013-07-30 11:55:12 EDT&quot; [10] &quot;2013-07-30 11:00:15 EDT&quot; Nous remarquons que la date et l’heure sont exprimées dans un format particulier. Regardons la classe des colonnes start et stop  : class(trajets$start) [1] &quot;POSIXct&quot; &quot;POSIXt&quot; class(trajets$stop) [1] &quot;POSIXct&quot; &quot;POSIXt&quot; Les classes obtenues signifient que start et stop sont exprimés par des chaînes de caractères qui suivent une norme POSIX (Portable Operating System Interface). En l’occurrence POSIXct (calendar time) est une variété de POSIXt (time) qui contient le nombre de secondes écoulées depuis l’Heure Unix (Epoch time), le 1er janvier 1970 00:00:00 UTC (Temps Universel Coordonné). Ainsi, il est possible de convertir des objets de classe POSIXct en objet de classe numeric pour obtenir le temps écoulé en secondes, par exemple : nb_sec &lt;- as.numeric(trajets$start) nb_sec[1:10] [1] 1.372e+09 1.375e+09 1.375e+09 1.372e+09 1.372e+09 [6] 1.373e+09 1.373e+09 1.375e+09 1.375e+09 1.375e+09 Aussi, la soustraction de deux objets POSIXct nous donne un objet de classe difftime qui exprime une durée: duree &lt;- trajets$stop[1] - trajets$start[1] duree Time difference of 12.92 mins class(duree) [1] &quot;difftime&quot; Nous pouvons aussi spécifier l’unité de temps dans laquelle nous voulons obtenir la durée entre deux évènements en utilisant la fonction R difftime(). Cette dernière est composée de trois arguments difftime(end, start, units) : la date et l’heure de l’évènement final, la date et l’heure de l’évènement initial, et l’unité désirée. duree &lt;- difftime(trajets$stop[1], trajets$start[1], units = &#39;secs&#39;) duree Time difference of 775 secs Ainsi, nous pouvons calculer la durée de chaque trajet en seconde en utilisant la fonction difftime(). Ajoutons une colonne à l’objet trajets pour conserver le résultat de ce calcul. trajets$duree_s &lt;- difftime(trajets$stop, trajets$start, units = &#39;secs&#39;) trajets$duree_s[1:10] Time differences in secs [1] 775 144 1437 776 844 210 2366 2148 4609 2467 Regardons maintenant les distributions de longueurs et de durées de trajets en dessinant un histogramme avec la fonction hist(). par(mfrow = c(1, 2)) # figure à deux panneaux côte à côte hist(trajets$length, breaks = seq(0, 44000, 2000), # spécifie les catégories de longueur xlab = &quot;Longueur (m)&quot;, ylab = &quot;Fréquence&quot;, main = &quot;&quot; # pas de titre ) hist(as.numeric(trajets$duree_s), breaks = seq(0, 20000, 1000), # spécifie les catégories de durée xlab = &quot;Durée (s)&quot;, ylab = &quot;Fréquence&quot;, main = &quot;&quot; # pas de titre ) Nous rajoutons maintenant une colonne vitesse_m_s à trajets qui est la vitesse moyenne de chaque trajet, exprimée en mètre par seconde. trajets$vitesse_m_s &lt;- trajets$length/as.numeric(trajets$duree_s) trajets$vitesse_m_s[1:10] [1] 4.081 7.403 3.910 4.014 6.370 5.490 5.006 3.740 [9] 4.588 3.370 Notez que nous avons converti l’objet trajets$duree_s qui est de classe difftime en format numérique pour réaliser cette division. Il peut être plus intuitif d’exprimer ces vitesses en kilomètre par heure, plutôt qu’en mètre par seconde, pour cela il nous suffit de diviser par 1000 [m/km] pour convertir les mètres en kilomètres et de multiplier les secondes par 3600 [s/h] pour les convertir en heures, ce qui revient à multiplier par 3.6 : trajets$vitesse_km_h &lt;- trajets$vitesse_m_s * 3.6 trajets$vitesse_km_h[1:10] [1] 14.69 26.65 14.08 14.45 22.93 19.77 18.02 13.46 [9] 16.52 12.13 Afin de déterminer le trajet le plus rapide, nous allons maintenant ordonner les vitesses par ordre décroissant, avec la fonction sort(), et regarder les 10 premières valeurs : vit_dec &lt;- sort(trajets$vitesse_km_h, decreasing = TRUE) vit_dec[1:10] [1] 365.08 39.60 38.89 34.30 34.12 33.20 30.67 [8] 30.46 29.99 29.51 Le ou la plus rapide des cyclistes circule à une vitesse moyenne de 365 km/h, ce qui ne semble pas réaliste! Nous supposons qu’un problème d’enregistrement de ce trajet est à l’origine de cette valeur abberante. Nous excluons donc ce trajet et retenons le second comme étant le plus rapide. Pour extraire le second trajet, nous utilisons la fonction order(). traj_rapide &lt;- trajets[order(trajets$vitesse_km_h, decreasing = TRUE)[2], ] traj_rapide Simple feature collection with 1 feature and 10 fields Geometry type: LINESTRING Dimension: XY Bounding box: xmin: -73.59 ymin: 45.53 xmax: -73.58 ymax: 45.53 Geodetic CRS: WGS 84 stop id_origine start 207 2013-08-05 22:00:02 3943 2013-08-05 21:58:45 length purpose n_coord id 207 847 Social 145 3943 geometry duree_s vitesse_m_s 207 LINESTRING (-73.58 45.53, -... 77 secs 11 vitesse_km_h 207 39.6 Notez que la fonction order() retourne l’indice de l’élément désiré, alors que la fonction sort() retourne la valeur de l’élément. Nous pouvons visualiser ce trajet en utilisant la fonction mapview() de la bibliothèque mapview(). library(mapview) mapview(traj_rapide) Un trajet bien singulier, à 22h près du parc Laurier. Nous remarquons que l’enregistrement du trajet manque probablement de précision, ce qui expliquerait son allure quelque peu tordue… 9.1.2.3 Période de l’année préférée Penchons-nous maintenant sur la deuxième question. Quelle est la période de l’année préférée des cyclistes du jeu de données? Pour répondre à cette deuxième question, nous allons utiliser certaines fonctions de la bibliothèque lubridate. Bien que R dispose, de base, de toutes les fonctionnalités nécessaires à la manipulation des dates et du temps, lubridate rend ces manipulations plus intuitives (l’aide mémoire (https://github.com/rstudio/cheatsheets/raw/master/lubridate.pdf fait un tour d’horizon complet des fonctionnalités de lubridate). Installons donc la bibliothèque lubridate : install.packages(&quot;lubridate&quot;) Chargeons la bibliothèque lubridate dans notre session de travail R afin de manipuler les données de classes POSIXct des colonnes start et stop. Par exemple nous pouvons extraire l’année avec la fonction year() : library(lubridate) year(trajets$start)[1:20] [1] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 [11] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 Afin de répondre à la question, nous commençons par identifier le mois de l’année qui compte le plus de trajets à vélo. Pour cela, nous allons utiliser la fonction month() de la bibliothèque lubridate. Cette fonction nous retourne le mois associé à un objet de classe POSIXct month(trajets$start[1]) [1] 6 La fonction month() nous offre aussi la possibilité d’utiliser les noms de mois (en anglais) sous forme de facteurs, de manière abrégée  : month(trajets$start[1], label = TRUE) [1] Jun 12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; ... &lt; Dec ou intégrale : month(trajets$start[1], label = TRUE, abbr = FALSE) [1] June 12 Levels: January &lt; February &lt; March &lt; ... &lt; December Pour la tâche à réaliser, utilisons seulement le numéro des mois et créons une colonne mois dans la table d’attributs de l’objet trajets pour les conserver : trajets$mois &lt;- month(trajets$start) trajets$mois[1:20] [1] 6 7 7 6 6 7 7 7 7 7 6 6 7 7 6 6 6 6 7 7 Une manière efficace de compter le nombre d’occurrence est d’appliquer la fonction table() sur la colonne nouvellement créée : nb_mois &lt;- table(trajets$mois) nb_mois 1 5 6 7 8 6 1 11 376 6 Juillet (le 7ième mois de l’année) est donc le mois qui concentre le plus de trajets à vélo dans le jeu de données étudié. Nous allons maintenant regarder le jour qui concentre le plus de trajets avec la fonction day() de la bibliothèque lubridate. Nous commençons par ajouter une colonne jour à l’objet trajets. trajets$jour &lt;- day(trajets$start) trajets$jour[1:10] [1] 25 25 25 25 26 2 2 25 30 30 Isolons ensuite les trajets effectués au mois de juillet. traj_juillet &lt;- trajets[trajets$mois == 7, ] Enfin, visualisons le nombre de trajets par jour avec les fonctions table() et barplot() cette fois-ci. barplot( table(traj_juillet$jour), xlab = &quot;Jour de juillet&quot;, ylab = &quot;Nombre de trajets&quot; ) C’est donc le 10 juillet que nous recensons le plus grand nombre de trajets. Nous allons même aller à l’échelle de l’heure et nous recommençons les étapes précédentes avec la fonction hour(). Au passage, mentionnons la bibliothèque hms pour manipuler les heures, minutes et secondes (nous ne l’utiliserons pas ici, mais elles pourraient vous être utile dans vos projets futurs). trajets$heure &lt;- hour(trajets$start) traj_10juillet &lt;- trajets[trajets$mois == 7 &amp; trajets$jour == 10, ] barplot( table(traj_10juillet$heure), xlab = &quot;Jours de juillet&quot;, ylab = &quot;Nombre de trajets&quot; ) C’est donc à 17h le 10 juillet que les trajets sont les plus nombreux. 9.1.2.4 Animation du trajet le plus long Nous allons à présent animer le trajet de vélo le plus long. Nous voulons, en effet, créer un fichier GIF qui illustrera le parcours de la ou du cycliste. Pour y arriver nous devrons faire les étapes suivantes : Trouver le trajet le plus long. Associer un temps à chaque segment du parcours. Créer une carte pour différents états d’avancement du parcours. Rassembler les cartes ainsi créées et en faire un fichier GIF. Commençons! 1. Trajet le plus long La première étape est une manipulation de filtres que nous avons fait à maintes reprises. Cette fois-ci appliquons which.max() sur la colonne length() et nous filtrons avec [. traj_long &lt;- trajets[which.max(trajets$length), ] traj_long Simple feature collection with 1 feature and 13 fields Geometry type: LINESTRING Dimension: XY Bounding box: xmin: -73.69 ymin: 45.43 xmax: -73.55 ymax: 45.53 Geodetic CRS: WGS 84 stop id_origine start 69 2013-07-30 15:52:09 3082 2013-07-30 11:38:30 length purpose n_coord id 69 42503 Social 14511 3082 geometry duree_s 69 LINESTRING (-73.57 45.52, -... 15219 secs vitesse_m_s vitesse_km_h mois jour heure 69 2.793 10.05 7 30 11 Regardons ce trajet : mapview(traj_long) 2. Segmentation du trajet Nous allons segmenter le trajet le plus long en une série de points successifs. Chaque point marquera ainsi une portion du trajet total. Nous allons ensuite associer un temps à chacune de ces portions. Pour ce faire, nous commencons par convertir la géométrie de traj_long de LINESTRING à POINT avec la fonction st_cast() vue au module 7. traj_long_pts &lt;- st_as_sf(st_cast(st_geometry(traj_long), to = &quot;POINT&quot;)) traj_long_pts Simple feature collection with 10818 features and 0 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -73.69 ymin: 45.43 xmax: -73.55 ymax: 45.53 Geodetic CRS: WGS 84 First 10 features: x 1 POINT (-73.57 45.52) 2 POINT (-73.57 45.52) 3 POINT (-73.57 45.52) 4 POINT (-73.57 45.52) 5 POINT (-73.57 45.52) 6 POINT (-73.57 45.52) 7 POINT (-73.57 45.52) 8 POINT (-73.57 45.52) 9 POINT (-73.57 45.52) 10 POINT (-73.57 45.52) Décortiquons cette ligne: Nous isolons d’abord la géométrie de traj_long avec la fonction st_geometry(). Nous faisons ensuite la conversion point/ligne avec la fonction st_cast(). Finalement, nous convertissons l’objet de classe sfc ainsi obtenu en objet de classe sf avec st_as_sf(). L’objet traj_long_pts ainsi créé contient 10818 points nrow(traj_long_pts) [1] 10818 Maintenant, nous allons associer un temps à chaque point du trajet. D’emblée, il nous est possible de déterminer le temps de départ et le temps d’arrivée de ce trajet puisque ceux-ci sont donnés par les valeurs de traj_long$start et de traj_long$stop respectivement. De plus, l’application “Mon RésoVélo” enregistre les coordonnées spatiales le long d’un trajet à intervalle régulier. Ainsi, le temps associé à chaque point d’un trajet est réparti de façon régulière entre son temps de départ et son temps d’arrivée. Nous créons donc une séquence régulière avec la fonction R seq() en spécifiant le temps de départ, le temps d’arrivé et le nombre de points que doit inclure la séquence (argument length.out) qui est le nombre de lignes (nrow()) de la table d’attributs de traj_long_pts. Finalement, nous ajoutons cette séquence au nouvel objet traj_long_pts dans une colonne temps. traj_long_pts$temps &lt;- seq( from = traj_long$start, to = traj_long$stop, length.out = nrow(traj_long_pts) ) 3. Visualisation du trajet pour différentes périodes À présent, nous allons visualiser le trajet parcouru sur différentes périodes de temps. Pour chaque période, nous sauvegarderons la visualisation obtenue. À la prochaine étape, nous combinerons ces images pour obtenir une animation. Dans un premier temps, visualisons le trajet parcouru pour une période de temps arbitraire, autrement dit pour une période allant du premier point jusqu’à n’importe quel points \\(n\\) le long du trajet traj_long_pts. À titre d’exemple, choisissons les 2000 premiers points. lin &lt;- st_cast(st_combine(traj_long_pts[1:2000, ]), &quot;LINESTRING&quot;) Cette ligne contient les étapes suivantes: Nous extrayons les 2000 premiers points avec [. Nous les combinons en MULTIPOINT avec st_combine(). Nous transformons le MULTIPOINT en LINESTRING avec st_cast(). Notons que sans l’étape (ii), st_cast() transformera chaque point en ligne ce qui donnera un ensemble de lignes de 1 seul point. Regardons cette section du trajet avec mapview(). mapview(lin) Grâce à l’étape précédente, nous pouvons facilement avoir accès à l’heure correspondant au dernier point de cette section du trajet. traj_long_pts$temps[2000] [1] &quot;2013-07-30 12:25:22 EDT&quot; Avec la fonction st_length() de la bibliothèque sf nous pouvons connaître la distance parcourue pour cette section du trajet : st_length(lin) 7866 [m] Visualisons maintenant cette section du trajet en utilisant la bibliothèque tmap. Dans le titre de la carte, indiquons la distance parcourue ainsi que le temps associé. Des objets de classe caractère peuvent être combinés (c’est-à-dire écrits l’un à la suite des autres sans espacement) en utilisant la fonction R paste0(). library(tmap) tm_shape(lin, bbox = st_bbox(traj_long_pts)) + tm_lines(lwd = 2, col = &quot;#62852eaa&quot;) + tm_layout(main.title = paste0( &quot;temps: &quot;, traj_long_pts$temps[2000], &quot; / distance&quot;, st_length(lin) ), main.title.size = 0.9) Pour obtenir une animation pour la totalité du trajet traj_long, nous devons alors faire cette même carte pour un nombre croissant de points et combiner toutes ces cartes en un seul fichier GIF. Puisque le trajet total compte 10818 points, cette tâche est répétitive. Dans ce qui suit nous allons structurer notre code avec quelques fonctions. Cela nous permet d’isoler les différentes étapes à réaliser et d’éviter de répétées du code. De manière générales, structurer son code en différentes fonctions permet d’augmenter la clarté du code et de diminuer les erreurs qui arrivent rapidement quand le code se complexifie. Nous devons donc prendre un peu de temps pour expliquer comment créer une fonction. Jusqu’ici nous avons utilisé de nombreuses fonctions déjà définies dans R ou dans les bibliothèques employées sans que nous n’ayons eu besoin de créer nos propres fonctions. Pour comprendre comment est structurée une fonction, nous allons détailler un exemple simple. ma_fonction &lt;- function(a, b = 1) { if (b &gt; 0) { c &lt;- a + b } else { c &lt;- a - 2*b } return(c) # ou simplement c } Dans R, une fonction est un objet créé avec function(). Comme tout objet nous pouvons l’assigner à une variable et dans notre exemple, nous l’assignons à ma_fonction qui sera le nom de la fonction. Dans la parenthèse qui suit function, nous écrivons les arguments de la fonction, en l’occurrence pour ma_fonction, nous avons a et b. Dans notre exemple, b a une valeur par défaut qui est 1, donc si nous ne spécifions pas b, alors b aura automatiquement une valeur de 1. Le corps de la fonction est l’expression juste après cette parenthèse, dans notre cas cela inclut tout ce qui est entre accolades ({ }). Une fonction peut comprendre autant de ligne de code que souhaité et peut contenir n’importe quelle expression R valide. À titre d’exemple, nous avons utilisé un test logique if/else pour que la valeur retournée c change selon les valeurs de b. Avec R, une fonction retourne la dernière ligne de code (l’utilisation de return() à la dernière ligne est ainsi optionnelle, mais elle permet de clarifier ce que retourne la fonction). Une fois la fonction créée, nous l’appelons comme toute autre fonction. ma_fonction(1) # utlise b = 1 [1] 2 ma_fonction(1, 2) [1] 3 ma_fonction(1, -2) [1] 5 Nous sommes maintenant outillés pour créer différentes fonctions pour structurer notre code. Notre fonction principale, visual(), a pour argument les points du trajet, traj_pts, et le nombre de points à combiner, que nous appellerons n. Cette fonction reprend les étapes précédentes. visual &lt;- function(traj_pts, n = 100) { # extraction des n premiers points pts &lt;- traj_pts[1:n, ] # conversion des points en ligne lin &lt;- st_cast(st_combine(pts), &quot;LINESTRING&quot;) # carte de la ligne tm_shape(lin, bbox = st_bbox(traj_long_pts)) + tm_lines(lwd = 2, col = &quot;#62852eaa&quot;) + tm_layout(main.title = paste0( &quot;temps: &quot;, traj_long_pts$temps[n], &quot; / distance&quot;, st_length(lin) ), main.title.size = 0.9) } Nous allons faire quelques améliorations sur le texte accompagnant les cartes en créant deux autres fonctions. La première, txt_temps(), a pour argument un temps (nous utiliserons le temps du point n) et retourne un texte formaté grâce aux fonctionnalités de la bibliothèque lubridate. txt_temps &lt;- function(temps) { paste0(hour(temps), &quot;h &quot;, minute(temps), &quot;m &quot;, floor(second(temps)), &quot;s&quot;) } La seconde, txt_distance(), prend pour argument une ligne et retourne un texte formaté comprenant la distance en kilomètre. txt_distance &lt;- function(lin) { len &lt;- st_length(lin) paste0(&quot;Distance parcourue: &quot;, format(as.numeric(len)/1000, digits = 4), &quot;km&quot;) } Notons que la fonction R format() nous permet de contrôler le nombre de chiffres (digits) affiché. Nous allons reformuler notre fonction visual() pour qu’elle appelle ces deux fonctions. De plus, nous y ajoutons un argument, basemap, de la bibliothèque tmap, qui nous permet d’ajouter un fond de carte. Cet argument a pour valeur NULL par défaut, ce qui nous permet d’avoir, par défaut, une carte sans fond. Enfin, nous allons nous assurer que le nombre n de points à combiner soit supérieur à 1 car nous avons besoin d’un minimum de 2 points pour créer une ligne. Cette condition est assurée par la fonction R stopifnot(). visual &lt;- function(traj_pts, n = 100, basemap = NULL) { stopifnot(n &gt; 1) tps &lt;- traj_pts$temps[n] pts &lt;- traj_pts[1:n, drop = FALSE] lin &lt;- st_cast(st_combine(pts), &quot;LINESTRING&quot;) basemap + tm_shape(lin, bbox = st_bbox(traj_long_pts)) + tm_lines(lwd = 2, col = &quot;#62852eaa&quot;) + tm_layout(main.title = paste0(txt_temps(tps), &quot; - &quot;, txt_distance(lin)), main.title.size = 0.9) } Nous pouvons maintenant faire la carte pour le nombre de points désirés, avec un minimum de 2 et un maximum de 10818 points. Pour faire la figure précédente nous utilisons le code suivant : visual(traj_long_pts, 2000) L’avantage du travail précédent est que nous pouvons maintenant très facilement faire la même carte en appelant notre fonction et en changeant simplement la valeur de n, par exemple, nous pouvons faire la même carte avec les 4000 premiers points. visual(traj_long_pts, 4000) 4. Créer une animation Nous allons maintenant créer une nouvelle fonction, anim(), qui nous permettra de générer une série de n_img images de notre trajet en appelant notre fonction visual() créée à l’étape précédente. anim &lt;- function(traj_pts, n_img, basemap = NULL) { for (i in floor(seq(2, nrow(traj_pts), length.out = n_img))) { print(visual(traj_pts, i, basemap)) } } Quelques remarques: La fonction for() constitue ce qu’on appelle une boucle en programmation informatique. La boucle vient répéter une action, donnée par les lignes de codes entre les accolades { }, pour chaque élément contenu dans une séquence. Nous utilisons seq() pour générer une séquence de n_img images entre 2 et le maximum de points (10818). La séquence peut générer des nombres décimaux, mais visual() demande des nombre entiers, nous utilisons alors floor() pour la conversion. Nous reprenons l’argument basemap pour qu’il puisse être passé à visual(). Observons, par exemple, la succession de cartes créées par la fonction anim() lorsque n_img = 5 : anim(traj_long_pts, n_img = 5, NULL) Une fois l’animation créée, pour un nombre d’images donné, nous voulons la sauvegarder en format GIF. Pour générer un fichier GIF, nous utilisons la fonction saveGIF() de la bibliothèque animation. Cette fonction prend en premier argument une expression (du code R) qui permet de générer une série de figures qui seront ensuite combinées en GIF. Installons la bibliothèque animation. install.packages(&quot;animation&quot;) Nous pouvons maintenant utiliser saveGIF(). library(animation) saveGIF(anim(traj_long_pts, 20, NULL), movie.name = &quot;anim1.gif&quot;, ani.height = 500, ani.width = 500) Pour finir, nous allons ajouter un fond de carte. Pour cela nous allons télécharger un fond de carte de OpenStreetMap grâce à fonction osm.raster() de la bibliothèque rosm. Installons la bibliothèque rosm. install.packages(&quot;rosm&quot;) La fonction osm.raster() s’utilise avec la library raster. Nous devons donc charger également cette library dans notre session de travail R. Nous devons aussi spécifier à la fonction osm.raster() l’étendue de la carte de fond désirée. library(raster) library(rosm) carte_fond &lt;- osm.raster(extent(traj_long_pts), crop = TRUE) carte_fond Visualisons cette carte de fond avec les fonctionnalités de la library tmap: tm_shape(carte_fond) + tm_rgb() Maintenant, répétons notre animation en remplaçant la valeur NULL de l’argument basemap par la carte de fond. saveGIF(anim(traj_long_pts, 20, tm_shape(carte_fond) + tm_rgb()), movie.name = &quot;anim2.gif&quot;, ani.height = 500, ani.width = 500) 9.1.3 Données spatiotemporelles matricielles Dans cette deuxième partie de la leçon, nous allons manipuler le temps et l’espace dans un ensemble de données matricielles. Plus précisément, nous nous intéresserons aux précipitations et aux températures moyennes autour du Parc national du Mont-Mégantic entre 2007 et 2016. Nous chercherons à répondre aux deux questions suivantes : Quel mois dispose du plus faible niveau de pluviométrie dans la région du Parc national du Mont-Mégantic? Où se situe le (ou les) point(s) le(s) plus chaud(s) dans la région du Parc national du Mont-Mégantic? De plus, nous terminerons cette partie par la réalisation de deux exercices de visualisation de données : Nous dessinerons les profils de températures et de précipitations pour la période étudiée. Nous animerons ces profils en ajoutant une carte, elle aussi animée. Pour pouvoir répondre à ces questions et réaliser ces exercices, nous utiliserons différents rasters qui seront manipulés sous forme d’objets rasterStack (mentionnés au Module 5). 9.1.3.1 Importer les données Les données que nous allons utiliser dans cette partie ont été préparées à partir de données climatiques historiques à haute résolution pour l’Amérique du Nord (MacDonald et al. 2020). Ces données (issues d’un travail de modélisation) sont disponibles sur l’espace dédié à l’archivage de données du Centre allemand de calcul pour le climat, DKRZ (pour y accéder, il faut d’abord s’enregistrer sur le site). Les données sont disponibles dans le répertoire Module9_donnees et elles incluent, pour l’ensemble de l’Amérique du Nord et pour chaque mois de 1901 à 2016, les trois variables suivantes: la température minimale moyenne (mint.nc), la température maximale moyenne (maxt.nc), les précipitations cumulées (pcp.nc), et ce, à une résolution de 60 arc-secondes. Figure 9.1: Température minimale moyenne au mois de janvier 2000. Par exemple, sur la figure 9.1, nous présentons les températures minimales moyennes pour le mois de janvier 2000. À partir des données brutes, nous avons sélectionné les données correspondantes aux années 2007 à 2016, puis nous avons fait une opération de rognage en utilisant l’étendue spatiale suivante (dans le système géodésique mondial WGS84): longitude : de 72°Ouest à 71°Ouest, latitude : de 45°Nord à 46°Nord. Les données préparées sont en format NetCDF (Network Common Data Form). Ces données peuvent être importées en utilisant la fonction stack() de la bibliothèque raster mais nécessitent l’utilisation de la bibliothèque ncdf4. Commençons par installer cette bibliothèque : install.packages(&quot;ncdf4&quot;) Puis, chargeons les bibliothèques raster et ncdf4 et importons les données en utilisant la fonction stack() : library(raster) library(ncdf4) # temperature minimale par mois pour mint &lt;- stack(&quot;Module9/Module9_donnees/mint.nc&quot;) # temperature maximale par mois maxt &lt;- stack(&quot;Module9/Module9_donnees/maxt.nc&quot;) # total des precipitations par mois pcp &lt;- stack(&quot;Module9/Module9_donnees/pcp.nc&quot;) class(mint) [1] &quot;RasterStack&quot; attr(,&quot;package&quot;) [1] &quot;raster&quot; Il s’agit là d’objets de classe rasterStack que nous détaillons dans la section suivante. 9.1.3.2 Les objets rasterStack Pour cette section, nous nous concentrons sur l’objet mint, notons cependant que tout ce que nous voyons ici s’applique aux autres objets rasterStack que nous avons importés. Inspectons rapidement ce nouvel objet. mint class : RasterStack dimensions : 60, 60, 3600, 120 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, ... min values : -16.2, -19.9, -12.8, -4.5, 2.4, 8.2, 9.7, 9.2, 6.3, 2.7, -7.1, -13.6, -13.9, -14.5, -13.9, ... max values : -13.9, -18.0, -9.5, -0.6, 5.5, 11.8, 13.0, 11.7, 8.7, 5.3, -4.0, -10.6, -11.8, -12.7, -10.0, ... Nous obtenons des informations similaires à celles d’un objet de classe rasterLayer, cependant la ligne qui indique les dimensions possède un élément de plus indiquant le nombre de couches, et les valeurs affichées correspondent aux valeurs minimales et maximales pour chacune des différentes couches. Extraire les informations générales Un raster rasterStack est en fait une collection derasterLayer qui ont la même projection spatiale, la même résolution, la même étendue spatiale et donc le même nombre de cellules. Pour obtenir ces informations individuellement, nous utilisons les mêmes fonctions que pour les rasterLayer. extent(mint) class : Extent xmin : -71.99 xmax : -70.99 ymin : 45.01 ymax : 46.01 projection(mint) [1] &quot;+proj=longlat +ellps=WGS84 +no_defs&quot; ncell(mint) [1] 3600 Les dimensions du rasterStack peuvent être aussi être affichées avec la fonction dim() dim(mint) [1] 60 60 120 Comme nous pouvons le constater, 3 nombres sont retournés, un de plus que pour les objets rasterLayer, le dernier chiffre est le nombre de couches que nous avons mentionné plus haut, ici 120. Ce nombre peut aussi être affiché en utilisant la fonction nlayers(). nlayers(mint) [1] 120 L’objet mint est une donc collection de 120 objets de classe rasterLayer, chaque couche représente des valeurs de températures minimales moyennes sur toutes la zone pour un mois donné. Ici, les couches sont ordonnées dans le temps (elles ont été combinées ainsi) et nous avons 1 couche par mois sur 10 ans. Extraire une selection de couches Il est possible d’accéder à n’importe quelle couche (rasterLayer) en utilisant [[: class(mint[[1]]) [1] &quot;RasterLayer&quot; attr(,&quot;package&quot;) [1] &quot;raster&quot; # Raster de Température minimale du mois de janvier de la première année (2007) mint[[1]] class : RasterLayer band : 1 (of 120 bands) dimensions : 60, 60, 3600 (nrow, ncol, ncell) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs source : mint.nc names : X1 values : -16.2, -13.9 (min, max) zvar : variable # Raster de Température minimale du mois de décembre de la dernière année (2016) mint[[120]] class : RasterLayer band : 120 (of 120 bands) dimensions : 60, 60, 3600 (nrow, ncol, ncell) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs source : mint.nc names : X120 values : -13, -9.5 (min, max) zvar : variable Nous pouvons aussi prendre une séquence d’indices et obtenir un autre rasterStack. Par exemple, nous pouvons obtenir les données de la première année en utilisant les 12 premiers indices. mint[[1:12]] class : RasterStack dimensions : 60, 60, 3600, 12 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12 min values : -16.2, -19.9, -12.8, -4.5, 2.4, 8.2, 9.7, 9.2, 6.3, 2.7, -7.1, -13.6 max values : -13.9, -18.0, -9.5, -0.6, 5.5, 11.8, 13.0, 11.7, 8.7, 5.3, -4.0, -10.6 Nous pouvons aussi obtenir les températures minimales pour les 10 mois de septembre, nous utilisons pour cela la fonction seq(). mint[[seq(9, by = 12, length.out = 10)]] class : RasterStack dimensions : 60, 60, 3600, 10 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X9, X21, X33, X45, X57, X69, X81, X93, X105, X117 min values : 6.3, 6.3, 4.7, 7.4, 8.1, 5.1, 5.8, 5.8, 8.6, 7.0 max values : 8.7, 9.3, 7.3, 10.3, 10.7, 8.4, 9.1, 8.9, 11.5, 9.3 Il est aussi possible de combiner des couches du même rasterStack et de différents rasterStack (si les contraintes spatiales sont respectées) avec stack(). stack(mint[[1]], maxt[[1]], pcp[[1]]) class : RasterStack dimensions : 60, 60, 3600, 3 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X1.1, X1.2, X1.3 min values : -16.2, -7.6, 66.8 max values : -13.9, -3.7, 107.0 Nous avons, ici, créé un rasterStack en combinant les températures minimales et maximales, et les précipitations cumulées du mois de janvier de la première année (2007). Extraire et manipuler les valeurs Nous pouvons extraire les valeurs en utilisant la double indexation : [[ pour choisir les couches désirées, et puis [ pour extraire les valeurs des couches sélectionnées. Ainsi, nous pouvons extraire les valeurs des 10 premières cellules pour la première année (c’est-à-dire les 12 premiers mois). mint[[1:12]][1:10] X1 X2 X3 X4 X5 X6 X7 X8 X9 [1,] -15.0 -19.0 -9.7 -0.9 5.5 11.8 13.0 11.5 8.7 [2,] -15.1 -19.1 -9.7 -1.0 5.5 11.7 12.9 11.4 8.7 [3,] -15.2 -19.1 -9.9 -1.1 5.4 11.6 12.8 11.3 8.6 [4,] -15.2 -19.1 -9.9 -1.1 5.4 11.6 12.7 11.3 8.6 [5,] -15.2 -19.1 -9.9 -1.1 5.3 11.6 12.7 11.3 8.6 [6,] -15.2 -19.1 -9.9 -1.1 5.3 11.6 12.7 11.3 8.6 [7,] -15.2 -19.1 -9.8 -1.1 5.3 11.6 12.8 11.3 8.6 [8,] -15.2 -19.1 -9.9 -1.2 5.3 11.5 12.7 11.2 8.5 [9,] -15.2 -19.1 -10.0 -1.2 5.3 11.5 12.6 11.1 8.5 [10,] -15.3 -19.0 -10.0 -1.3 5.2 11.4 12.5 11.1 8.5 X10 X11 X12 [1,] 5.3 -4.0 -12.2 [2,] 5.2 -4.1 -12.3 [3,] 5.1 -4.3 -12.4 [4,] 5.1 -4.4 -12.4 [5,] 5.1 -4.3 -12.4 [6,] 5.1 -4.3 -12.4 [7,] 5.1 -4.2 -12.3 [8,] 5.1 -4.4 -12.4 [9,] 5.0 -4.5 -12.5 [10,] 4.9 -4.6 -12.5 Nous obtenons ainsi une matrice de 12 colonnes (1 colonne par mois) et 10 lignes (1 par cellule). Il est aussi possible d’utiliser getValues() pour obtenir l’ensemble des valeurs d’un objet rasterStack. Dans ce cas, les valeurs sont alors retournées sous forme de matrice. val &lt;- getValues(mint) dim(val) [1] 3600 120 Pour appliquer les mêmes opérations sur les différentes couches, il est possible d’utiliser la fonction R apply() après avoir utilisée la fonction getValues(). Par exemple, pour connaître la valeur minimale de chaque couche, nous pouvons utiliser la ligne suivante : apply(val, 2, min) X1 X2 X3 X4 X5 X6 X7 X8 X9 -16.2 -19.9 -12.8 -4.5 2.4 8.2 9.7 9.2 6.3 X10 X11 X12 X13 X14 X15 X16 X17 X18 2.7 -7.1 -13.6 -13.9 -14.5 -13.9 -2.6 0.7 9.7 X19 X20 X21 X22 X23 X24 X25 X26 X27 11.6 9.5 6.3 -0.4 -4.9 -14.3 -21.2 -14.9 -11.2 X28 X29 X30 X31 X32 X33 X34 X35 X36 -3.2 2.1 7.6 10.1 10.9 4.7 -1.1 -2.8 -13.0 X37 X38 X39 X40 X41 X42 X43 X44 X45 -13.4 -11.2 -6.5 -1.1 3.8 8.2 12.8 10.2 7.4 X46 X47 X48 X49 X50 X51 X52 X53 X54 0.0 -5.1 -12.7 -16.2 -16.4 -11.6 -4.1 4.9 8.1 X55 X56 X57 X58 X59 X60 X61 X62 X63 11.3 10.6 8.1 1.9 -2.5 -10.3 -15.0 -12.8 -6.6 X64 X65 X66 X67 X68 X69 X70 X71 X72 -3.3 5.4 8.4 11.0 11.3 5.1 2.4 -6.8 -10.4 X73 X74 X75 X76 X77 X78 X79 X80 X81 -16.8 -14.1 -9.4 -5.0 3.5 8.5 12.7 9.8 5.8 X82 X83 X84 X85 X86 X87 X88 X89 X90 1.4 -7.6 -14.2 -17.5 -16.0 -17.8 -5.0 3.4 8.3 X91 X92 X93 X94 X95 X96 X97 X98 X99 11.1 9.8 5.8 3.0 -6.7 -10.0 -20.4 -23.2 -15.5 X100 X101 X102 X103 X104 X105 X106 X107 X108 -5.6 4.8 6.9 10.6 11.5 8.6 -1.7 -4.0 -5.7 X109 X110 X111 X112 X113 X114 X115 X116 X117 -14.0 -13.3 -9.3 -6.7 3.3 7.9 11.1 11.5 7.0 X118 X119 X120 1.5 -3.7 -13.0 Notez que l’argument 2 signifie que la fonction min() est appliquée sur la deuxième dimension de la matrice val (c’est-à-dire la dimension associée aux couches). Nous pouvons aussi utiliser la fonction summary() qui nous donne un aperçu de la distribution des valeurs pour chaque couche. Par exemple, voici le résumé des cinq premières couches : su_mint &lt;- summary(mint) su_mint[,1:5] X1 X2 X3 X4 X5 Min. -16.2 -19.9 -12.8 -4.5 2.4 1st Qu. -15.2 -19.1 -11.0 -2.2 4.1 Median -15.0 -18.9 -10.4 -1.7 4.6 3rd Qu. -14.8 -18.7 -10.3 -1.4 4.9 Max. -13.9 -18.0 -9.5 -0.6 5.5 NA&#39;s 0.0 0.0 0.0 0.0 0.0 Aussi, certaines fonctions ont des comportements prédéfinies pour les objets rasterStack. Par exemple, la fonction min() retourne un objet de classe rasterLayer dont chaque cellule contient la valeur minimale des cellules des différentes couches ayant la même latitude et la même longitude (c’est-à-dire à la même position dans le raster). min(mint) class : RasterLayer dimensions : 60, 60, 3600 (nrow, ncol, ncell) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs source : memory names : layer values : -23.2, -22 (min, max) La fonction max() a le même comportement, pour une combinaison (longitude, latitude) donnée, elle retourne la valeur maximale des différentes cellules. La fonction quantile() retourne les quantiles pour les différentes couches, par défaut, 5 quantiles sont retournées. Ci-dessous, nous présentons le résultat pour les 10 premières couches. quantile(mint)[1:10, ] 0% 25% 50% 75% 100% X1 -16.2 -15.2 -15.0 -14.8 -13.9 X2 -19.9 -19.1 -18.9 -18.7 -18.0 X3 -12.8 -11.0 -10.4 -10.3 -9.5 X4 -4.5 -2.2 -1.7 -1.4 -0.6 X5 2.4 4.1 4.6 4.9 5.5 X6 8.2 10.3 10.8 11.1 11.8 X7 9.7 11.3 12.0 12.2 13.0 X8 9.2 10.6 10.8 11.0 11.7 X9 6.3 7.6 8.1 8.3 8.7 X10 2.7 4.3 4.6 4.8 5.3 Cette opération est équivalente à appliquer la fonction apply() et quantile() après avoir utilisé getValues(). apply(val, 2, quantile)[, 1:10] X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 0% -16.2 -19.9 -12.8 -4.5 2.4 8.2 9.7 9.2 6.3 2.7 25% -15.2 -19.1 -11.0 -2.2 4.1 10.3 11.3 10.6 7.6 4.3 50% -15.0 -18.9 -10.4 -1.7 4.6 10.8 12.0 10.8 8.1 4.6 75% -14.8 -18.7 -10.3 -1.4 4.9 11.1 12.2 11.0 8.3 4.8 100% -13.9 -18.0 -9.5 -0.6 5.5 11.8 13.0 11.7 8.7 5.3 Il est aussi possible de faire des calculs sur les différentes couches en utilisant la fonction calc(), par exemple nous pouvons obtenir le quantiles cellule par cellule de la manière suivante : calc(mint, quantile) class : RasterBrick dimensions : 60, 60, 3600, 5 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs source : memory names : X0., X25., X50., X75., X100. min values : -23.200, -11.300, -1.400, 7.675, 12.800 max values : -22.000, -8.325, 1.300, 10.625, 16.100 Ce qui nous donne un objet rasterStack qui loge, sur chacune de ses 5 couches, les valeurs des différents quantiles pour chacune des combinaisons (longitude, latitude). Nous noterons alors qu’utiliser calc(mint, min) revient à utiliser min(mint). Réaliser des opérations spatiales Les principales opérations spatiales pour les objets de classe rasterStack utilisent les mêmes fonctions que pour les objets de classe rasterLayer. Les opérations spatiales à réaliser seront alors, au besoin, répétées sur les différentes couches (cela étant dit, pour des raisons d’optimisation algorithmiques, il se peut que les opérations soient plus rapides sur un rasterStack de \\(n\\) couches plutôt que d’appliquer \\(n\\) fois les mêmes opérations sur \\(n\\) objets rasterLayer). En guise de démonstration, nous allons utiliser les fonctions projectRaster(), crop(), mask() et extract() sur le rasterStack mint (voir le Module 5 et le Module 8 pour plus de détails sur ces fonctions). Pour illustrer le changement de projections des rasterStack, projetons mint en utilisant la projection de Mercator. library(sf) mint_merc &lt;- projectRaster(mint, crs = st_crs(3857)$proj4string) mint_merc class : RasterBrick dimensions : 70, 74, 5180, 120 (nrow, ncol, ncell, nlayers) resolution : 1860, 2650 (x, y) extent : -8027100, -7889460, 5609433, 5794933 (xmin, xmax, ymin, ymax) crs : +proj=merc +a=6378137 +b=6378137 +lat_ts=0 +lon_0=0 +x_0=0 +y_0=0 +k=1 +units=m +nadgrids=@null +wktext +no_defs source : memory names : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, ... min values : -1.616e+01, -1.986e+01, -1.276e+01, -4.459e+00, 2.427e+00, 8.241e+00, 9.727e+00, 9.227e+00, 6.285e+00, 2.741e+00, -7.032e+00, -1.355e+01, -1.390e+01, -1.451e+01, -1.386e+01, ... max values : -1.390e+01, -1.801e+01, -9.526e+00, -6.056e-01, 5.500e+00, 1.180e+01, 1.300e+01, 1.170e+01, 8.700e+00, 5.300e+00, -4.000e+00, -1.060e+01, -1.180e+01, -1.270e+01, -1.000e+01, ... Notons que la fonction st_crs() nécessite la bibliothèque sf. Nous allons maintenant faire une opération de rognage sur mint en utilisant l’étendue spatiale suivante (dans le système géodésique mondial WGS84): longitude : de 71.5°Ouest à 71°Ouest, latitude : de 45°Nord à 45.5°Nord. mint_crop &lt;- crop(mint, extent(c(-71.5, -71, 45, 45.5))) Pour les deux opérations suivantes nous allons utiliser les contours du Parc national de Frontenac qui est le premier élément de l’objet parcs_sherbrooke manipulé au Module 8 et disponible dans le répertoire Module8_donnees. # importer le raster parcs parcs &lt;- st_read(&quot;Module8/Module8_donnees/parcs_sherbrooke&quot;) Reading layer `parcs_sherbrooke&#39; from data source `/home/kc/git/inSileco/sci1031_backup/Module8/Module8_donnees/parcs_sherbrooke&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 4 features and 18 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -323500 ymin: 151800 xmax: -201900 ymax: 226200 Projected CRS: NAD83 / Quebec Lambert Nous isolons d’abord les contours du Parc national de Frontenac (parcs[1, ]) puis nous créons le shapefile frontenac en utilisant la projection de mint. Ensuite, nous utilisons la fonction mask() pour isoler les cellules de mint qui sont dans les limites du parc frontenac, et cela, pour toutes les couches de mint. # isoler le premier élément de `parcs`, et le convertir dans le CRS de `mint` frontenac &lt;- st_transform(parcs[1, ], st_crs(mint)) # appliquer un mask à `mint` mint_mask &lt;- mask(mint, frontenac) Enfin nous pouvons extraire les valeurs des cellules de mint qui sont à l’intérieur des limites de frontenac en utilisant la fonction extract(). val_frontenac &lt;- extract(mint, frontenac) # la fonction extract retourne une liste, qui associe la valeur de mint à chaque cellule de chaque couche. # Par exemple, retournons les 10 premières lignes et les 5 premiers éléments de cette liste val_frontenac[[1]][1:10, 1:5] X1 X2 X3 X4 X5 [1,] -15.2 -19.1 -10.3 -1.8 4.7 [2,] -15.2 -19.1 -10.3 -1.9 4.6 [3,] -15.2 -19.1 -10.3 -1.9 4.6 [4,] -15.2 -19.0 -10.3 -1.8 4.7 [5,] -15.2 -19.1 -10.3 -1.9 4.7 [6,] -15.2 -19.1 -10.3 -1.9 4.6 [7,] -15.2 -19.1 -10.4 -1.9 4.6 [8,] -15.2 -19.1 -10.4 -1.9 4.6 [9,] -15.2 -19.0 -10.3 -1.8 4.8 [10,] -15.2 -19.0 -10.3 -1.8 4.7 Notons qu’ici, cette opération aurait aussi pu être réalisée en utilisant getValues() sur mint_mask(). Visualiser des rasterStack Comme pour les objets rasters, nous pouvons rapidement visualiser les objets rasterStack avec la fonction plot(). plot(mint) Par défaut, 16 couches sont affichées au maximum. Toutefois, il est possible d’augmenter ce nombre en modifiant la valeur de l’argument maxnl : plot(mint, maxnl = 25) Avec un grand nombre de cartes (au-delà de 10), il peut s’avérer difficile de visualiser correctement les données et il est parfois souhaitable de sélectionner les couches à inspecter. Par exemple, il est possible de visualiser les données des 4 derniers mois en sélectionnant les 4 dernières couches de mint. plot(mint[[117:120]]) Par défaut, le titre utilisé pour chaque carte correspond au nom des couches. Pour modifier les titres, nous pouvons renommer les couches en utilisant la fonction names(). Cela dit, il y a des contraintes sur les noms des couches (par exemple, les espaces blancs sont à éviter). Pour avoir un titre libre de ces contraintes, nous pouvons utiliser l’argument main dans la fonction plot() auquel nous donnons un vecteur contenant les titres souhaités. plot(mint[[117:120]], main = c(&quot;09/2016&quot;, &quot;10/2016&quot;, &quot;11/2016&quot;, &quot;12/2016&quot;)) La fonction mapview() peut aussi être utilisée pour visualiser les rasterStack (voir [Module 8][#mat]). Les différentes couches seront alors mises les unes par dessus les autres dans l’ordre donné (la dernière étant sur le dessus de la pile). Un trop grand nombre de couches rendra la carte difficile à interpréter. Comme mentionner précédemment, mieux vaut sélectionner un nombre limité de couches à visualiser. Ci-dessous, nous visualisons les trois premières couches. library(mapview) mapview(mint[[1:3]]) Remarquer que vous pouvez sélectionner l’affichage de l’une ou l’autre des couches dans le menu apparaissant dans le coin gauche de la carte. Lien entre rasterStack et objets spatio-temporels Jusqu’ici nous avons implicitement utilisé un objet rasterStack comme un objet spatio-temporel: chaque couche est bien un objet spatial (avec son étendue spatiale, sa projection, etc.) les couches sont ordonnées dans le temps. Il est cependant important d’insister sur le fait qu’un rasterStack ne contient pas nécessairement un objet spatio-temporel. La seule contrainte sur les couches contenues est spatiale: étendue, projection et résolution doivent être identiques. Ainsi, il est commun de travailler sur une même période avec des objets rasterStack qui contiennent différentes variables pour une période donnée (par exemple, la température, les précipitations, l’élévation, etc.). Cela permet, entre autres, d’éviter la répétition des mêmes opérations sur plusieurs objets rasterLayer. Aussi, certaines données sont, par nature, multi-couches, c’est le cas des données d’imagerie satellitaire (on parle alors de bandes). Jusqu’ici, nous n’avons pas formalisé l’utilisation du temps, nous savons simplement à quoi correspondent les différentes couches. Cette information a été donnée dans le texte plus haut. Toutefois, dans un contexte de partage de données, cette information aurait été ajoutée dans les métadonnées (les données qui décrivent les données). Il existe cependant un moyen de formaliser un peu plus l’information qui ordonne les couches avec la fonction setZ()de la bibliothèque raster. Nous allons utiliser cette fonction pour associer une date à chacune des couches contenues dans le rasterStack. En premier lieu, créons une séquence de date “mois/année”, que nous appèlerons moan, en utilisant les fonctions R rep() et paste0(): # ci-dessous la séquence 1, 2..., 12 est répétée 10 fois (i.e. chacun des 12 mois pour chacune des 10 années) # et chacune des 10 années (2007, ..., 2016) est répétée consécutivement 12 fois moan &lt;- paste0(rep(1:12, 10), &quot;/&quot;, rep(2007:2016, each = 12)) moan[1:12] [1] &quot;1/2007&quot; &quot;2/2007&quot; &quot;3/2007&quot; &quot;4/2007&quot; &quot;5/2007&quot; [6] &quot;6/2007&quot; &quot;7/2007&quot; &quot;8/2007&quot; &quot;9/2007&quot; &quot;10/2007&quot; [11] &quot;11/2007&quot; &quot;12/2007&quot; Nous utilisons ensuite la fonction my() de la bibliothèque lubridate pour formaliser la séquence de temps. Cette fonction transformera la séquence de caractères moan en objet de classe date donnant le mois et l’année (ainsi que le jour, correspondant au premier du mois par défaut). library(lubridate) temps &lt;- my(moan) class(temps) [1] &quot;Date&quot; temps[1:12] [1] &quot;2007-01-01&quot; &quot;2007-02-01&quot; &quot;2007-03-01&quot; [4] &quot;2007-04-01&quot; &quot;2007-05-01&quot; &quot;2007-06-01&quot; [7] &quot;2007-07-01&quot; &quot;2007-08-01&quot; &quot;2007-09-01&quot; [10] &quot;2007-10-01&quot; &quot;2007-11-01&quot; &quot;2007-12-01&quot; Le vecteur temps que nous venons de créer correspond à la date associée à chaque couche de l’objet mint. Nous sommes alors en mesure d’ajouter cette information à mint en utilisant la fonction setZ(). Notons que la longueur de cette séquence doit correspondre au nombre de couches du rasterStack, soit nlayers(mint) dans le cas présent, sinon un message d’erreur sera retourné. mint &lt;- setZ(mint, temps, name = &quot;temps&quot;) mint class : RasterStack dimensions : 60, 60, 3600, 120 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, ... min values : -16.2, -19.9, -12.8, -4.5, 2.4, 8.2, 9.7, 9.2, 6.3, 2.7, -7.1, -13.6, -13.9, -14.5, -13.9, ... max values : -13.9, -18.0, -9.5, -0.6, 5.5, 11.8, 13.0, 11.7, 8.7, 5.3, -4.0, -10.6, -11.8, -12.7, -10.0, ... temps : 2007-01-01 - 2016-12-01 (range) Nous pouvons constater qu’une ligne “temps” a été ajoutée, résumant cette nouvelle information. Ces données sont facilement accessibles avec getZ() qui nous retourne les valeurs de ce nouvel axe z. getZ(mint)[1:10] [1] &quot;2007-01-01&quot; &quot;2007-02-01&quot; &quot;2007-03-01&quot; [4] &quot;2007-04-01&quot; &quot;2007-05-01&quot; &quot;2007-06-01&quot; [7] &quot;2007-07-01&quot; &quot;2007-08-01&quot; &quot;2007-09-01&quot; [10] &quot;2007-10-01&quot; La couche mint pour une année donnée le long de cette axe de temps est accessible en utilisant [[. Par exemple, la première couche est : mint[[1]] class : RasterLayer band : 1 (of 120 bands) dimensions : 60, 60, 3600 (nrow, ncol, ncell) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs source : mint.nc names : X1 values : -16.2, -13.9 (min, max) temps : 2007-01-01 zvar : variable Il devient alors plus aisé de trier les couches sur la date. Par exemple, nous pouvons sélectionner toutes les couches de 2015 en utilisant year() de lubridate. mint[[which(year(getZ(mint)) == 2015)]] class : RasterStack dimensions : 60, 60, 3600, 12 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X97, X98, X99, X100, X101, X102, X103, X104, X105, X106, X107, X108 min values : -20.4, -23.2, -15.5, -5.6, 4.8, 6.9, 10.6, 11.5, 8.6, -1.7, -4.0, -5.7 max values : -18.6, -22.0, -11.5, -1.3, 8.1, 10.4, 14.1, 15.0, 11.5, 1.1, -0.9, -1.8 temps : 2015-01-01, 2015-02-01, 2015-03-01, 2015-04-01, 2015-05-01, 2015-06-01, 2015-07-01, 2015-08-01, 2015-09-01, 2015-10-01, 2015-11-01, 2015-12-01 Rappelons ici que la fonction which() retourne les indices des éléments qui satisfont à la condition. 9.1.3.3 Mois de plus faible pluviométrie Nous sommes maintenant en mesure de répondre à la première question : Quel mois dispose du plus faible niveau de pluviométrie dans la région du Parc national du Mont-Mégantic? Pour ce faire, nous devons réaliser trois étapes : Isoler les cellules du rasterstack pcp qui correspondent à la zone du Parc national du Mont-Mégantic. Calculer la pluviométrie moyenne pour toutes les couches (c’est-à-dire tous les mois). Déterminer le mois et l’année pour lequel la pluviométrie moyenne ainsi calculée est la plus faible. Commençons! 1. Cellules du Parc national du Mont-Mégantic Nous décidons de prendre les cellules de nos couches qui sont à l’intérieur du Parc du Mont-Mégantic ainsi que les cellules qui sont proches du parc, dans un rayon de 5 km. Cette opération de buffer est très souvent utilisée pour augmenter la couverture spatiale et ainsi obtenir une moyenne climatique à une plus large échelle. Nous commençons donc par extraire les limites du parc de l’objet parcs et nous y ajoutons une zone tampon de 5 km. megantic &lt;- parcs[2, ] megantic_buf &lt;- st_buffer(megantic, dist = 5000) Ici dist = 5000, car les distances sont à exprimer en mètre, nous pouvons le savoir en regardant le champ units retourner par st_crs(). st_crs(parcs)$units [1] &quot;m&quot; Nous affichons maintenant, les deux objets : les limites du parc et les mêmes limites auxquelles une zone tampon de 5 km a été ajoutée. parc_buffer &lt;- mapview(megantic, col.regions = &quot;seagreen&quot;) + mapview(megantic_buf, col.regions = &quot;lightgreen&quot;) parc_buffer@map Nous allons maintenant appeler la fonction mask() de la bibliothèque raster pour extraire les cellules désirées du raster pcp (précipitations cumulées). Utiliser cette fonction nous permet de visualiser spatialement les données extraites, mais notons que nous aurions pu aussi utiliser la fonction extract() pour répondre à la question. pcp_megantic &lt;- mask(pcp, st_transform(megantic_buf, st_crs(pcp))) Notez également, que nous nous sommes assurés que le raster utilisé pour créer le masque soit dans le même système de coordonnées de référence que le rasterStack interrogé. Visualisons les quatres premières couches de pcp_megantic : plot(pcp_megantic[[1:4]]) Celles-ci correspondent aux précipitations cumulées dans la région autour du Parc national du Mont-Mégantic pour les quatre premiers mois répertoriés. 2. Calculer la pluviométrie moyenne pour toutes les couches Nous pouvons alors extraire les valeurs des différentes couches avec la fonction getValues() et faire la moyenne couche par couche (c’est-à-dire mois par mois) en utilisant les fonctions R apply() et mean(), sans oublier d’enlever les valeurs non attribuées (NA). mean_pcp &lt;- apply(getValues(pcp_megantic), 2, mean, na.rm = TRUE) Rappelez-vous que l’argument 2 signifie que la fonction mean() est appliquée sur la deuxième dimension de la matrice getValues(pcp_megantic) (c’est-à-dire la dimension associée aux couches). Utilisons le vecteur temps créé plus tôt pour visualisons le changement dans les précipitations cumulées moyennes en fonction du temps : plot(temps, mean_pcp) 3. Déterminer le mois de plus faible pluviométrie moyenne Nous sommes maintenant en mesure de chercher le minimum de ces moyennes. min(mean_pcp) [1] 39.81 Cette valeur correspond à la plus faible pluviométrie moyenne. Pour quel mois cette valeur a-t-elle été enregistrée? which.min(mean_pcp) X71 71 temps[which.min(mean_pcp)] [1] &quot;2012-11-01&quot; # ou encore getZ(mint)[which.min(mean_pcp)] [1] &quot;2012-11-01&quot; C’est la couche 71 qui présente la plus faible valeur moyenne des précipitations totales, cette couche correspond au mois de novembre 2012. 9.1.3.4 Points les plus chauds Nous allons maintenant répondre à la deuxième question : Où se situe le (ou les) point(s) le(s) plus chaud(s) dans la région du Parc national du Mont-Mégantic? Pour ce faire, nous allons réaliser deux étapes : Isoler les cellules de maxt qui correspondent à la zone du parc du Mont-Mégantic. Trouver la ou les cellules pour laquelle cette valeur est maximale. Commençons! 1. Cellules du Parc national du Mont-Mégantic Pour répondre à cette question, nous utilisons seulement les cellules contenues dans les limites du Parc national du Mont-Mégantic. Ainsi, nous n’ajouterons pas de zone tampon autour du parc. Nous appliquons la fonction mask() au rasterStack maxt qui contient les températures maximales moyennes en utilisant les limites du parc. Comme nous avons déjà réalisé des opérations de mask() à plusieurs reprises, nous allons faire cette première étape à l’aide d’une seule ligne de commande. maxt_megantic &lt;- mask(maxt, st_transform(megantic, st_crs(maxt))) 2. Cellules de température maximale Pour la seconde étape, il y a plusieurs façons de procéder. Ici, nous allons procéder en deux temps : nous allons d’abord trouver la couche (ou les couches) qui contient (ou contiennent) la valeur de température maximale, puis trouver les coordonnées du point (ou des points) associées. Nous calculons donc le maximum pour chaque couche, puis nous déterminons quel est le maximum de ces maxima. id &lt;- which.max(apply(getValues(maxt_megantic), 2, max, na.rm = TRUE)) id X43 43 Notez que la fonction apply() calcule le maximum pour chacune des couches contenues dans maxt_megantic, alors que le fonction which.max() détermine l’indice de la couche qui contient le maximum de ces maxima. C’est donc la couche 43 qui contient ce maximum. Nous pouvons également déterminer que c’est au mois de juillet 2010 que ce maximum a été atteint : temps[id] [1] &quot;2010-07-01&quot; et que cette température était de 24.7°C : max(apply(getValues(maxt_megantic), 2, max, na.rm = TRUE)) [1] 24.7 Utilisons maintenant la fonction xyFromCell() de la bibliothèque raster pour déterminer les coordonnées spatiales auxquelles cette température a été enregistrée. xyFromCell(maxt_megantic[[id]], which.max(maxt_megantic[[id]])) x y [1,] -71.22 45.48 [2,] -71.20 45.42 [3,] -71.18 45.42 Rappelons que la fonction xyFromCell(A,id) détermine les coordonnées (x,y) de la cellule d’un raster A dont l’indice est id. Ainsi, dans la ligne de code précédente, le premier argument de la fonction xyFromCell() correspond au raster au sein duquel on recherche les coordonnées (x,y). Dans le cas présent, ce raster est la couche 43 du rasterStack maxt_megantic. Le deuxième argument correspond à l’indice de la ou des cellules qui contiennent le maximum. Ainsi, la température maximale a été enregistrée sur trois cellules à l’intérieur du parc. 9.1.3.5 Profils de temperatures et de precipitations Nous allons maintenant réaliser des profils de températures et de précipitations. Ces profils correspondent à l’évolution temporelle des températures (maximales et minimales) et des précipitations moyennes. Plus précisément, nous cherchons à créer des graphiques où l’ordonnée correspondra à l’une des trois valeurs environnementales moyennes et l’abscisse au temps, selon une résolution mensuelle. Pour réaliser ces profils, nous allons faire une moyenne pour chaque couche des valeurs puis les afficher en fonction du temps. Nous allons répéter trois fois la même opération ici (une fois pour chaque rasterStack: maxt.nc, mint.nc et pcp.nc). Au lieu de copier/coller notre code pour les trois sources de données, nous allons créer une fonction profil(). Cette fonction prend en intrant ras, un objet rasterLayer ou rasterStack et masque, l’objet spatial qui sera utilisé pour découper le raster. profil &lt;- function(ras, masque) { # l&#39;argument masque doit utiliser le même SCR que ras masque_crs &lt;- st_transform(masque, st_crs(ras)) # extraire les valeurs de ras au sein du masque ainsi créé ras_extract &lt;- extract(ras, masque_crs)[[1]] # notons que la fonction `extract()` permet de faire des extractions # pour plusieurs polygones, ici masque_crs n&#39;aura qu&#39;un seul polygon et nous # utilisons donc que le premier élément de la liste retournée par `extract()` # calculer la moyenne pour chaque couche apply(ras_extract, 2, mean, na.rm = TRUE) } Cette fonction nous permet donc d’obtenir les valeurs environnementales moyennes à mettre en ordonnées de nos profils. Il nous reste à obtenir les valeurs des abscisses, autrement dit les dates pour chacune des moyennes. Comme les dates sont les mêmes pour mint, maxt et pcp, nous utilisons getZ(mint) qui nous donne exactement ce dont nous avons besoin. Notez que nous pouvons également utiliser le vecteur temps créé plus tôt. Nous allons maintenant créer la figure. Celle-ci contiendra trois panneaux. Chaque panneau appelle la fonction profil() que nous venons de créer avec en argument l’une ou l’autre des variables environnementales (mint, maxt et pcp) ainsi que le raster correspondant aux frontières élargies du Parc national du Mont-Mégantic,megantic_buf. Pour illustrer les températures, nous utilisons des lignes et pour les précipitations nous utilisons des barres, ces réglages peuvent se faire avec l’argument type de la fonction plot(). Enfin comme l’axe des abscisses est identique pour les trois panneaux, nous ajoutons un titre seulement à cet axe, donc seulement pour le dernier panneau. # figures de trois lignes et 1 seule colonne par(mfrow = c(3, 1), mar = c(4, 4, 1, 1)) plot(getZ(mint), profil(mint, megantic_buf), type = &quot;l&quot;, ylab = &quot;Températures minimales (°C)&quot;, xlab = &quot;&quot;) plot(getZ(mint), profil(maxt, megantic_buf), type = &quot;l&quot;, ylab = &quot;Températures maximales (°C)&quot;, xlab = &quot;&quot;) plot(getZ(mint), profil(pcp, megantic_buf), type = &quot;h&quot;, ylab = &quot;Précipitations totales (mm)&quot;, xlab = &quot;Années&quot;) Ces profils, s’échelonnant sur plusieurs années, nous permettent d’observer la périodicité annuelle des variables environnementales illustrées. 9.1.3.6 Animations Pour finir, nous allons animer les profils que nous venons de dessiner. Ici, au lieu d’appeler la fonction profil() dans la fonction plot(), comme fait précédemment, nous calculons les profils des trois variables environnementales (mint, maxt et pcp) en amont. Cela permet de gagner du temps de calcul. pr_mint &lt;- profil(mint, megantic_buf) pr_maxt &lt;- profil(maxt, megantic_buf) pr_pcp &lt;- profil(pcp, megantic_buf) Nous allons maintenant créer une nouvelle fonction, plot_profil(), pour produire une figure affichant les profils des trois variables d’intérêt pour un nombre donné de mois. Cette fonction prend en entrée cinq arguments : n, le nombre de mois pour lequel nous voulons afficher les profils, les trois profils des variables environnementales d’intérêt (pr_mint, pr_maxt et pr_pcp), et la variable temporelle temps. De plus, nous voulons améliorer quelque peu le rendu visuel obtenu avec la fonction plot(). Tout d’abord, nous souhaitons utiliser les températures minimales et maximales moyennes pour créer une envelope de températures. Cela est possible en faisant appel à la fonction polygon(). Attention, la fonction polygon() n’est pas liée à la fonction st_polygon()! La fonction polygon(x,y,...) dessine un polygone dont les coordonnées des sommets sont données par les vecteurs x et y. Par exemple : # soit les vecteurs x et y des sommets du polygone x &lt;- c(1:6,5:1) y &lt;- c(2,2,2,3,3,3,4,4,4,5,5) # tracer le polygone de couleur rose délimité par une ligne rouge plot(c(1,6),c(1,5), type = &quot;n&quot;) polygon(x, y, col = &quot;pink&quot;, lty = 2, lwd = 2, border = &quot;red&quot;) Deux remarques méritent d’être mentionnées : Un polygone est une figure fermée. Le premier et le dernier sommets sont donc joints. l’argument type = \"n\" dans la fonction plot() permet de créer une figure vide (dans laquelle on ajoute le polygone). Ainsi, pour créer une enveloppe, nous définissions les sommets du polygone en utilisant la variable temporelle temps pour définir les coordonnées en x, et les profils pr_mintet pr_maxt pour définir les coordonnées en y. De plus, toujours dans l’objectif d’améliorer le rendu visuel de la figure, nous ajoutons les valeurs de précipitations sur la même figure que celle des températures. La fonction plot_profil() prend la forme suivante : plot_profil &lt;- function(n, pr_mint, pr_maxt, pr_pcp, temps) { # Créer un vecteur allant de 1 à n id &lt;- seq_len(n) # Premier affichage sur la figure: les temperatures # definition des paramètres (par) de ce premier graphique: # les marges (mar) et le style d&#39;écriture horizontal sur les axes (las = 1) par(mar = c(4, 4.5, 1, 4.5), las = 1) # créer une figure vide (type = &quot;n&quot;) # dont la limite des axes est définie par les températures minimale et maximale plot(range(temps), c(min(pr_mint), max(pr_maxt)), type = &quot;n&quot;, xlab = &quot;Années&quot;, ylab = &quot;Températures minimales et maximales (°C)&quot;) # créer une enveloppe polygon(c(temps[id], rev(temps[id])), c(pr_mint[id], pr_maxt[rev(id)]), col = &quot;#aaaaaa&quot;, border = &quot;#6a6a6a&quot;) # Deuxième affichage sur la figure: les précipitations # permettre de recommencer à dessiner sur la figure par(new = TRUE) # créer une figure vide (type = &quot;n&quot;) # dont la limite des axes est définie par l&#39;étendue des valeurs de temps et de précipitations # sans ajout d&#39;axes (axes), et sans annotation sur les axes (ann) plot(range(temps), range(pr_pcp), type = &quot;n&quot;, axes = FALSE, ann = FALSE) # ajouter des points pour chaque valeur du vecteur id points(temps[id], pr_pcp[id], type = &quot;h&quot;, col = &quot;#c62b63&quot;, lwd = 2) # ajout d&#39;un axe à droite axis(4) # ajouts d&#39;un texte à droite mtext(&quot;Précipitations totales (mm)&quot;, side = 4, line = 3, las = 0, col = &quot;#c62b63&quot;) # Ajouter le mois en bas a gauche de la figure mtext(temps[n], side = 1, line = 2.5, at = as.Date(&quot;2007-01-01&quot;),cex = 1.4) } Nous devons maintenant passer les profils calculés précédemment à la fonction plot_profil() pour les afficher. Par exemple, pour visualiser les profils pour les 40 premiers mois, nous utilisons la valeur 40 pour n. plot_profil(40, pr_mint, pr_maxt, pr_pcp, temps) Finalement, nous utilisons la fonction saveGIF() de la bibliothèque animation, pour enregistrée une séquence de figures produites avec plot_profil() en faisant évoluer le nombre de mois : library(animation) saveGIF({ # nous générons une figure par trimestre en commençant au mois de mars for (i in seq(3, 120, by = 3)) plot_profile(i, pr_mint, pr_maxt, pr_pcp, temps) }, movie.name = &quot;anim3.gif&quot;, ani.height = 400, ani.width = 600) "],["ex_spatiotemp.html", "9.2 Exercice", " 9.2 Exercice Dans cette section, vous mettrez en pratique certains concepts vus dans la section leçon de ce module. Bien que la réponse à chaque question soit disponible, il est très important de tenter d’y répondre par vous même! Question 1 Créer une animation de la carte des températures minimums pour les 12 premiers mois de l’année 2007. Votre animation doit avoir les caractéristiques suivantes : Couvrir seulement la région allant de 71.4°Ouest à 71°Ouest, en longitude, et de 45°Nord à 45.4°Nord en latitude dans le dans le système géodésique mondial WGS84. Comprendre légende affichant les températures de -24 C à +24 C par bond de 2 C. Afficher la légende à droite de la carte. Utiliser une palette de couleurs allant d’une couleur froide pour les températeurs négatives vers une couleur chaude pour les températures négatives. Avoir un titre qui comprend le mois (en français) et l’année. Être construite avec la bibliothèque tmap. Réponse Pour commencer, il nous faut sélectionner la région demandée de mint en utilisant la fonction crop(). Nous savons que ce rasterStack utilise le système WGS84, nous n’avons donc pas à changer le SCR. region &lt;- extent(c(-71.5, -71, 45, 45.4)) mint_region &lt;- crop(mint,region) Ensuite, construisons une fonction pour afficher une seule couche du rasterStack mint_region avec les caractéristiques demandées. Définission d’abord les éléments propres à la légende, aux couleurs, et au titre. # Légende allant de -24 à 24 par pas de 2. L &lt;- seq(-24, 24, by = 2) # Palette de couleurs allant de froid à chaud # Par exemple de bleu à rouge en passant par gris Pal &lt;- colorRampPalette( c(&quot;blue&quot;,&quot;grey&quot;, &quot;red&quot;)) # On assigne une couleur à chaque élément de la légende Coul &lt;- Pal(length(L)) # On peut également assigner des noms à chaque élément. # Par défaut, chaque élément aura la forme : &quot;-24 to -22&quot; noms &lt;- c(L[1:12], L[14:25]) noms &lt;- as.character(noms) # On se souvient que les dates associées à chacune des couches de mint # sont données par le vecteur `temps` # ainsi, la bibliothèque lubridate nous permet de connaitre # l&#39;année year(temps[1:12]) [1] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 [11] 2007 2007 # et le mois month(temps[1:12]) [1] 1 2 3 4 5 6 7 8 9 10 11 12 # qu&#39;on peut écrire en français FR &lt;- c(&quot;janvier&quot;, &quot;février&quot;, &quot;mars&quot;,&quot;avril&quot;,&quot;mai&quot;, &quot;juin&quot;, &quot;juillet&quot;, &quot;août&quot;, &quot;septembre&quot;, &quot;octobre&quot;, &quot;novembre&quot;, &quot;décembre&quot;) FR[month(temps[1:12])] [1] &quot;janvier&quot; &quot;février&quot; &quot;mars&quot; &quot;avril&quot; [5] &quot;mai&quot; &quot;juin&quot; &quot;juillet&quot; &quot;août&quot; [9] &quot;septembre&quot; &quot;octobre&quot; &quot;novembre&quot; &quot;décembre&quot; Créons maintenant la fonction pour afficher un seul mois. # La fonction comprend 2 arguments: # - RS, le rasterStack # - t, le mois library(tmap) fct_carte &lt;- function(RS,t){ tm_shape(RS[[t]])+ #couche correspondant au mois t tm_raster(palette=Coul, title = &quot;&quot;, #pas de titre pour la légende breaks = L, labels=noms, legend.is.portrait = TRUE, legend.reverse = TRUE) + #assure que les T négatives sont au bas de la légende tm_layout(main.title = paste0(&quot;Températures minimales (°C) - &quot;,FR[month(temps[t])],&quot; &quot;,year(temps[t])), main.title.size = 0.9, legend.outside = TRUE, legend.outside.position = &quot;right&quot;, legend.text.size = 0.8, legend.format = list(text.align = &quot;right&quot;)) } Par exemple, pour le premier mois, cette fonction affiche  : # Par exemple cette fonction donne fct_carte(mint_region,3) Nous devons à présent créer une fonction qui répètera l’affichage de la carte pour tous les mois souhaités. # Cette fonction compte encore deux arguments: # - RS, le rasterStack # - T, le nombre de mois anim_carte &lt;- function(RS, T){ for(i in 1:T){ print(fct_carte(RS,i)) } } Pour les douzes premiers mois, cette fonction affichera la séquence suivante: anim_carte(mint_region,12) Vous pouvez également sauvegarder cette animation en exécutant cette ligne de commande : saveGIF(anim_carte(mint_crop, 12), movie.name = &quot;anim_mint.gif&quot;, ani.height = 500, ani.width = 500) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
